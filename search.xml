<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[siege压测工具使用说明]]></title>
    <url>%2F2018%2F12%2F16%2Fsiege%E5%8E%8B%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[siege工具使用 命令12siege -c 200 -r 100 "URL连接地址" #模拟200个用户并发，-r 重复次数100次siege -c 200 -t 10m "URL连接地址" siege结果报告12345678910111213siege报告:Transactions: 4000 hits #完成4000次处理Availability: 100.00 % # 成功率百分之百Elapsed time: 21.16 secs # 总共使用时间21.16Data transferred: 36.52 MB # 总数据传输36.52MBResponse time: 0.29 secs # 平均响应时间0.29Transaction rate: 189.04 trans/sec # 平均每秒处理请求次数189.04Throughput: 1.73 MB/sec # 平均每秒传送数据MBConcurrency: 54.53 # 实际最高并发连接数Successful transactions: 4000 # 成功处理次数Failed transactions: 0 # 失败处理次数Longest transaction: 1.33 # 满足一个请求所需最长时间Shortest transaction: 0.15 # ................最短时间]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>siege压测工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty学习知识点备忘录]]></title>
    <url>%2F2018%2F12%2F16%2Fopenresty%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录下学习openresty的一些小知识点，小命令方便忘记的时候查看 以下所有学习记录知识点都是从 ==&gt; 张开涛博客 《跟我学nginx+lua开发》博客地址链接 openresty中lua获取请求相关参数ngx.req.get_headers12345678910111213141516--请求头 local headers = ngx.req.get_headers() ngx.say("headers begin", "&lt;br/&gt;") ngx.say("Host : ", headers["Host"], "&lt;br/&gt;") ngx.say("user-agent : ", headers["user-agent"], "&lt;br/&gt;") ngx.say("user-agent : ", headers.user_agent, "&lt;br/&gt;") for k,v in pairs(headers) do if type(v) == "table" then ngx.say(k, " : ", table.concat(v, ","), "&lt;br/&gt;") else ngx.say(k, " : ", v, "&lt;br/&gt;") end end ngx.say("headers end", "&lt;br/&gt;") ngx.say("&lt;br/&gt;") 123456789101112131415161718192021222324252627282930313233343536--get请求uri参数 ngx.say("uri args begin", "&lt;br/&gt;") local uri_args = ngx.req.get_uri_args() for k, v in pairs(uri_args) do if type(v) == "table" then ngx.say(k, " : ", table.concat(v, ", "), "&lt;br/&gt;") else ngx.say(k, ": ", v, "&lt;br/&gt;") end end ngx.say("uri args end", "&lt;br/&gt;") ngx.say("&lt;br/&gt;") --post请求参数 ngx.req.read_body() ngx.say("post args begin", "&lt;br/&gt;") local post_args = ngx.req.get_post_args() for k, v in pairs(post_args) do if type(v) == "table" then ngx.say(k, " : ", table.concat(v, ", "), "&lt;br/&gt;") else ngx.say(k, ": ", v, "&lt;br/&gt;") end end ngx.say("post args end", "&lt;br/&gt;") ngx.say("&lt;br/&gt;") --请求的http协议版本 ngx.say("ngx.req.http_version : ", ngx.req.http_version(), "&lt;br/&gt;") --请求方法 ngx.say("ngx.req.get_method : ", ngx.req.get_method(), "&lt;br/&gt;") --原始的请求头内容 ngx.say("ngx.req.raw_header : ", ngx.req.raw_header(), "&lt;br/&gt;") --请求的body内容体 ngx.say("ngx.req.get_body_data() : ", ngx.req.get_body_data(), "&lt;br/&gt;") ngx.say("&lt;br/&gt;") 1234567891011ngx.var ： nginx变量，如果要赋值如ngx.var.b = 2，此变量必须提前声明；另外对于nginx location中使用正则捕获的捕获组可以使用ngx.var[捕获组数字]获取；ngx.req.get_headers：获取请求头，默认只获取前100，如果想要获取所以可以调用ngx.req.get_headers(0)；获取带中划线的请求头时请使用如headers.user_agent这种方式；如果一个请求头有多个值，则返回的是table；ngx.req.get_uri_args：获取url请求参数，其用法和get_headers类似；ngx.req.get_post_args：获取post请求内容体，其用法和get_headers类似，但是必须提前调用ngx.req.read_body()来读取body体（也可以选择在nginx配置文件使用lua_need_request_body on;开启读取body体，但是官方不推荐）；ngx.req.raw_header：未解析的请求头字符串；ngx.req.get_body_data：未解析的请求body体内容字符串 lua获取location使用正则匹配的部分12345678910111213141516location ~ /lua_request/(\d+)/(\d+) &#123; #设置nginx变量 set $a $1; set $b $host; default_type "text/html"; #nginx内容处理 content_by_lua_file /usr/example/lua/test_request.lua; #内容体处理完成后调用 echo_after_body "ngx.var.b $b"; &#125; # lua代码获取local var = ngx.var ngx.say("ngx.var.a : ", var.a, "&lt;br/&gt;") ngx.say("ngx.var.b : ", var.b, "&lt;br/&gt;") # 对于nginx location中使用正则捕获的捕获组可以使用ngx.var[捕获组数字]获取 ngx.say("ngx.var[2] : ", var[2], "&lt;br/&gt;") uri编码和解码12345678910111213--未经解码的请求uri local request_uri = ngx.var.request_uri; ngx.say("request_uri : ", request_uri, "&lt;br/&gt;"); --解码 ngx.say("decode request_uri : ", ngx.unescape_uri(request_uri), "&lt;br/&gt;"); --MD5 ngx.say("ngx.md5 : ", ngx.md5("123"), "&lt;br/&gt;") --http time ngx.say("ngx.http_time : ", ngx.http_time(ngx.time()), "&lt;br/&gt;")# ngx.escape_uri/ngx.unescape_uri ： uri编码解码；# ngx.encode_args/ngx.decode_args：参数编码解码；# ngx.encode_base64/ngx.decode_base64：BASE64编码解码；# ngx.re.match：nginx正则表达式匹配； 全局共享内存变量1234567891011121314--1、获取全局共享内存变量 local shared_data = ngx.shared.shared_data --2、获取字典值 local i = shared_data:get("i") if not i then i = 1 --3、惰性赋值 shared_data:set("i", i) ngx.say("lazy set i ", i, "&lt;br/&gt;") end --递增 i = shared_data:incr("i", 1) ngx.say("i=", i, "&lt;br/&gt;") set_by_lua_file or set_by_lua 获取变量123456789101112131415161718192021222324252627282930313233343536373839404142# Use help# set_by_lua_filelocation /lua_set_1 &#123; default_type "text/html"; set_by_lua_file $num /usr/example/lua/test_set_1.lua; echo $num; &#125; # set_by_lua_file：语法set_by_lua_file $var lua_file arg1 arg2...; 在lua代码中可以实现所有复杂的逻辑，但是要执行速度很快，不要阻塞；# test_set_1.lua文件内容local uri_args = ngx.req.get_uri_args() local i = uri_args["i"] or 0 local j = uri_args["j"] or 0 return i + j # set_by_lua语法set_by_lua $to_book ' local ngx_match = ngx.re.match local var = ngx.var local skuId = var.skuId local r = var.item_dynamic ~= "1" and ngx.re.match(skuId, "^[0-9]&#123;8&#125;$") if r then return "1" else return "0" end; '; set_by_lua $to_mvd ' local ngx_match = ngx.re.match local var = ngx.var local skuId = var.skuId local r = var.item_dynamic ~= "1" and ngx.re.match(skuId, "^[0-9]&#123;9&#125;$") if r then return "1" else return "0" end; '; #自营图书 if ($to_book) &#123; proxy_pass http://127.0.0.1/old_book/$skuId.html; &#125; #自营音像 if ($to_mvd) &#123; proxy_pass http://127.0.0.1/old_mvd/$skuId.html; &#125; #默认 proxy_pass http://127.0.0.1/proxy/$skuId.html; 连接redis1234567891011121314151617181920212223242526272829303132333435363738394041424344local function close_redis(red) if not red then return end local ok, err = red:close() if not ok then ngx.say("close redis error : ", err) end end local redis = require("resty.redis") --创建实例 local red = redis:new() --设置超时（毫秒） red:set_timeout(1000) --建立连接 local ip = "127.0.0.1" local port = 6660 local ok, err = red:connect(ip, port) if not ok then ngx.say("connect to redis error : ", err) return close_redis(red) end --调用API进行处理 ok, err = red:set("msg", "hello world") if not ok then ngx.say("set msg error : ", err) return close_redis(red) end --调用API获取数据 local resp, err = red:get("msg") if not resp then ngx.say("get msg error : ", err) return close_redis(red) end --得到的数据为空处理 if resp == ngx.null then resp = '' --比如默认值 end ngx.say("msg : ", resp) close_redis(red)]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志切割shell脚本]]></title>
    <url>%2F2018%2F12%2F16%2Fnginx%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2shell%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[nginx日志按天进行切割，通过写shell脚本，创建以日期命名文件 直奔主题12345678910111213141516171819202122232425262728293031#!/usr/bin/env bashset -e# 定义nginx 日志路径LOG_PATH="/var/gb/logs/"# 定义nginx 访问日志文件名称ACCESS_LOG="access.log"ERROR_LOG="error.log"for i in `find $LOG_PATH -name "$ACCESS_LOG"`; do cd $(dirname $i) # 切割access日志 if [[ -f $ACCESS_LOG ]]; then cp &#123;,$(date +%F)-&#125;$&#123;ACCESS_LOG&#125; : &gt; $ACCESS_LOG fi # 如果error日志&gt;20m，切 if [[ -f $ERROR_LOG ]]; then ERROR_SIZE=`ls -l $ERROR_LOG | awk '&#123; print $5 &#125;'` if [[ $ERROR_SIZE -gt 20971520 ]]; then cp &#123;,$(date +%F)-&#125;$&#123;ERROR_LOG&#125; : &gt; $&#123;ERROR_LOG&#125; fi fidone# 查找nginx 日志目录下7天前的日志并删除find $&#123;LOG_PATH&#125; -type f -name "*-$&#123;ACCESS_LOG&#125;" -mtime +7 -deletefind $&#123;LOG_PATH&#125; -type f -name "*-$&#123;ERROR_LOG&#125;" -mtime +7 -delete]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx日志切割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx根据http_useragent判断是手机端还是pc端]]></title>
    <url>%2F2018%2F12%2F16%2Fnginx%E6%A0%B9%E6%8D%AEhttp-useragent%E5%88%A4%E6%96%AD%E6%98%AF%E6%89%8B%E6%9C%BA%E7%AB%AF%E8%BF%98%E6%98%AFpc%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[nginx的location判断用户端是手机还是pc端配置 配置12345678910111213141516# 判断 pc 和 mobile 的 H5 location / &#123; set $is_mobile false; #设置一个初始值 if ( $http_cookie ~* "ACCESS_TERMINAL=mobile" ) &#123; #判断匹配手机端 set $is_mobile true; &#125; if ($http_user_agent ~* (android|ip(ad|hone|od)|kindle|blackberry|windows\s(ce|phone))) &#123; #匹配手机端类型 set $is_mobile true; &#125; if ($is_mobile = true) &#123; root /usr/local/openresty/nginx/html/mobile/; break; &#125; root /usr/local/openresty/nginx/html/pc/; &#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装配置NFS]]></title>
    <url>%2F2018%2F12%2F16%2FCentos7%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AENFS%2F</url>
    <content type="text"><![CDATA[在生产环境中，有些目录需要共享，想让其他节点挂载此共享目录使用场景： 日志目录，应用程序目录 安装环境说明:OS: Centos71yum -y install nfs-utils rpcbind nfs配置文件: /etc/exports共享目录: /home/data管理节点上配置: 12# cat /etc/exports/home/data 192.168.0.0/24(rw,async,insecure,anonuid=1000,anongid=1000,no_root_squash) 生效配置文件 1exportfs -rv nfs的配置参数说明 192.168.1.0/24 可以为一个网段，一个IP，也可以是域名，域名支持通配符 如: *.com rw：read-write，可读写； ro：read-only，只读； sync：文件同时写入硬盘和内存； async：文件暂存于内存，而不是直接写入内存； no_root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，也拥有root权限。显然开启这项是不安全的。 root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，拥有匿名用户权限，通常他将使用nobody或nfsnobody身份； all_squash：不论NFS客户端连接服务端时使用什么用户，对服务端分享的目录来说都是拥有匿名用户权限； anonuid：匿名用户的UID值 anongid：匿名用户的GID值。备注：其中anonuid=1000,anongid=1000,为此目录用户web的ID号,达到连接NFS用户权限一致。 defaults 使用默认的选项。默认选项为rw、suid、dev、exec、auto nouser与async。 atime 每次存取都更新inode的存取时间，默认设置，取消选项为noatime。 noatime 每次存取时不更新inode的存取时间。 dev 可读文件系统上的字符或块设备，取消选项为nodev。 nodev 不读文件系统上的字符或块设备。 exec 可执行二进制文件，取消选项为noexec。 noexec 无法执行二进制文件。 auto 必须在/etc/fstab文件中指定此选项。执行-a参数时，会加载设置为auto的设备，取消选取为noauto。 noauto 无法使用auto加载。 suid 启动set-user-identifier设置用户ID与set-group-identifer设置组ID设置位，取消选项为nosuid。 nosuid 关闭set-user-identifier设置用户ID与set-group-identifer设置组ID设置位。 user 普通用户可以执行加载操作。 nouser 普通用户无法执行加载操作，默认设置。 remount 重新加载设备。通常用于改变设备的设置状态。 rsize 读取数据缓冲大小，默认设置1024。–影响性能 wsize 写入数据缓冲大小，默认设置1024。 fg 以前台形式执行挂载操作，默认设置。在挂载失败时会影响正常操作响应。 bg 以后台形式执行挂载操作。 hard 硬式挂载，默认设置。如果与服务器通讯失败，让试图访问它的操作被阻塞，直到服务器恢复为止。 soft 软式挂载。服务器通讯失败，让试图访问它的操作失败，返回一条出错消息。这项功能对于避免进程挂在无关紧要的安装操作上来说非常有用。 retrans=n 指定在以软方式安装的文件系统上，在返回一条出错消息之前重复发出请求的次数。 nointr 不允许用户中断，默认设置。 intr 允许用户中断被阻塞的操作并且让它们返回一条出错消息。 timeo=n 设置请求的超时时间以十分之一秒为单位。 tcp 传输默认使用udp,可能出现不稳定，使用proto=tcp更改传输协议。客户端参考mountproto=netid （以上内容：参考：man nfs） 启动nfs1234systemctl enable rpcbindsystemctl start rpcbindsystemctl enable nfs-serversystemctl start nfs-server 客户端挂载 linux客户端挂载安装nfs服务，然后启动rpcbind服务 12systemctl enable rpcbind.servicesystemctl start rpcbind.service 查看服务端的共享目录 12# showmount -e nfs服务器IPshowmount -e 192.168.1.41 123456789# 开机自动挂载# cat /etc/fstab192.168.1.41:/home/data /home/data nfs4 rw,hard,intr,proto=tcp,port=2049,noauto 0 0# 手动挂载mount -t nfs 192.168.1.41:/home/data /home/data# NFS默认是用UDP协议，换成TCP协议达到稳定传输目的：mount -t nfs 192.168.1.41:/home/data /home/data -o proto=tcp -o nolock]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>NFS服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习五-django的日志输出配置]]></title>
    <url>%2F2018%2F12%2F16%2Fpython%E5%AD%A6%E4%B9%A0%E4%BA%94-django%E7%9A%84%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[django的日志管理 django日志Django 使用Python 内建的logging 模块打印日志，Python 的logging 配置由四个部分组成 记录器 —— Logger 处理程序 —— Handler 过滤器 —— Filter 格式化 —— Formatter 记录器 Logger Logger为日志系统的入口，每个logger命名都是bucket，可以向bucket写入需要处理的消息 每个logger都有一个日志级别，日志级别表示该logger将要处理的消息的严重性，python定义以下几种日志级别: DEBUG: 用于调试目的的底层系统信息 INFO：普通的系统信息 WARNING：表示出现一个较小的问题 ERROR：表示出现一个较大的问题 CRITICAL：表示出现一个致命的问题 写入logger 的每条消息都是一条日志。每条日志也具有一个日志级别，它表示对应的消息的严重性。每个日志记录还可以包含描述正在打印的事件的元信息。 当一条消息传递给logger 时，消息的日志级别将与logger 的日志级别进行比较。如果消息的日志级别大于等于logger 的日志级别，该消息将会往下继续处理。如果小于，该消息将被忽略。 Logger 一旦决定消息需要处理，它将传递该消息给一个Handler logger日志级别 级别 值 描述 CRITICAL 50 关键错误/消息 ERROR 40 错误 WARNING 30 警告消息 INFO 20 通知消息 DEBUG 10 调试 NOTSET 0 无级别 Logger配置logger 对应的值是个字典，其每一个键都是logger的名字，每一个值又是个字典，描述了如何配置对应的Logger实例。 level （可选的）。logger的级别。 propagate （可选的）。logger的传播设置。 filters （可选的）。logger的filter的标识符的列表。 handlers （可选的）。logger的handler的标识符的列表 Logger配置实例12345678LOGGING = &#123; 'loggers': &#123; 'log1': &#123; 'handlers': ['file_handler', 'console_handler'], 'level': 'DEBUG', &#125;, &#125;,&#125; 处理程序Handler Handler 决定如何处理logger 中的每条消息。它表示一个特定的日志行为，例如将消息写到屏幕上、写到文件中或者写到网络socket 与logger 一样，handler 也有一个日志级别。如果消息的日志级别小于handler 的级别，handler 将忽略该消息 Logger 可以有多个handler，而每个handler 可以有不同的日志级别。利用这种方式，可以根据消息的重要性提供不同形式的处理 Handler配置实例123456789LOGGING = &#123; 'handlers': &#123; 'log1': &#123; 'level': 'DEBUG', 'class': 'logging.StreamHandler', 'formatter': 'simple’, &#125; &#125;&#125; 过滤器 Filter Filter 用于对从logger 传递给handler 的日志记录进行额外的控制。 默认情况下，满足日志级别的任何消息都将被处理。通过安装一个filter，你可以对日志处理添加额外的条件。例如，你可以安装一个filter，只允许处理来自特定源的ERROR 消息 Filters 还可以用于修改将要处理的日志记录的优先级。例如，如果日志记录满足特定的条件，你可以编写一个filter 将日志记录从ERROR 降为WARNING Filters 可以安装在logger 上或者handler 上；多个filter 可以串联起来实现多层filter 行为 格式化 Formatters日志记录需要转换成文本。Formatter 表示文本的格式。Fomatter 通常由包含日志记录属性的Python 格式字符串组成；你也可以编写自定义的fomatter 来实现自己的格式 12345678910LOGGING = &#123; 'formatters': &#123; 'log1':&#123; 'format': '%(asctime)s - %(pathname)s:%(lineno)d[%(levelname)s] - %(message)s' &#125; 'simple': &#123; 'format': '%(asctime)s %(levelname)s %(message)s' &#125;, &#125;,&#125; Format日志消息格式 django日志配置管理demo写入文件的日志,用于生产环境1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# settings.py文件定义LOGGINGLOGGING = &#123; 'version': 1, 'disable_existing_loggers': False, 'loggers': &#123; 'reboot': &#123; 'handlers': ["reboot"], 'level': 'DEBUG', 'propagate': True &#125;, "django": &#123; 'handlers': ["django"], 'level': 'DEBUG', 'propagate': True &#125;, "django.server": &#123; 'handlers': ["django_server"], 'level': 'DEBUG', "propagate": True &#125; &#125;, 'handlers': &#123; 'reboot': &#123; 'level': 'DEBUG', 'class': 'logging.StreamHandler', 'formatter': 'simple', &#125;, 'file': &#123; 'level': 'DEBUG', 'class': 'logging.FileHandler', 'filename': '/tmp/django.log', 'formatter': 'json', &#125;, 'django': &#123; 'level': 'DEBUG', 'class': 'logging.FileHandler', 'filename': '/tmp/default.log', 'formatter': 'simple', &#125;, 'django_server': &#123; 'level': 'DEBUG', 'class': 'logging.FileHandler', 'filename': '/tmp/django_server.log', 'formatter': 'simple', &#125;, &#125;, 'formatters': &#123; 'json': &#123; 'format': '&#123;"levelname":"%(levelname)s","asctime":"%(asctime)s","module":"%(name)s","fullpath":"%(pathname)s","funcName":"%(funcName)s","lineno":"%(lineno)s","message":"%(message)s"&#125;' &#125;, 'reboot': &#123; 'format': '%(asctime)s - %(pathname)s:%(lineno)d[%(levelname)s] - %(message)s' &#125;, 'simple': &#123; 'format': '%(name)s %(asctime)s %(levelname)s %(message)s' &#125;, 'verbose': &#123; 'format': '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s' &#125;, &#125;, 'root': &#123; 'handlers': ["file"], 'level': 'DEBUG', &#125;&#125;# views.py定义输出日志import logginglogger = logging.getLogger(__name__)class userView2(View): def post(self, request, *args, **kwargs): logger.debug("创建用户") #输出日志 # 1. 获取提交数据 data = request.POST.dict() # 获取post提交的所有数据 logger.debug("请求数据转dict") # 2. 创建用户 try: logger.debug("执行用户创建") #输出日志 user = User.objects.create_user(**data) except IntegrityError: logger.debug("用户已存在") return JsonResponse(&#123;"errmsg": "用户已存在"&#125;) return JsonResponse(&#123;"id": user.id, "email": user.email, "username": user.username&#125;) 写入终端的日志,用于开发环境12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 复制一份manage_dev.py 用于使用这个文件启动webserver，日志输出到终端# 修改导入的settings配置if __name__ == "__main__": os.environ.setdefault("DJANGO_SETTINGS_MODULE", "devops.settings_dev") #修改此处，导入settings_dev文件 try: from django.core.management import execute_from_command_line except ImportError: # The above import may fail for some other reason. Ensure that the # issue is really that Django is missing to avoid masking other # exceptions on Python 2. try: import django except ImportError: raise ImportError( "Couldn't import Django. Are you sure it's installed and " "available on your PYTHONPATH environment variable? Did you " "forget to activate a virtual environment?" ) raise execute_from_command_line(sys.argv)# 复制一份settings文件为settings_dev.py# 输出到终端的日志格式定义LOGGING = &#123; 'version': 1, 'disable_existing_loggers': False, "loggers": &#123; "django": &#123; 'handlers': ["reboot"], 'level': 'DEBUG', 'propagate': False &#125;, &#125;, 'handlers': &#123; 'reboot': &#123; 'level': 'DEBUG', 'class': 'logging.StreamHandler', 'formatter': 'simple', &#125;, &#125;, 'formatters': &#123; 'simple': &#123; 'format': '%(name)s %(asctime)s %(levelname)s %(message)s' &#125;, &#125;, "root": &#123; 'handlers': ["reboot"], 'level': 'DEBUG', &#125;&#125;# 启动django，使用以下命令python manage_dev.py runserver 0.0.0.0:8000]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习(四)django的类视图函数]]></title>
    <url>%2F2018%2F11%2F24%2Fpython%E5%AD%A6%E4%B9%A0-%E5%9B%9B-django%E7%9A%84%E7%B1%BB%E8%A7%86%E5%9B%BE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[django 使用类定义视图 在django的视图中，通过定义class方法，调用 定义类视图函数123456789# urls.pyfrom django.conf.urls import url, includefrom . import viewsurlpatterns = [ url(r'^$', views.index, name='index'), url(r'^loginview/$', views.LoginView.as_view()) #必须使用as_view] 12345678910111213# views.pyfrom django.http import HttpResponse, QueryDict, JsonResponsefrom django.views import View #导入Viewfrom django.contrib.auth.models import Userfrom django.core.paginator import Paginatorfrom django.db.utils import IntegrityErrorimport loggingclass LoginView(View): #集成View类 def get(self, request, *args, **kwargs): #定义get属性 return HttpResponse("展示用户登陆页面") def post(self, request, *args, **kwargs): #定义post属性 return HttpResponse("验证用户名与密码") 以上就是定义类视图的方法，当在类中，定义的请求属性，在View类中不存在，会提示405状态码，抛出请求属性方法不被允许的warning，可进入View类方法中查看 数据分页12from django.contrib import User #导入django的User模型，查询数据库User.object.all() #获取数据库所有用户 12345678910111213# 创建测试数据python manage.py shell# 创建100个用户from django.contrib.auth import Userfor n in range(1,101): username = "sun-&#123;&#125;".format(n) User.objects.create_user(username, email="sun-&#123;&#125;@163.com".format(n), password=123456)# 查看用户python manage.py dbshell #进入django的dbshell 管理台use devops; #使用devops数据库select * from auth_user;select * from auth_user limit 10,20 #过滤数据，从第10个开始显示，显示20行数据 1234# 小插曲# for循环获取所有用户data = [&#123;"id" : user.id, "email": user.email, "username": user.username&#125; for user in User.object.all()]# User.object.all() 返回querySet类型，使用for将数据序列化，在前端使用JsonResponse响应 1234567891011121314151617181920212223# 定义类视图，显示数据# dashboard/urls.pyfrom . import viewsurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login'), url(r'^articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/(?P&lt;day&gt;[0-9]&#123;2&#125;)/$', views.ariticleView, name='article'), url(r'^user/$', views.userView.as_view())]# dashboard/views.pyfrom django.shortcuts import renderfrom django.http import HttpResponse,JsonResponsefrom django.contrib.auth.models import Userfrom django.contrib.auth import authenticate,loginfrom django.views import View # 导入Viewimport jsonclass userView(View): def get(self, request, *args, **kwargs): querySet = User.objects.all() data = [&#123;"id": user.id, "email": user.email, "username": user.username&#125; for user in querySet] return JsonResponse(data, safe=False) 访问http://127.0.0.1:8000/dashboard/user返回数据库的查询数据，刚才创建的100个用户 分页显示使用django自带的paginator模块(如果前后端分离的情况下，不再适用!)123456789101112131415# views使用paginator写法（精简）# 官网: https://docs.djangoproject.com/en/2.1/topics/pagination/class UserViewV2(View): def get(self, request, *args, **kwargs): queryset = User.objects.all() paginator = Paginator(queryset, 10) try: page = int(request.GET.get("page")) except: page = 1 if page &lt; 1: page = 1 page = paginator.page(page) data = [&#123;"id": user.id, "email": user.email, "username": user.username&#125; for user in page.object_list] return JsonResponse(data, safe=False) 练习创建用户接口，添加数据，并返回1234567891011121314151617181920212223242526# views.pyclass userView2(View): def post(self, request, *args, **kwargs): # 1. 获取提交数据 data = request.POST.dict() # 获取post提交的所有数据 # 2. 创建用户 user = User.objects.create_user(**data) return JsonResponse(&#123;"id": user.id, "email": user.email, "username": user.username&#125;)# 调用接口创建用户In [19]: data Out[19]: &#123;'username': 'sun101', 'email': 'sun101@163.com', 'password': '123456789'&#125;In [20]: data["username"] = "sun111" In [21]: data["email"] = "sun111@163.com" In [22]: result = requests.post("http://127.0.0.1:8000/dashboard/user_create/", data) In [23]: result.status_code Out[23]: 200In [24]: result.json Out[24]: &lt;bound method Response.json of &lt;Response [200]&gt;&gt;In [25]: result.json() Out[25]: &#123;'id': 105, 'email': 'sun111@163.com', 'username': 'sun111'&#125;]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器的上行和下行带宽理解]]></title>
    <url>%2F2018%2F11%2F23%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E4%B8%8A%E8%A1%8C%E5%92%8C%E4%B8%8B%E8%A1%8C%E5%B8%A6%E5%AE%BD%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[上行带宽 和下行带宽 理解 对于服务器而言: 上行带宽是指每秒钟服务器传给客户端的最大数据量， 下载图片消耗的是上行流量 下行带宽是指客户上传数据到服务器，对于服务器来说，下行带宽是不限制的，网络因素，取决于客户端当前的网络情况]]></content>
  </entry>
  <entry>
    <title><![CDATA[Vagrantfile配置虚拟机网络]]></title>
    <url>%2F2018%2F11%2F20%2FVagrantfile%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[了解下Vagrant创建虚拟机的几种网络模式 参考博客地址 Vagrantfile网络相关配置文件端口转发12# config.vm.network "forwarded_port"config.vm.network "forwarded_port", guest: 80, host: 8080 # guest: 80 虚拟机上的端口 host: 8080 本地电脑的8080端口， 这段配置含义: 将本机的8080转发到虚拟机的80端口，可根据虚拟机实际端口，开放 公有网络1# config.vm.network "public_network" # dhcp分配一个ip给虚拟机使用 私有网络1# config.vm.network "private_network", ip: "192.168.33.10" # 自定义一个内网ip，但是不能和宿主机处于同一个网段]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>Vagrantfile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[autoenv使用]]></title>
    <url>%2F2018%2F11%2F19%2Fautoenv%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[autoenv 进入目录，自动加载虚拟环境 安装12345678# 使用git clone到本地项目git clone https://github.com/kennethreitz/autoenv.git# 添加到bashrcecho 'source /opt/autoenv/activate.sh' &gt;&gt; ~/.bashrc# 加载到当前环境source ~/.bashrc 使用123456789# 进入/opt/myproject ,自动加载python3虚拟环境cd /opt/myproject# 创建.env文件# vim .env# 添加内容如下source /home/root/python36env/bin/activate # 需要提前创建python的虚拟环境# 初次进入/opt/myproject目录，会提示,输入y即可，下次，进入此目录，会自动加载python3的虚拟环境]]></content>
      <categories>
        <category>完美工具分享</category>
      </categories>
      <tags>
        <tag>autoenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习(三)django URL]]></title>
    <url>%2F2018%2F11%2F18%2Fpython%E5%AD%A6%E4%B9%A0-%E4%B8%89-django-URL%2F</url>
    <content type="text"><![CDATA[django 的url基础知识 django url请求 django 加载 ROOT_URLCONF指定的模块，并寻找可用的urlpatterns.它是django.conf.urls.url() 实例的一个Python 列表。 Django 依次匹配每个 URL，在与请求的URL 匹配的第一个url停下来 一旦其中的一个正则表达式匹配上，Django 将导入并调用给出的视图，它是一个简单的Python 函数（或者一个基于类的视图） 如果没有匹配到正则表达式，或者如果过程中抛出一个异常，Django 将调用一个适当的错误处理视图：handler404， handler500， handler403， handler400 url的几种写法:123456789101112131415161718# 1.urlpatterns = [ url( r'^$', RedirectView.as_view(url="/dashboard/")), url(r'^dashboard/', include("dashboard.urls")), url(r'^accounts/', include("accounts.urls")), url(r'^admin/', admin.site.urls),]# 2. urlpatterns = [ url(r"^user/", include([ url(r'^list/$', view.userlist, name="user_list"), url(r'^info/$', view.userinfo, name="userer_inf), url(r'^modify/', include([ url(r'status/$',view.modifystatus, name="user_modify_status"), ])) ]))] url参数定义位置参数12345678910111213141516171819# dashboard/urls.pyfrom django.conf.urls import url,includefrom .views import index,loginView,ariticleView #导入views中定义articleViewfrom . import views #导入viewsurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login'), url(r'^articles/([0-9]&#123;4&#125;)/([0-9]&#123;2&#125;)/([0-9]&#123;2&#125;)/$', views.ariticleView, name='article') # 匹配url dashboard/articles/2018/11/18]# views.pyfrom django.shortcuts import renderfrom django.http import HttpResponse,JsonResponsefrom django.contrib.auth.models import Userfrom django.contrib.auth import authenticate,loginimport json# Create your views here.def ariticleView(request, *args, **kwargs): # 通过args接受参数（位置参数） return HttpResponse(json.dumps(args)) 关键字参数12# 语法： (?P&lt;name&gt;pattern) 12345678910111213141516171819# dashboard/urls.pyfrom django.conf.urls import url,includefrom .views import index,loginView,ariticleViewfrom . import viewsurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login'), url(r'^articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/(?P&lt;day&gt;[0-9]&#123;2&#125;)/$', views.ariticleView, name='article') # 定义关键字参数]# views.pydef ariticleView(request, *args, **kwargs): return HttpResponse(json.dumps(kwargs)) # 输出关键字参数# 输出结果展示&#123; "year": "2018", "month": "11", "day": "12"&#125; 额外参数1234567891011# RLconfs 具有一个钩子，让你传递一个Python 字典作为额外的参数传递给视图函数# django.conf.urls.url() 函数可以接收一个可选的第三个参数，它是一个字典，表示想要传递给视图函数的额外关键字参数from django.conf.urls import urlfrom . import viewsurlpatterns = [ url(r'^blog/(?P&lt;year&gt;[0-9]&#123;4&#125;)/$', views.year_archive, &#123;'foo': 'bar'&#125;),]#请求地址：/blog/2005/#调用函数：views.year_archive(request, year='2005',foo='bar')]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习(二)django基础配置]]></title>
    <url>%2F2018%2F11%2F17%2Fpython%E5%AD%A6%E4%B9%A0-%E4%BA%8C-django%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[学习django路程一，基础配置 django基础概念第一篇文章中，搭建了开发环境，并创建了第一个django项目，名称为devops 看下django项目，默认目录的含义 最完成的devops/目录是项目的一个容器 manager.py 一个使用的命令行工具，可让你以各种方式与该 Django 项目进行交互 内层 devops/ 目录是你项目中的实际Python包。通过它你可以导入它里面的任何东西 devops/init.py: 一个空文件，告诉Python该目录是一个Python包 devops/settings.py: 该Django项目的配置文件 devops/urls.py: 该Django项目的 URL 声明 devops/wsgi.py: 一个WSGI兼容的Web服务器的入口启动项目的命令:1python manage.py runserver 0.0.0.0:8000 django的appdjango中有app的概念，本人的理解就是，在一个项目中，有实现不同功能的代码，那么把不同的功能的代码，存放于一个目录下，这个目录就称为django的app 新建app:123python manage.py startapp dashboard#或者django-admin startapp dashboard 创建了app，肯定需要在django项目中加载到此app目录，配置说明 在项目的settings配置文件 123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'dashboard', #加载刚刚创建的app] 配置路由，进入dashboard 12345678# 在主项目devops目录的urls.py中配置from django.conf.urls import url,includefrom django.contrib import adminurlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^dashboard/', include("dashboard.urls")), # 访问dashboard，加载dashboard目录下的urls] 1234567# dashboard目录下创建urls.py文件from django.conf.urls import url,includefrom .views import indexurlpatterns = [ url(r'^$', index, name='index'), #匹配所有，然后通过index的函数响应内容，如何找到views中的index函数，通过from .views import index 导入下面要定义的views.py中的index函数] 1234567# index的定义，需要去views.py中查找，这就是django项目的FBV 基于函数的视图# views.pyfrom django.http import HttpResponse# Create your views here.def index(request): return HttpResponse("Hello,this is dashboard url") 现在访问 http://127.0.0.1:8000/dashboard 就会出现我们刚刚定义的路由信息 HttpRequest对象属性官网地址 常用的request方法12345HttpRequest.get_host()HttpRequest.get_port()HttpRequest.get_full_path()HttpRequest.is_secure()HttpRequest.is_ajax() HttpResponse对象属性1234HttpResponse.contentHttpResponse.charsetHttpResponse.status_codeHttpResponse.reason_phrase HttpResponse的另一种写法 HttpResponse传入列表,通过json.dumps JsonResponse的使用使用JsonResponse传入列表数据，必须设置 safe=False参数，要不然会报错12345678from django.shortcuts import renderfrom django.shortcuts import renderfrom django.http import HttpResponse,JsonResponse# Create your views here.def index(request): data = ["a", "b", "c"] return JsonResponse(data, safe=False) django的request中GET与POST使用浏览器访问http://127.0.0.1:8000/dashboard/?name=changming&amp;&amp;age=23在上面url中使用?号传入参数当访问这个url时，我们可以根据request.get获取数据，数据类型是request.get方法获取数据123# GETrequest.GET.get("name") #获取key对应的值，返回字符串request.GET.getlist("name") #如果key对应多个值，使用此方法，返回列表 在chrome使用postman插件，模拟发送post请求12# POSTrequest.POST.get("name") 实例化QueryDictQueryDict官网地址12345678910111213QueryDict.__init__(query_string=None, mutable=False, encoding=None)&gt;&gt;&gt; QueryDict('a=1&amp;a=2&amp;c=3') &lt;QueryDict: &#123;'a': ['1', '2'], 'c': ['3’]&#125;&gt;通过fromkeys实例化QueryDict (1.11新增)QueryDict.fromkeys(iterable, value=”, mutable=False, encoding=None)&gt;&gt;&gt; QueryDict.fromkeys(['a', 'a', 'b'], value='val') &lt;QueryDict: &#123;'a': ['val', 'val'], 'b': ['val']&#125;&gt;# 除了GET POST请求发送的数据，都会存于request.body()中request.body获取的数据，可以使用QueryDict 转换数据 完成用户登录请求练习request方法使用，判断用户和密码实现登录1234567891011121314151617181920212223242526272829303132333435363738394041# dashboard/views.pydef login(request): if request.method == "GET": return HttpResponse("Hello world") elif request.method == "POST": username = request.POST.get("username") userpass = request.POST.get("userpass") if username == "lichangming" and userpass == "123456": msg = "登录成功" return HttpResponse(msg) else: msg = "登录失败" return HttpResponse(msg)# dashboard/urls.pyfrom django.conf.urls import url,includefrom .views import index,loginurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', login, name='login')]#使用ipython模拟POST发送数据(python36env) [1::vagrant@localhost::~]$ &gt;&gt;&gt;ipythonIn [2]: import requestsIn [3]: data = &#123;&#125;In [5]: data["username"]="lichangming" In [6]: data Out[6]: &#123;'username': 'lichangming'&#125;In [7]:data["userpass"]=123456In [8]: data Out[8]: &#123;'username': 'lichangming', 'userpass': 123456&#125;In [9]: url="http://127.0.0.1:8000/dashboard/login/" In [11]: r = requests.post(url,data) In [13]: r.status_code Out[13]: 200In [14]: r.contentOut[14]: b'\xe7\x99\xbb\xe5\xbd\x95\xe6\x88\x90\xe5\x8a\x9f'In [16]: r.content.decode("utf8")Out[16]: '登录成功' django操作数据库123python manage.py dbshell # 进入数据库python manage.py showmigrations #列出未同步的模型数据python manage.py migrate #同步数据库 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# User模型的使用, python manage.py shell 进入终端(python36env) [14::vagrant@localhost::/vagrant/devops]$ &gt;&gt;&gt;python manage.py shellPython 3.6.6 (default, Nov 1 2018, 14:42:57) Type 'copyright', 'credits' or 'license' for more informationIPython 7.1.1 -- An enhanced Interactive Python. Type '?' for help.In [1]: from django.contrib.auth.models import User In [2]: ?User.objects.create_user Signature: User.objects.create_user(username, email=None, password=None, **extra_fields)Docstring: &lt;no docstring&gt;File: ~/python36env/lib/python3.6/site-packages/django/contrib/auth/models.pyType: methodIn [3]: User.objects.create_user("lichangming", "changming@163.com", "123456") Out[3]: &lt;User: lichangming&gt;# 进入数据库，查询刚刚创建的用户(python36env) [15::vagrant@localhost::/vagrant/devops]$ &gt;&gt;&gt;python manage.py dbshellReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -AWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 35Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [devops]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || devops || mysql || performance_schema |+--------------------+4 rows in set (0.00 sec)MariaDB [devops]&gt; select * from auth_user;+----+-------------------------------------------------------------------------------+------------+--------------+-------------+------------+-----------+-------------------+----------+-----------+---------------------+| id | password | last_login | is_superuser | username | first_name | last_name | email | is_staff | is_active | date_joined |+----+-------------------------------------------------------------------------------+------------+--------------+-------------+------------+-----------+-------------------+----------+-----------+---------------------+| 1 | pbkdf2_sha256$36000$2nCUpnjFR8DS$FqMKTt2+fz2mp+d8lHvgN2JGb89SgoZ4CmAQz/H3bKw= | NULL | 0 | lichangming | | | changming@163.com | 0 | 1 | 2018-11-18 04:59:54 |+----+-------------------------------------------------------------------------------+------------+--------------+-------------+------------+-----------+-------------------+----------+-----------+---------------------+1 row in set (0.00 sec)MariaDB [devops]&gt; select * from auth_user\G;*************************** 1. row *************************** id: 1 password: pbkdf2_sha256$36000$2nCUpnjFR8DS$FqMKTt2+fz2mp+d8lHvgN2JGb89SgoZ4CmAQz/H3bKw= last_login: NULLis_superuser: 0 username: lichangming first_name: last_name: email: changming@163.com is_staff: 0 is_active: 1 date_joined: 2018-11-18 04:59:541 row in set (0.01 sec)ERROR: No query specifiedMariaDB [devops]&gt;# 创建管理员账户python manage.py shellUser.objects.create_superuser("admin", "admin@163.com", "123456")# 或者通过python manage.py 创建python manage.py create_superuser #根据提示创建管理用户# 修改密码python manage.py shell&gt;&gt;&gt; from django.contrib.auth.models import User&gt;&gt;&gt; u = User.objects.get(username='lichangming')&gt;&gt;&gt; u.set_password('sunpwd@123')&gt;&gt;&gt; u.save()# 或者python manage.pypython manage.py changepassword lichangming 小实验(用户登录)需求: 获取用户输入的用户和密码，数据库查询数据，完成登录验证操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 新建login.html页面，使用form表单提交数据&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;用户登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;ul&gt; &lt;form method="post"&gt; &lt;li&gt; &lt;span&gt;用户名： &lt;/span&gt; &lt;input type="text" name="username" /&gt; &lt;/li&gt; &lt;li&gt; &lt;span&gt;密码： &lt;/span&gt; &lt;input type="password" name="userpass" /&gt; &lt;/li&gt; &lt;li&gt; &lt;input type="submit"&gt; &lt;/li&gt; &lt;/form&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt;# 配置urlfrom django.conf.urls import url,includefrom .views import index,loginView # 注意需要导入views.py中的loginViewurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login')]# 编写views函数，查询数据库使用django 的User模块完成查询数据from django.shortcuts import renderfrom django.contrib.auth.models import Userdef loginView(request): if request.method == "POST": username = request.POST.get("username") userpass = request.POST.get("userpass") try: User.objects.get(username=username) except User.DoesNotExist: return HttpResponse("用户不存在") return render(request,"login.html") # 第二种方式使用django自带的authtication方法def loginView(request): if request.method == "POST": username = request.POST.get("username") userpass = request.POST.get("userpass") user = authenticate(request, username=username, password=userpass) if user is not None: #判断返回的用户和密码是否正确，正确返回对象，错误返回失败 login(request, user) return HttpResponse("用户登陆成功") else: return HttpResponse("用户登陆失败") return render(request, 'login.html')]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的ConfigParser总结]]></title>
    <url>%2F2018%2F11%2F16%2FPython%E7%9A%84ConfigParser%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[python操作配置文件读取写入的ConfigParser模块python version: python3 代码如下12345678910# cat config.ini[db]db_port = 3306db_user = rootdb_host = 127.0.0.1db_pass = sun[concurrent]processor = 20thread = 10 12345678910111213141516171819202122232425262728293031323334353637# 获取配置文件定义的内容# -*- coding: utf-8 -*-# Author: LiChangMing# Time: 2018/11/16# Blog: https://MrLichangming.github.iofrom configparser import ConfigParsercf = ConfigParser() #实例化cf.read("config.ini") #读取配置文件secs = cf.sections() #获取所有sections，以列表返回 ["db","concurrent"]print("sections: ", secs, type(secs)) opts = cf.options("db") # 获取sections db下所有options，也就是keyprint("options: ", opts, type(opts))kvs = cf.items("db") # 以列表返回print("db: ", kvs, type(kvs))输出：db: [('db_port', '3306'), ('db_user', 'root'), ('db_host', '127.0.0.1'), ('db_pass', 'sun')] &lt;class 'list'&gt;#获取value，cf.get 以str返回db_host = cf.get("db", "db_host")db_port = cf.get("db", "db_port") db_user = cf.get("db", "db_user")db_pass = cf.get("db", "db_pass")print("db_host: ", db_host, type(db_host))print("db_port: ", db_port)print("db_user: ", db_user)print("db_pass: ", db_pass)# 获取value,cf.getint 以int类型返回数据concurrent_processor = cf.getint("concurrent", "processor")concurrent_thread = cf.getint("concurrent", "thread")print("conncurrent_processor; ", concurrent_processor, type(concurrent_processor))print("conncurrent_thread: ", concurrent_thread, type(concurrent_thread)) 123456789101112131415161718192021222324252627282930313233# ConfigParser的修改操作# cat config2.ini[hexo]url = https://localhost:4000user = guest2pass = guestpwd@123# modify# -*- coding: utf-8 -*-# Author: LiChangMing# Time: 2018/11/16# Blog: https://MrLichangming.github.iofrom configparser import ConfigParserimport oscf = ConfigParser()# modify cf, be sure to read!cf.read("config2.ini")cf.set("hexo", "user", "changming")cf.set("hexo", "pass", "king@pwd@123")# write filewith open("config2.ini", "w+") as f: cf.write(f) f.close()结果:[hexo]url = https://localhost:4000user = changmingpass = king@pwd@123 ConfigParser写入操作12345678910111213141516171819202122232425# -*- coding: utf-8 -*-# Author: LiChangMing# Time: 2018/11/16# Blog: https://MrLichangming.github.iofrom configparser import ConfigParserimport oscf = ConfigParser()# add section / set option &amp; valuecf.add_section("myblog")cf.set("myblog", "url", "https://localhost:4000")cf.set("myblog", "user", "guest")cf.set("myblog", "pass", "testpwd@123")# write to filewith open("config2.ini", "w+") as f: cf.write(f) f.close()查看内容[myblog]url = https://localhost:4000user = guestpass = testpwd@123]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python的ConfigParser</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的argparse总结]]></title>
    <url>%2F2018%2F11%2F16%2Fpython%E7%9A%84argparse%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[argparse是python内置的一个用于命令选项与参数解析的模块argparse 将会从 sys.argv 中解析出这些参数，并自动生成帮助和使用信息 使用python3操作 参考博客地址 argparse使用 创建ArgumentParser()对象 调用add_argument()方法添加参数 使用parse_args()解析添加的参数12345678910111213# cat python_argparse.py# -*- coding: utf-8 -*-import argparseparser = argparse.ArgumentParser()parser.add_argument("value", type=int, help="显示输出的值")args = parser.parser_args()print(args.value)# 执行python python_argparse.py 100100 以上定义的参数value称为定位参数，必须输入value值，并且是数字类型 可选参数定义12345678910111213141516# -*- coding: utf-8 -*-import argparseparser = argparse.ArgumentParser()parser.add_argument("--square", help="display a square of a given number", type=int)parser.add_argument("--cubic", help="display a cubic of a given number", type=int)args = parser.parse_args()if args.square: print args.square**2if args.cubic: print args.cubic**3 12345678# 执行python python_argparse.py --square 864python python_argparse.py --cubic 28(python36env) [25::vagrant@localhost::/vagrant/practice]$ &gt;&gt;&gt;python python_argparse.py --cubic 28]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python的argparse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python脚本积累1]]></title>
    <url>%2F2018%2F11%2F15%2Fpython%E8%84%9A%E6%9C%AC%E7%A7%AF%E7%B4%AF1%2F</url>
    <content type="text"><![CDATA[总结下工作中写过的python脚本以下脚本内容，主要控制容器服务的启动和停止，采用多线程，并发执行 脚本思路展示 定义变量文件，key=value格式，使用python自带的文件读取模块，读取所有行，以=号分割存储为字典格式 使用os.popen执行linux的bash命令，并获取结果，os.popen(‘hostname’).read().strip() 使用re模块，匹配内容 123456789value = "HTTP/1.1 200 OKServer: nginx/1.15.5Date: Thu, 15 Nov 2018 12:43:43 GMTContent-Type: text/html; charset=utf-8Connection: keep-alive"findPattern = re.compile(r'200') result = findPattern.findall(value) 使用sys模块，获取参数 sys.argc[1] len(sys.argv) 使用python3的threading123for num in range(2, len(sys.argv)): threads = threading.Thread(target=controlService().stop, args=[sys.argv[num]]) threads.start() 脚本内容123456789101112# appServiceControl.conf# Decription: 控制各主机容器服务启停，定义的变量# 变量内容根据脚本主要定义: 1. 项目,获取项目值进入容器 2. 反注册dubbo的url请求 3. check监测tomcat的状态url请求# 基础变量project=app#反注册dubbo的url请求tomcat_dubbo_off=curl -s http://localhost:8080/destroy/serviceStop | grep success# tomcat的check请求app-service=/lt-service/health/check.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#!/usr/bin/env python3#coding: utf-8# python_version : 3.5.3# __author__ == "Sun"#Description: a主机控制容器中的tomcat服务 启动 停止import os,sys,re,time,threadingclass controlService: env_file = os.path.join(os.getcwd(),"appServiceControl.conf") hostname = os.popen('hostname').read() def get_env(self, key): #读取变量文件，转换成python字典 env_dict = &#123;&#125; if os.path.exists(self.env_file): with open(self.env_file) as f: for line in f.readlines(): line = line.strip("\n") if len(line) != 0 and not line.startswith('#'): k = line.split("=")[0] v = line.split("=")[1] env_dict[k] = v if env_dict.__contains__(key): return env_dict.get(key) else: result = self.env_file + "未定义此变量" + key return result else: result = self.env_file + "变量文件不存在" return result def getContainerName(self, app): #获取容器名 project = self.get_env('project') containerName = os.popen('docker ps --format "&#123;&#123;.Names&#125;&#125;" --filter name=' + project + '-' + app + "." + self.hostname).read().strip() return containerName def get_check(self, app): #停止服务后，进行check请求，确认服务是否停止 check_url = "curl -s -I http://" + self.get_env('project') + "-" + app + "." + self.hostname + ":8080" + self.get_env(app) container_name = self.getContainerName(app) response = os.popen("docker exec " + container_name + ' ' + check_url).read() statusCode = re.compile(r'200') result = statusCode.findall(response) if result: return True else: return False def stop(self, *apps): # 停止服务 for app in apps: container_name = self.getContainerName(app) app_dubbo_off = app + "_dubbo_off" dubbo_off = self.get_env(app_dubbo_off) print("反注册dubbo服务-------" + app) os.system("docker exec " + container_name + ' ' + dubbo_off) check_value = self.get_check(app) if not check_value: result = "反注册dubbo成功，check状态码为非200,开始执行stop" #调试信息 print(result) os.system("docker exec " + container_name + ' ' + 'stop.sh') print("休眠20秒，进行check监测是否停止服务") time.sleep(20) check_info = self.get_check(app) if not check_info: result = "服务已停止 " print(result + app) return result else: return_info = os.popen("docker exec " + container_name + ' ' + "status.sh").read().strip() print("反注册dubbo服务失败" + '--服务状态信息----' + return_info ) def start(self, *apps): #启动服务 for app in apps: print("监测服务是否是停止状态-check-----" + app) check_value = self.get_check(app) if check_value: print("服务已是运行状态 !!...... " + app) return False else: container_name = self.getContainerName(app) print("启动服务---" + app) os.system('docker exec ' + container_name + ' ' + 'start.sh') print("休眠20秒，开始进行check监测启动是否成功-----------" + app) time.sleep(20) check_value = self.get_check(app) if check_value: result = app + "服务已启动，check状态码为200" print(result) return result else: result = app + "服务启动失败，请手动查看日志" print(result) return resultif __name__ == "__main__": try: parameter = sys.argv[1] except IndexError: print("检查参数是否正确") else: if parameter == "stop": for num in range(2, len(sys.argv)): threads = threading.Thread(target=controlService().stop, args=[sys.argv[num]]) threads.start() # controlService().stop(sys.argv[num]) elif parameter == "start": for num in range(2,len(sys.argv)): threads = threading.Thread(target=controlService().start, args=[sys.argv[num]]) threads.start() # controlService().start(sys.argv[num])]]></content>
      <categories>
        <category>python实践</category>
      </categories>
      <tags>
        <tag>python脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习(一)搭建开发环境]]></title>
    <url>%2F2018%2F11%2F15%2Fpython%E5%AD%A6%E4%B9%A0-%E4%B8%80-%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[学习来源： 51Reboot学院搞运维，不管写python脚本，还是python的项目，都希望在linux环境中调试代码所以使用，以下方式搭建自己的本地开发环境使用vagrant+virtualbox+pycharm 安装软件OS: windows software: vagrant virtualboxvagrant和virtualbox直接google搜索下载即可， vagrant使用 下载vagrant的centos7镜像centos-7.2镜像下载地址 下载完后，在windows，创建目录D:\studyProject\51Reboot\vagrant CMD进入终端，使用以下命令进行初始化镜像,从而启动虚拟机1234# 格式 vagrant box add 初始化名称 镜像vagrant box add centos-7.2 vagrant-centos-7.2.box # 在目录下需要存在镜像vagrant init centos-7.2 # 进行初始化vagrant box list #初始化完后，可以查看当前主机模板 初始化完镜像后，会在当前路径下生成Vagrantfile文件，修改此文件修改： 将本地的8000端口转到虚拟机中8000端口 1234567vagrant up #启动刚刚初始化的虚拟机vagrant ssh #可以直接进入linux主机中vagrant halt #关闭虚拟机vagrant suspend #暂停虚拟机vagrant resume #恢复虚拟机vagrant destroy #删除虚拟机 可以使用xshell链接:123456IP： 127.0.0.1Port: 2222User: vagrantpassword: vagrant# 切换到root用户，直接sudo -s即可！ 使用vagrant启动的虚拟机，会把本地宿主机的目录映射到虚拟机中cd /vagrant 可以看到，就是宿主机的目录 在虚拟机中安装python12345678wget https://www.python.org/ftp/python/3.6.6/Python-3.6.6.tgz# 安装依赖包yum install openssl-devel readline-devel unzip -y# 编译安装./configure --prefix=/usr/local/python36make &amp;&amp; make install 创建虚拟环境创建虚拟环境，有利于项目的迁移，那些依赖包，可以直接将venv目录拷走即可12345678910#普通用户执行sudo /usr/local/python36/bin/pip3 install virtualenv# 创建虚拟环境/usr/local/python36/bin/virtualenv ./python36env# 虚拟环境生效source ./python36env/bin/activate# 在虚拟环境中安装djangopip install "django&gt;=1.11,&lt;2.0" 安装数据库123456789101112131415161718192021222324252627# 在虚拟机中安装mariadbsudo yum -y install mariadb mariadb-server mariadb-devel#修改mariadb配置文件# sudo vim /etc/my.cnf[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemddefault-storage-engine=innodb #添加此内容 --startinnodb_file_per_tablecollation-server=utf8_general_ciinit-connect='SET NAMES utf8'character-set-server=utf8 # --stop[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid## include all files from the config directory#!includedir /etc/my.cnf.d 12345678910# 启动mariadb服务sudo systemctl start mariadbsudo systemctl enable mariadb# 初始化数据库mysql_secure_installation#创建数据库mysql -u root -p #登录数据库create database devops CHARACTER SET utf8; 12# 在python的虚拟环境中安装mysqlclientpip3 install mysqlclient 启动django项目在虚拟机中，进入/vagrant 目录执行以下命令，初始化一个django项目1django-admin startproject devops #启动django项目 windows配置pycharm打开远端项目打开pycharm，点击file ==&gt; settings ==&gt; project Interpreter在右侧project Interpreter 的齿轮标记 点击 Add… 左侧选择 Vagrant目录一定要选择本地的vagrant目录 配置django的数据库123456789101112131415# 在devops目录# settings文件DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'devops', 'USER': 'root', 'PASSWORD': '123456', 'HOST': '127.0.0.1', 'PORT': '3306', 'OPTIONS': &#123; 'init_command': 'SET default_storage_engine=INNODB;', &#125;, &#125;&#125; 运行django在虚拟机中执行命令运行123source python36env/bin/activate #在宿主目录执行cd devopspython manage.py runserver 0.0.0.0:8000 #浏览器访问1http://127.0.0.1:8000 #Vagrantfile 文件中设置了本机的8000端口转发到linux虚拟机8000 pycharm运行：点击manage.py ，在if name == “main__”: 区域，左边有播放按钮，点击，即可运行django项目 配置run参数 在pycharm的Terminal 也可以输入vagrant ssh进入linux主机进行操作! 使用vagrant注意:电脑关机，下次需要通过在cmd终端，进入Vagrantfile文件当前路径，输入vagrant up启动虚拟机，会把当前的目录挂载到虚拟机中去。]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty添加nginx_dynamic_upstream模块]]></title>
    <url>%2F2018%2F11%2F12%2Fopenresty%E6%B7%BB%E5%8A%A0nginx-dynamic-upstream%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[openresty version : 1.13.6.2编译nginx添加nginx_dynamic_upstream模块，提供api接口，动态控制后端upstream的server上下线 模块下载地址nginx_dynamic_upstream github 地址 聊聊编译的那些事 openresty 1.13.6.2封装的nginx也是1.13.6 添加第三方模块，只需要重新编译openresty即可，添加编译参数 –add-module=/usr/local/src/nginx_dynamic_upstream 编译完后，使用nginx -V 查看是否正确安装nginx_dynamic_upstream模块 nginx_dynamic_upstream接口使用说明文档配置12345678910111213141516171819202122# nginx.confupstream backends &#123; zone zone_for_backends 1m; #zone_for_必选项，后接 upstream的name server 127.0.0.1:6001; server 127.0.0.1:6002; server 127.0.0.1:6003;&#125;server &#123; listen 6000; location /dynamic &#123; allow 127.0.0.1; deny all; dynamic_upstream; &#125; location / &#123; proxy_pass http://backends; &#125;&#125; API指定upstream name列出所有的server12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends" # curl后的url 必须使用双引号server 127.0.0.1:6001;server 127.0.0.1:6002;server 127.0.0.1:6003; 指定upstream name列出所有server的详细信息12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;verbose="server 127.0.0.1:6001 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6002 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6003 weight=1 max_fails=1 fail_timeout=10; 更新server参数12345678910[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;server=127.0.0.1:6003&amp;weight=10&amp;max_fails=5&amp;fail_timeout=5"server 127.0.0.1:6001 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6002 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6003 weight=10 max_fails=5 fail_timeout=5;# 支持更新的参数 weight max_fails fail_timeout 下线节点 Down12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;server=127.0.0.1:6003&amp;down="server 127.0.0.1:6001 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6002 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6003 weight=1 max_fails=1 fail_timeout=10 down; 上线节点 up12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;server=127.0.0.1:6003&amp;up="server 127.0.0.1:6001 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6002 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6003 weight=1 max_fails=1 fail_timeout=10; 添加节点 add123456[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;add=&amp;server=127.0.0.1:6004"server 127.0.0.1:6001;server 127.0.0.1:6002;server 127.0.0.1:6003;server 127.0.0.1:6004; 移除节点 remove12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;remove=&amp;server=127.0.0.1:6003"server 127.0.0.1:6001;server 127.0.0.1:6002;server 127.0.0.1:6004;]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7中设置目录的ACL规则]]></title>
    <url>%2F2018%2F11%2F02%2Fcentos7%E4%B8%AD%E8%AE%BE%E7%BD%AE%E7%9B%AE%E5%BD%95%E7%9A%84ACL%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[centos系统设置目录的ACL控制权限 获取ACL1getfacl 目录 # 查看目录的ACL规则 设置ACL1setfacl -m u:test:rw /data/data1/ #对data1目录设置允许test用户读取写入]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GlusterFS使用中的一些命令积累]]></title>
    <url>%2F2018%2F10%2F27%2FGlusterFS%E4%BD%BF%E7%94%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%91%BD%E4%BB%A4%E7%A7%AF%E7%B4%AF%2F</url>
    <content type="text"><![CDATA[记录下GlusterFS的命令 分布式文件系统GlusterFS实战，参考文档： CHEGVA博客链接 install1234yum install centos-release-glusteryum install -y glusterfs glusterfs-server glusterfs-fuse glusterfs-rdmasystemctl start glusterd.servicesystemctl enable glusterd.service configuration123456789101112131415161718192021222324252627282930313233343536373839404142# 查看glusterfs版本信息glusterfs -V# 将节点加入存储池# 节点加入防火墙的时候，需要开放防火墙端口：firewall-cmd --add-service=glusterfsgluster peer probe lg1gluster peer probe lg2# 创建volume , 复制几份replica后的数字就是几 分布式复制模式gluster volume create test replica 2 transport tcp lg1:/var/test/data lg2:/var/test/data lg3:/var/test/data lg4:/var/test/data # 查看刚才创建卷gluster volume info#启动刚才创建的卷组 gluster volume start test #查看各节点状态gluster peer status ``` # gluster 性能调优：开启 指定 volume 的配额： (test 为 volume 名称)```bashgluster volume quota test enable限制 test 中 / (既总目录) 最大使用 80GB 空间gluster volume quota test limit-usage / 80GB# 设置 cache 4GBgluster volume set test performance.cache-size 4GB# 开启 异步 ， 后台操作gluster volume set test performance.flush-behind on# 设置 io 线程 32gluster volume set test performance.io-thread-count 32# 设置 回写 (写数据时间，先写入缓存内，再写入硬盘)gluster volume set test performance.write-behind on Mounts1mount -t glusterfs 127.0.0.1:test /var/data]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>GlusterFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty中lua代码调试日志]]></title>
    <url>%2F2018%2F10%2F27%2Fopenresty%E4%B8%ADlua%E4%BB%A3%E7%A0%81%E8%B0%83%E8%AF%95%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[openresty中，如何使用了lua代码，调试信息输出到log中 1ngx.log(ngx.ERR,"判断一个变量的值: ---", value) #输出value的值到错误日志中]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客美化添加live2d]]></title>
    <url>%2F2018%2F10%2F24%2Fhexo%E5%8D%9A%E5%AE%A2%E7%BE%8E%E5%8C%96%E6%B7%BB%E5%8A%A0live2d%2F</url>
    <content type="text"><![CDATA[hexo添加live2d的使用 live2d-github地址 使用说明文档安装插件 在hexo的根目录下执行 1npm install --save hexo-helper-live2d 安装完插件后，可以安装喜欢的模型模型名称:模型展示图 live2d-widget-model-chitose live2d-widget-model-epsilon2_1 live2d-widget-model-gf live2d-widget-model-haru live2d-widget-model-haruto live2d-widget-model-hibiki live2d-widget-model-hijiki live2d-widget-model-izumi live2d-widget-model-koharu live2d-widget-model-miku live2d-widget-model-ni-j live2d-widget-model-nico live2d-widget-model-nietzsche live2d-widget-model-nipsilon live2d-widget-model-nito live2d-widget-model-shizuku live2d-widget-model-tororo live2d-widget-model-tsumiki live2d-widget-model-unitychan live2d-widget-model-wanko live2d-widget-model-z16 本人安装的是live2d-widget-model-haruto1npm install live2d-widget-model-haruto 配置使用 在hexo的根目录创建名为live2d_models的文件夹 把之前安装的模型文件夹从node_modules文件夹复制到live2d_models中 比如我这里安装的是live2d-widget-model-haruto 从hexo的根目录的node_modules中找到这个文件夹，复制到live2d_models文件夹中 在hexo根目录下的_config.yml中的最后面添加以下内容12345678910111213141516live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-haruto display: position: right width: 150 height: 300 mobile: show: true]]></content>
      <categories>
        <category>hexo美化</category>
      </categories>
      <tags>
        <tag>hexo添加看板图片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty的lua语法学习一]]></title>
    <url>%2F2018%2F10%2F24%2Fopenresty%E7%9A%84lua%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[openresty的lua语法学习 lua的popen获取命令的执行结果 1234567891011121314151617181920212223242526272829-- 打开文件local myfile = io.popen("pwd", "r")if nil == myfile then print("open file for dir fail!!")endprint("\n=========command dir result:")-- 读取文件内容for cnt in myfile:lines() do print(cnt)end-- 关闭文件myfile:close()local secondfile = io.popen("ifconfig")if nil == secondfile then print("open file for ifconfig fail!!")endprint("\n==========command ifconfig result:")-- 读取文件内容local content = secondfile:read("*a")print(content)-- 关闭文件secondfile:close() openresty调用lua脚本通过openresty的web服务提供一个接口，执行系统脚本，停止某个服务，并返回结果 1234567891011121314151617# 调用 http://192.168.1.12/testapi?value=stoplocation = /testapi &#123; default_type &apos;text/plain&apos;; content_by_lua_block &#123; local value = ngx.var.arg_value if value ~= nil then local command = &quot;/usr/bin/bash /usr/local/src/stopService.sh &quot;..value local handle = io.popen(command) local result = handle:read(&quot;*a&quot;) handle:close() ngx.say(result) ngx.exit(200) else ngx.exit(404) end &#125;&#125;]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的server_name正则表达式匹配]]></title>
    <url>%2F2018%2F10%2F23%2Fnginx%E7%9A%84server-name%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[nginx的server_name 匹配正则 参考文档链接: Nginx技巧:灵活的server_name server_name如果使用了正则，优先级匹配 精确匹配server_name 1234server &#123; listen 80; server_name test1.com test2.com;&#125; 以* 通配符开始的字符串 1234server &#123; listen 80; server_name *.test.com;&#125; 以*通配符结束的字符串 1234server &#123; listen 80; server_name www.*;&#125; 匹配正则 1234server &#123; listen 80; server_name ~^api(?.+)\.test\.com #匹配api*.test.com *代表所有&#125;]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的json模块]]></title>
    <url>%2F2018%2F10%2F21%2Fpython%E7%9A%84json%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[python的json模块笔记 1import json json.dumps: 将Python对象编码成JSON字符串json.loads: 将已编码的JSON字符串解码为Python对象]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose文件对应docker版本号]]></title>
    <url>%2F2018%2F10%2F15%2Fdocker-compose%E6%96%87%E4%BB%B6%E5%AF%B9%E5%BA%94docker%E7%89%88%E6%9C%AC%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[docker-compose 文件格式版本对应docker版本 docker-compose github地址 Compose file format compatibility matrix Compose file format Docker Engine 1 1.9.0+ 2.0 1.10.0+ 2.1 1.12.0+ 2.2, 3.0, 3.1, 3.2 1.13.0+ 2.3, 3.3, 3.4, 3.5 17.06.0+ 2.4 17.12.0+ 3.6 18.02.0+ 3.7 18.06.0+]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell匹配数字]]></title>
    <url>%2F2018%2F10%2F15%2Fshell%E5%8C%B9%E9%85%8D%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[使用bash匹配数字1234567str="1222"if [[ $str =~ ^[0-9]+$ ]];then echo "True"else echo "False"fi]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[获取registry私有仓库的镜像信息]]></title>
    <url>%2F2018%2F10%2F14%2F%E8%8E%B7%E5%8F%96registry%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E7%9A%84%E9%95%9C%E5%83%8F%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[docker官方registry镜像的一些操作命令 获取registry的镜像1curl -X GET http://&#123;IP_Address&#125;:5000/v2/_catalog 获取镜像的标签列表1curl -X GET http://&#123;IP_Address&#125;:5000/v2/&#123;镜像名&#125;/tags/list]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>registry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker命令总结]]></title>
    <url>%2F2018%2F10%2F12%2Fdocker%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[docker命令总结 docker操作镜像命令导出镜像1docker save -o centos7.tar centos 导入本地镜像1docker load --input centos7.tar docker获取容器名12# docker ps获取容器完整名称docker ps --format '&#123;&#123;.Names&#125;&#125;' --filter name=匹配的关键字 获取本机容器名称1docker ps --format &#123;&#123;.Names&#125;&#125; 获取容器ID1docker ps -q]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker遇到的问题总结]]></title>
    <url>%2F2018%2F10%2F12%2Fdocker%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[总结在工作中，线上使用docker遇到的问题总结 swarm集群相关问题Error response from daemon: context deadline exceededQ: docker swarm集群中节点未离开集群，异常重启机器，删除节点，再次加入提示，已在集群中，docker swarm leave -f提示以下信息1Error response from daemon: context deadline exceeded A: 解决办法 删除/var/lib/docker/swarm目录 systemctl restart docker 重启docker服务 加入集群参考链接: docker swarm leave in daemon error response]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>docker问题总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看证书有效期bash命令]]></title>
    <url>%2F2018%2F10%2F11%2F%E6%9F%A5%E7%9C%8B%E8%AF%81%E4%B9%A6%E6%9C%89%E6%95%88%E6%9C%9Fbash%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[openssl查看证书有效期 123456# 找到证书的CERTIFICATE文件openssl x509 -in cert1.pem -noout -dates#输出结果notBefore=Sep 20 05:07:48 2018 GMTnotAfter=Dec 19 05:07:48 2018 GMT]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>openssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7挂载windows共享文件夹]]></title>
    <url>%2F2018%2F10%2F11%2FCentos7%E7%9A%84mount%E6%8C%82%E8%BD%BDwindows%E7%9A%84%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[记录一下linux系统挂载windows共享文件夹 挂载windows的共享文件夹: 1mount -t cifs -o username="administrator",password="testPWD" //192.168.1.2/software /mnt/share 永久挂载 123vim /etc/fstab #编辑fstab文件,新增以下内容//192.168.1.2/software /mnt/share cifs auto,username="administrator",password="testPWD" 0 0]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>fstab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7编译安装python3，进入python终端不能使用退格和上下键翻动]]></title>
    <url>%2F2018%2F10%2F09%2Fcentos7%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85python3%EF%BC%8C%E8%BF%9B%E5%85%A5python%E7%BB%88%E7%AB%AF%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E9%80%80%E6%A0%BC%E5%92%8C%E4%B8%8A%E4%B8%8B%E9%94%AE%E7%BF%BB%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[编译安装的python3，进入终端不能使用退格，和上下翻键 解决办法: 1yum -y install readline-devel.* 安装以上依赖包，重新编译安装python3即可！]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vsftpd中umask数字的含义]]></title>
    <url>%2F2018%2F10%2F09%2Fvsftpd%E4%B8%ADumask%E6%95%B0%E5%AD%97%E7%9A%84%E5%90%AB%E4%B9%89%2F</url>
    <content type="text"><![CDATA[之前一直搞不懂vsftpd服务中，local_umask 设置的数值有什么含义，特此记录下所知，所得 参考链接：csdn博客:vsftpd中umask值的介绍及计算 个人总结如下:local_umask: 设置本地用户的上传文件或者目录的权限anon_umask: 设置匿名用户上传的文件或者目录的权限 文件或者目录的权限： 读取： 4 写入： 2 执行： 1 文件最高权限为666目录最高权限为777 local_umask=022 # 022 如果是文件，最高权限为666,022代表从666权限中抽走的权限，剩下644]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>vsftpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisord提示refused connection]]></title>
    <url>%2F2018%2F10%2F09%2Fsupervisord%E6%8F%90%E7%A4%BArefused-connection%2F</url>
    <content type="text"><![CDATA[记录下在工作中，遇到docker容器的supervisord提示 refused connection 错误提示:123[root@sun-host ~]# supervisorctl statusunix:///var/run/supervisor.sock refused connection 问题追溯： 灵感获知：overlayfs不适用于unix域套接字 docker在使用overlayfs时，unix域套接字似乎不起作用，当我使用设备映射器，将/var/run挂载到容器中/var/run，这时supervisord创建的sockt文件，写入挂载的目录 /var/run/supervisor.sock 使用命令supervisorctl status查看的时候，就不再提示此错误了。 可是为了不挂载此路径，再继续翻阅技术文档，完美的解决办法就是修改docker默认的存储驱动 123456789vim /etc/docker/daemon.json #添加以下内容&#123; "storage-driver": "devicemapper" &#125;# 停止docker服务# 删除以前创建的容器数据，rm -rf /var/lib/docker/*# 启动docker服务# 使用docker info可以查看 Storage Driver的类型，默认是overlay]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>supervisord</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看linux系统CPU相关信息]]></title>
    <url>%2F2018%2F10%2F08%2F%E6%9F%A5%E7%9C%8Blinux%E7%B3%BB%E7%BB%9FCPU%E7%9B%B8%E5%85%B3%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[文档说明: 查看linux系统CPU， 物理个数 逻辑个数 单个CPU的核心数 查看物理CPU个数cat /proc/cpuinfo | grep “pysical id” | sort | uniq | wc -l 查看单个CPU的核心数cat /proc/cpuinfo | grep “cpu cores” | uniq 查看逻辑CPU的个数cat /proc/cpuinfo | grep “processor” | wc -l 物理CPU:很好理解，实际服务器插槽上的cpu个数 逻辑CPU:CPU使用超线程技术，在逻辑上在分一倍数量的cpu core出来1逻辑cpu = 物理cpu * 单个cpu核心数 * 2 CPU核心数： 官方话： 一块CPU上面能处理数据的芯片组的数量]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo Next主題给文章加密]]></title>
    <url>%2F2018%2F10%2F05%2Fhexo-Next%E4%B8%BB%E9%A1%8C%E7%BB%99%E6%96%87%E7%AB%A0%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[hexo 文章加密 插件: hexo-blog-encrypt 参考链接地址https://github.com/MikeCoder/hexo-blog-encrypt/blob/master/ReadMe.zh.md 效果展示:]]></content>
      <categories>
        <category>hexo博客配置与优化</category>
      </categories>
      <tags>
        <tag>hexo_Next主题文章加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux用户管理]]></title>
    <url>%2F2018%2F10%2F05%2Flinux%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[向组中添加用户：1usermod -G groupname username]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>linux用户</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安裝google身份认证]]></title>
    <url>%2F2018%2F10%2F05%2FCentos7%E5%AE%89%E8%A3%9Dgoogle%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[记录在Centos7上安装Google身份认证 安装epel源1yum -y install epel-release Qrencode1yum install -y qrencode # 谷歌身份验证器通过该程序生成二维码 安装google身份验证器1234567891011git clone https://github.com/google/google-authenticator-libpam.gitcd google-authenticator-libpam./bootstrap.sh./configure –prefix=/usr/local/google-authenticator# 编译时如果提示一下错误configure: error: Unable to find the PAM library or the PAM header files# 安装pam-devle库yum -y instlal pam-devel# 再次执行./configuremake &amp;&amp; make install 拷贝google的身份验证器pam模块到系统下1cp /usr/local/google-authenticator/lib/security/pam_google_authenticator.so /lib64/security/ 配置sshd的pam认证123vim /etc/pam.d/sshd# 写在auth include password-auth 基于密码认证的上面一行,先基于google验证码认证auth required pam_google_authenticator.so 修改ssh服务配置123vim /etc/ssh/sshd_configChallengeResponseAuthentication yes 重启ssh服务配置1systemctl restart sshd 开始生成google认证码1234# 进入刚才克隆下来的 google-authenticator-libpam 目录，执行./google-authenticator #基于当前用户做验证，如果切换别的系统用户，请登陆其他用户，执行此命令即可Do you want authentication tokens to be time-based (y/n) y #输入y， 提示是否基于时间的认证# 接下来会生成一张二维码图片： 手机上下载身份验证器app软件，扫描此二维码 1234567891011121314151617181920212223242526272829303132333435Your new secret key is: JS57SLVUDEEA7SQ7LD6BEBWGAA #此安全key需要备份，用于后续更换手机或者二维码丢失，浏览器的身份验证丢失后，通过此安全key获取新的验证吗 Your verification code is 005421 #扫描上述二维码后，查看验证吗，输入Your emergency scratch codes are:# 以下验证吗，是后续备用的，只能验证一次4541236521522365851246328512463114785216 Do you want me to update your “/root/.google_authenticator” file (y/n) y Do you want to disallow multiple uses of the same authenticationtoken? This restricts you to one login about every 30s, but it increasesyour chances to notice or even prevent man-in-the-middle attacks (y/n) Do you want to disallow multiple uses of the same authenticationtoken? This restricts you to one login about every 30s, but it increasesyour chances to notice or even prevent man-in-the-middle attacks (y/n) y By default, tokens are good for 30 seconds. In order to compensate forpossible time-skew between the client and the server, we allow an extratoken before and after the current time. If you experience problems withpoor time synchronization, you can increase the window from its defaultsize of +-1min (window size of 3) to about +-4min (window size of17 acceptable tokens).Do you want to do so? (y/n) y# 安全相关，默认继续 If the computer that you are logging into isn’t hardened against brute-forcelogin attempts, you can enable rate-limiting for the authentication module.By default, this limits attackers to no more than 3 login attempts every 30s.Do you want to enable rate-limiting (y/n) y# 安全相关，默认继续 使用xshell连接xshell终端的连接方式改为：keyboard Interactive 输入验证码： 输入密码：]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>Google身份认证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python正则表达式]]></title>
    <url>%2F2018%2F10%2F04%2Fpython%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[python正则表达式 python获取字符串中的数字 123456import retestStr = "100abc"Number = re.sub("\D", "", testStr)print Number100]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>pyton</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows编辑的文件上传linux显示^M问题]]></title>
    <url>%2F2018%2F10%2F02%2Fwindows%E7%BC%96%E8%BE%91%E7%9A%84%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0linux%E6%98%BE%E7%A4%BA-M%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[记录一下在windows中编辑文件上传到linux的坑 windows上编辑的文件上传到linux中，使用vim打开，会显示^M 的问题 ^M 是因为windows操作系统用的文本换行符和UNIX/Linux操作系统用的不同，Windows系统下输入的换行符在UNIX/Linux下不会显示为“换行”，而是显示为 ^M 这个符号 使用vi的替换功能替换 ^M： 使用键盘的ctrl + v ctrl + M :%s/^M//g]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>^M问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sshfs 配置使用]]></title>
    <url>%2F2018%2F09%2F30%2Fsshfs-%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[sshfs: 通过ssh挂载远程的Linux文件系统或目录 以下总结参考: sshfs配置参考文档来源 安装12yum -y install epel-releaseyum -y install sshfs 使用1234567891011# 挂载远程主机的logs到本机 allow_other参数，允许普通用户读取，如果没有，只能root用户访问sshfs -o allow_other root@192.168.1.17:/var/logs/ /var/logs/testMountLogs/#Ubuntu挂载方式sudo sshfs -o allow_other root@192.168.1.17:/var/logs/ /var/logs/testMountLogs/#基于ssh秘钥授权sshfs -o IdentityFile=~/.ssh/id_rsa root@192.168.1.17:/var/lb/logs/ /var/logs/testMountLogs/#Ubuntu挂载方式sudo sshfs -o allow_other,IdentityFile=~/.ssh/id_rsa root@192.168.1.17:/var/lb/logs/ /var/logs/testMountLogs/ 永久挂载使用12345sshfs#root@192.168.1.17:/var/lb/logs/ /var/logs/testMountLogs/ fuse.sshfs defaults 0 0 基于秘钥的挂载：sshfs#root@192.168.1.17:/var/lb/logs/ /var/logs/testMountLogs/ fuse.sshfs IdentityFile=~/.ssh/id_rsa defaults 0 0]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>sshfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grep检索出ip地址]]></title>
    <url>%2F2018%2F09%2F29%2Fgrep%E6%A3%80%E7%B4%A2%E5%87%BAip%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[grep匹配ip地址 1grep -E "([0-9]&#123;1,3&#125;[\.])&#123;3&#125;[0-9]&#123;1,3&#125;"]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose相关内容]]></title>
    <url>%2F2018%2F09%2F28%2Fdocker-compose%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[记录下工作中常用的docker-compose相关内容 开机自启动docker-compose部署的容器开机自动运行找到/etc/rc.d/rc.local文件,添加以下脚本1/usr/local/bin/docker-compose -f /usr/local/nginx/docker-compose.yml up -d]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python OS模块的学习积累]]></title>
    <url>%2F2018%2F09%2F28%2Fpython-OS%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%A7%AF%E7%B4%AF%2F</url>
    <content type="text"><![CDATA[python的学习就是不断的撸，才能对这项技能有更深入的了解 聊聊工作中用到的最基础的功能 os模块目录结构 os.walk 返回可迭代对象os.getcwd 返回当前路径 1234567891011121314151617181920212223242526272829303132333435dir = “/var/lb/apps”# 以下，输出目录下的所有文件，包括二级目录下的文件&gt;&gt;&gt; for root,subdirs,files in os.walk(dir):... print(files)... []['world.txt']['index.html'][][]['test.txt', 'test']# 以下，输出所有目录的绝对路径&gt;&gt;&gt; for root,subdirs,files in os.walk(dir):... print(root)... /var/lb/apps/var/lb/apps/pc-h5/var/lb/apps/mobile-h5/var/lb/apps/server/var/lb/apps/server/WEB-INF/var/lb/apps/server/classes以下输出所有目录，包括二级目录&gt;&gt;&gt; for root,subdirs,files in os.walk(dir):... print(subdirs)... ['pc-h5', 'mobile-h5', 'server'][][]['WEB-INF', 'classes'][][]&gt;&gt;&gt; 12345# 读取文件内容，转为Python字典格式# 文件/etc/environment 内容定义为host=devops1file=testapps=tensorflow 1234567891011121314151617#将以上内容转为字典#!/usr/bin/env python#coding: utf-8import osenv_file = "/etc/environment"def get_env_dict(env_file): env_dict = &#123;&#125; if os.path.exists(env_file): with open(env_file) as f: for line in f.readlines(): line = line.strip("\n") if len(line) != 0 and not line.startswith('#'): k = line.split("=")[0] v = line.split("=")[1] env_dict[k] = v return env_dict]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx缓存静态资源proxy_cache的一些指令的含义]]></title>
    <url>%2F2018%2F09%2F28%2Fnginx%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[记录nginx的缓存proxy_cache的指令的含义 proxy_cache相关的指令proxy_cache_path : 设置缓存路径/tmp/proxy_cache levels=1:2，表示第一级目录1个字符，第2级目录两个字符。 keys_zone=cache_www:100m表示这个zone的名字叫cache_www，分配内存的大小为100MB。inactive表示如果这个资源在inactive规定的时间内没有被访问到就会被删除。max_size表示这个zone可以使用的硬盘空间。 add_header ： 在给客户端的返回中，增加名为X-Cache-Status的header，其值是缓存命中情况，比如MISS，HIT等等。 proxy_cache ： 设置缓存资源的zone proxy_cache_key ： 设置缓存文件中的key，硬盘中缓存文件的名字key值的MD5。譬如key是test.xnow.me/，则在硬盘上的md5值是c9d71dc81143d6d9a60165bdcb1b9c9f，计算方法： echo -n “test.xnow.me/“ | md5sum proxy_cache_valid 200 304 301 302 10d： 设置缓存的状态码，把返回状态是200和304的请求缓存起来。缓存时间是60分钟，过了缓存时间之后，设置缓存状态为EXPIRED，这是绝对时间，和上次更新时间相比。10d代表缓存的时间，为10天proxy_cache_use_stale 返回码出错的时候，使用缓存数据。譬如出现超时，502和503等等情况 Example配置nginx的缓存，通过两个指令控制：proxy_cache_pathproxy_cache 12345678910111213141516proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;server &#123;...location / &#123;proxy_cache my_cache;proxy_cache_lock on;proxy_cache_key $uri$is_args$args # $uri: 请求的URI，可能和最初的值不同，比如经过重定向之类的 # $is_args: 请求行中是否匹配参数，如果有参数返回?,没有返回空字符串 # args: 请求中的参数proxy_cache_valid 200 304 10d;proxy_pass http://my_upstream;expires 7d;&#125;&#125; 注释：proxy_cache_path：/path/to/cache 设置缓存文件的存放路径 levels=1:2 设置缓存文件存放目录层级结构，1:2表示第一级目录一个字符，第二级目录2个字符，这样存放的目的，提高文件的读取速度，默认会存放于一个目录中key_zone=my_cache:10m 共享内存区的名称，用于存储缓存键和元数据，设置空间大小10MBmax_size=10g 设置缓存的上限大小，默认允许缓存不断增长，直到用尽可用的磁盘空间inactive=60m 指定在内存中的缓存文件，在60分钟内没有被访问，就会自动删除use_temp_path=off 关闭临时存储区域，开启状态，会把一个写入缓存的文件，先放入一个临时存储区域，建议关闭，可以避免文件系统中不必要的数据拷贝 在location中 使用proxy_cache 共享内存区名称 ，启用匹配location的内容进行缓存 缓存优化参数：proxy_cache_lock on 启用此配置，如果请求到没有存在缓存中的文件时，将只有第一个请求去源服务器获取内容，后续请求从缓存中获取数据。 清除缓存模块ngx_cache_purge说起nginx缓存模块，必须要知道proxy_cache_key设置的nginx的内置变量获取的是什么内容,贴一张图Nginx内置绑定变量 安装此模块，下载模块到本地，只需要重新编译nginx，添加参数–add-module=/usr/local/src/ngx_cache_purge即可 使用ngx_cache_purge12345678#配置# 静态资源清除，在nginx的配置文件添加 location ~ /__purge(/.*) &#123; proxy_cache_purge cache_one $1$is_args$args; #这个是根据我上述proxy_cache_key设置的缓存key进行清除 &#125;# 使用# 浏览器访问此接口，后面加上清除的单个静态资源文件即可]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx_proxy_cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置健康监测中指令的含义]]></title>
    <url>%2F2018%2F09%2F28%2Fnginx%E9%85%8D%E7%BD%AE%E5%81%A5%E5%BA%B7%E7%9B%91%E6%B5%8B%E4%B8%AD%E6%8C%87%E4%BB%A4%E7%9A%84%E5%90%AB%E4%B9%89%2F</url>
    <content type="text"><![CDATA[记录在nginx的upstream后端健康监测配置中，各指令的含义 比较常见的配置方式12345678910upstream backend1 &#123; sticky; server 192.168.0.125:8080 max_fails=1 fail_timeout=10s weight=1; server 192.168.0.126:8080 max_fails=1 fail_timeout=10s weight=1; server 192.168.0.127:8080 max_fails=1 fail_timeout=10s weight=1; keepalive 16; check interval=3000 rise=1 fall=3 timeout=2000 type=http; check_http_send "HEAD hall/health/check.html HTTP/1.0\r\nUser-Agent:check\r\n\r\n"; check_http_expect_alive http_2xx http_3xx;&#125; 以上配置，采用http的方式，对后端tomcat的做健康监测，通过tomcat中提供的check.html接口返回的状态，判断tomcat是否存活。 指令的各含义 interval: 向后端发送的健康检查包的间隔fall: 如果失败次数达到定义的数，服务器就认为是downrise: 如果成功次数达到定义的数,服务器就认为是uptimout: 后端健康请求的超时时间default_down: 设定初始时服务器的状态,如果是true,就说明默认是down的，如果是false，就是up的，默认值为true，也就是一开始服务器认为是不可用的，要等健康检查包达到一定成功次数以后才会被认为是健康的type： 健康监测的类型,常见的类如下: tcp: 简单的tcp连接，如果连接成功，说明后端正常 ssl_hello: 发送一个输出的SSL hello包并接受服务器的SSL hello 包 http: 发送http请求，通过后端的回复包的状态来判断后端是否存活 mysql: 向mysql服务器连接，通过接受Cpong包来判断后端是否存活 ajp: 向后端发送AJP协议的Cping包，通过接受Cpong包来判断后端是否存活port: 指定后端服务器的检查端口.]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx中常见的一些变量]]></title>
    <url>%2F2018%2F09%2F28%2Fnginx%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[常见的日志变量 $remote_addr, $http_x_forwarded_for 记录客户端IP地址 $remote_user记录客户端用户名称 $request记录请求的URL和HTTP协议(GET,POST,DEL,等) $status记录请求状态 $body_bytes_sent发送给客户端的字节数，不包括响应头的大小； 该变量与Apache模块mod_log_config里的“%B”参数兼容。 $bytes_sent发送给客户端的总字节数。 $connection连接的序列号。 $connection_requests 当前通过一个连接获得的请求数量。 $msec 日志写入时间。单位为秒，精度是毫秒。 $pipe如果请求是通过HTTP流水线(pipelined)发送，pipe值为“p”，否则为“.”。 $http_referer 记录从哪个页面链接访问过来的 $http_user_agent记录客户端浏览器相关信息 $request_length请求的长度（包括请求行，请求头和请求正文）。 $request_time 请求处理时间，单位为秒，精度毫秒；从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止。 $time_iso8601 ISO8601标准格式下的本地时间。 $time_local通用日志格式下的本地时间]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的location配置优先级]]></title>
    <url>%2F2018%2F09%2F28%2Fnginx%E7%9A%84location%E9%85%8D%E7%BD%AE%E4%BC%98%E5%85%88%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[记录下，平常工作中容易混淆的nginx的location 优先级匹配的问题 location表达式类型~ 表示执行一个正则匹配，区分大小写~* 表示执行一个正则匹配，不区分大小写^~ 表示普通字符匹配，使用前缀匹配。如果匹配成功，则不再匹配其他location= 进行普通字符精确匹配。完全匹配 location优先级说明注意： 在nginx的location配置中，和顺序没有太大关系，相同类型的表达式，字符串长的会优先匹配 优先级排列说明: 第一优先级，等号类型，一旦匹配成功，则不再查找其他匹配项 第二优先级，^~ 类型表达式，一旦匹配成功，则不再查找其他匹配项 第三优先级，正则表达式类型(~ ~*)的优先级次之，如果有多个location的正则能匹配的话，则使用正则表达式最长的那个 第四优先级，常规字符串匹配类型，按前缀匹配]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lsyncd的配置与使用]]></title>
    <url>%2F2018%2F09%2F26%2Flsyncd%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简要说明下lsyncd的配置与使用 lsyncd： 持续监控目录下的文件，有变动，实时同步 安装环境描述: OS: centos7 12yum -y install epel-releaseyum install -y lsyncd 配置需求： 两台远程主机之间，目录同步， host1目录： /var/vm1 host2目录： /var/vm2不能加delete=true,因为，在host1的目录如果删除，会同步到host2，把host2中存在的也删除了 lsyncd.conf配置 配置参数说明lsyncd.conf配置选项说明(列出工作中常用的) settings123456789settings &#123; logfile="/var/log/lsyncd.log", #定义日志文件路径 statusFile="/var/log/lsyncd.status", #定义哪些文件发生变动的状态日志 statusInterval=5, # 将lsyncd的状态写入statusFile的间隔，默认为10秒 maxDelays=3, # 累计到多少所监控的事件激活一次同步 inotifyMode="CloseWrite or Modify", # 指定inotify监控的事件，默认CloseWrite（关闭写入操作） nodaemon=false, # 表示不启用守护模式 maxProcesses=1, # 同步进程的最大个数，执行rsync的进程数，如果设置3个进程，有20个文件同步，最大有3个rsync进程&#125; sync12345678sync &#123; default.rsyncssh, #指定同步参数，以什么模式运行 source="/var/data/", #监控的源目录 host="10.10.4.2", # 目标主机 targetdir="/var/data/", #目标目录 exclude=&#123; "*.swp","*.swx" #排除同步的文件 &#125;, rsync 参数12345678910rsync = &#123; binary = "/usr/bin/rsync", archive = true, compress = true, verbose = true, _extra = &#123;"--delete=false"&#125;, &#125;, ssh=&#123; port=22 &#125;]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>lsyncd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jumpserver部署文档]]></title>
    <url>%2F2018%2F09%2F24%2Fjumpserver%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[jumpserver部署文档 Jumpserver特点： 1）完全开源，GPL授权 2）Python编写，容易再次开发 3）实现了跳板机基本功能，身份认证、访问控制、授权、审计 、批量操作等。 4）集成了Ansible，批量命令等 5）支持WebTerminal 6）Bootstrap编写，界面美观 7）自动收集硬件信息 8）录像回放 9）命令搜索 10）实时监控 11）批量上传下载 参考官网地址，写的非常详细 jumpserver官网部署文档]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>jumpserver</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http状态码分析]]></title>
    <url>%2F2018%2F09%2F24%2Fhttp%E7%8A%B6%E6%80%81%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[以下http协议分析图片来自菜鸟教程：http协议状态码 如有侵犯，请告知，将删除。]]></content>
      <categories>
        <category>http状态码</category>
      </categories>
      <tags>
        <tag>http状态码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git操作]]></title>
    <url>%2F2018%2F09%2F21%2FGit%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[作为一名运维人员，学会使用git也是完全有必要的 #git在分支下工作 创建新分支：1git checkout -b sun #此命令，会创建新分支，并切换到新分支上 添加修改的代码文件，到当前新分支12git add 文件git commit -m “注释信息” 合并分支123git checkout master #先切换到master分支上git merge sun #合并新分支sun ，到当前的master上 合并后，删除当前分支1git branch -d sun #如果没有合并，不能删除当前分支 查看所有分支1git branch -a git add之后的撤销操作123456789101112git status #可以看到git add 中的文件git reset HEAD #对上次所有的add撤销git reset HEAD test.txt #只对上次add test.txt文件撤销git commit 之后的撤销操作git log #查看commit信息的哈希值例如：commit b262ed4528aebe2052f0c92e149e3e3fb0f7c609git reset &#123;commit后的哈希值&#125;git push 之后的撤销操作git revert HEAD 撤销前一次 commit git revert HEAD^ 撤销前前一次 commit git revert commit-id (撤销指定的版本，撤销也会作为一次提交进行保存） git revert是提交一个新的版本，将需要revert的版本的内容再反向修改回去，版本会递增，不影响之前提交的内容。 git pull 显示代码冲突的解决办法：123如果丢弃本地的更改，同步仓库的代码，使用以下方法：git reset –hardgit pull git合并冲突解决]]></content>
      <categories>
        <category>Git基本操作技能</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7部署ftp服务]]></title>
    <url>%2F2018%2F09%2F21%2FCentos7%E9%83%A8%E7%BD%B2ftp%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[在生产环境，开发需要借助ftp来上传开发程序包，特此记录下，部署vsftpd的笔记，方便后续查看 环境说明OS: Centos7.3 1511(core) 部署123yum -y install vsftpdsystemctl enable vsftpdsystemctl start vsftpd 配置采用虚拟用户，基于系统用户，实现不同用户，控制不同目录12345678910111213141516171819cp /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.bak# vim /etc/vsftpd/vsftpd.conf# 禁用匿名用户登录anonymous_enable=NO# 添加下列内容到vsftpd.conf末尾use_localtime=YESlisten_port=21chroot_local_user=YESidle_session_timeout=300guest_enable=YESguest_username=vsftpduser_config_dir=/etc/vsftpd/vconfdata_connection_timeout=1virtual_use_local_privs=YESpasv_min_port=10060pasv_max_port=10090accept_timeout=5connect_timeout=1allow_writeable_chroot=YES 建立用户文件123# vim /etc/vsftpd/virtuserstesttestpwd@123 生成用户数据文件123456789101112131415161718db_load -T -t hash -f /etc/vsftpd/virtusers /etc/vsftpd/virtusers.db #设定PAM验证文件，并指定对虚拟用户数据库文件进行读取 chmod 600 /etc/vsftpd/virtusers.db ## 修改前先备份 cp /etc/pam.d/vsftpd /etc/pam.d/vsftpd.bak# 将auth及account的所有配置行均注释掉# vi /etc/pam.d/vsftpdauth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/virtusersaccount sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/virtusers# 如果系统为32位，上面改为lib例如：![ftpd](/images/ftp-virtusers.png)## 新建系统用户useradd vsftpd -d /home/vsftpd -s /sbin/nologinchown -R vsftpd:vsftpd /home/vsftpd 建立虚拟用户个人配置文件1234567891011121314mkdir /etc/vsftpd/vconfcd /etc/vsftpd/vconftouch test ##虚拟用户是什么，这里就是什么# vim test内容如下：local_root=/data/packages/write_enable=YESanon_world_readable_only=NOanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES 防火墙配置12firewall-cmd --add-service=ftp --permanentfirewall-cmd --reload 重启vsftpd服务1systemctl restart vsftpd 需要注意刚才/data/packages这个目录的本地权限需要允许vsftpd用户，有访问权限！ 如果后续要增加用户： 例如添加test1用户1234567891011121314151617181920212223# 编辑此文件，添加虚拟用户的配置# vim /etc/vsftpd/virtusers# 追加：test1testpwd@123生成用户数据文件db_load -T -t hash -f /etc/vsftpd/virtusers /etc/vsftpd/virtusers.db# 进入此目录/etc/vsftpd/vconftouch test1# 编辑test文件vim test1# 添加以下内容:local_root=/date/test1/packages #指定上传路径write_enable=YESanon_world_readable_only=NOanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>vsftpd配置与使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker仓库Harbor的配置与使用]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker%E4%BB%93%E5%BA%93Harbor%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[有一个私有仓库来管理镜像，还是非常方便的，特此记录下部署docker Harbor的笔记 参考链接 官方文档相关链接安装和配置指南用户指南 简介 Harbor的基本功能： VMware公司最近开源了企业级Registry项目Harbor，由VMware中国研发的团队负责开发 基于角色的访问控制 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限。 镜像复制 – 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡，高可用，混合云和多云的场景。 图形化用户界面 – 用户可以通过浏览器来浏览，检索当前Docker镜像仓库，管理项目和命名空间。 AD/LDAP 支持 – Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。 审计管理 – 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。 国际化 – 已拥有英文、中文、德文、日文和俄文的本地化版本。更多的语言将会添加进来。 RESTful API – RESTful API 提供给管理员对于Harbor更多的操控, 使得与其它管理软件集成变得更容易。 部署简单 – 提供在线（online）和离线（offline）两种安装工具， 也可以安装到vSphere平台(OVA方式)虚拟设备。 官方提供的架构图 环境描述 OS : Centos7本机已经安装docker docker-compose 安装部署下载离线安装包安装包链接地址 解压包1tar xf harbor-offline-installer-v1.5.1.tgz 修改配置文件123456789101112131415# 主配置文件harbor.cfg以下修改的参数中，仓库启用了https，满足docker仓库默认pull push需要使用https，要不然需要修改docker参数添加 –insecure-register修改hostname = hub.com #这个配置，是指定docker 仓库的url地址，也就是在客户端执行 docker pull 时，需要指定的仓库地址 修改ui_url_protocol = https #指定url访问为https，默认是http， 如果这里修改成https，如果使用http访问仓库，会自动跳转到https上；修改customize_crt: on #打开表示，创建私钥和根证书，用于https链接，官方介绍:打开或关闭，默认打开）打开此属性时，准备脚本创建私钥和根证书，用于生成/验证注册表令牌。当由外部来源提供密钥和根证书时，将此属性设置为off。 ssl_cert = /data/cert/hub.com.bundle.crt #ssl证书路径，ssl_cert_key = /data/cert/hub.com.key.pem #ssl私钥文件路径 这两项，在nginx的配置中使用；会加载到nginx的配置文件中注释： https生成证书，我使用的是github上的一个生成自签名证书的脚本生成；这个脚本，使用openssl注册自签名证书，只不过把所有的操作封装成了脚本，可以生成多域名证书，泛域名证书，表示很好用，也可以参考官网提供的openssl 生成 github链接地址：https://github.com/Fishdrowned/ssl 修改self_registration = off #禁止普通用户可以注册用户选项 修改project_creation_restriction = adminonly #只允许管理员创建项目 配置截图： 当然，harbor支持邮件发送，用户忘记密码，通过邮件来更改密码；这里我没有使用邮件服务； harbor也可以支持ldap认证；修改完配置文件，接下来就是制作证书了： 制作证书：创建目录：（此目录，容器会挂载此目录下的证书文件，也就是配置文件中指定的证书路径），当然也可以自定义此路径mkdir /data/cert使用openssl命令生成证书（本文我使用的是脚本生成）openssl生成证书主要分几个步骤： 创建CA证书 生成证书签名请求 生成服务器证书 介绍脚本使用： 脚本路径： /root/ssl 脚本执行: ./gen.cert.sh hub.com 脚本输出路径： /root/ssl/out/hub.com/ 证书生成成功后，就可以执行脚本安装了！修改docker-compose.yml,指定端口访问主要修改，proxy映射到宿主机的默认端口，80改为5000，https默认使用443； 执行以下命令，运行容器：1./install.sh 安装完成后，可以使用docker-compose ps 查看运行的容器；安装成功后，就可以使用浏览器进行访问了！注意： 生成证书时，使用的是hub.com，hub.com是一个虚假的域名，需要在本机添加hosts文件， 192.168.0.154 hub.com 访问UI界面https://hub.com 介绍几个命令如果在容器运行后，修改配置文件，使用以下命令，重新加载容器 停止容器：(注意需要在harbor目录中执行，因为要依赖docker-compose.yml文件) docker-compose down重新加载配置文件修改harbor.cfg配置文件后，执行以下命令，重新生成文件 ./prepare #如果语法错误，会提示错误启动容器： docker-compose up -d]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker Harbor仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker与系统软件防火墙关系]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker%E4%B8%8E%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E9%98%B2%E7%81%AB%E5%A2%99%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[在使用docker的过程中，经常遇到要改动防火墙，要注意的问题 以下笔记总结参考此链接: Docker网络与防火墙 QAQ: 在docker运行的过程中，重启了firewalld或者iptables A:会触发，在宿主机无法转发请求到容器，这是因为 docker 在默认启动的时候，会修改iptables规则，如果重启了iptables，或者firewalld，则docker默认启动服务设置的规则就会丢失，所以会影响容器访问 Q: 启动一个新的docker容器，映射了端口，需不需要在系统防火墙开放端口 A: 不需要，因为docker 容器如果映射了端口，在没有指定网络模式的情况下，默认使用docker0网络，也就是容器的网关，容器访问外部数据，到达docker0，也就是网关后，会查询主机的路由表，确定数据包从哪个网卡发出，iptables负责对数据包进行snat转换，将源地址转换为对应网卡的地址，因此容器对外是不可见的。 A: 外部想要访问容器内的数据，首先需要将容器的端口映射到宿主机上。这时候docker会在iptables添加转发规则，把接收到的数据转发给容器。 注意:如果在启动docker服务的情况下，需要动态添加防火墙规则。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker与系统防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker swarm 一些常用命令]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker-swarm-%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[记录工作中常用的一些docker swarm的命令 docker命令官网 docker swarm命令docker swarm创建集群1docker swarm init --advertise-addr 192.168.1.10 node节点加入集群1234567891011docker swarm join --token "创建集群的tocken值" 192.168.1.10:2377#如果忘记了加入集群的命令，可以在管理节点执行以下命令获取[1::root@sun-host::~]# &gt;&gt;&gt;docker swarm join-token manager #查看加入管理节点的tockenTo add a manager to this swarm, run the following command: docker swarm join --token SWMTKN-1-5n0yqdoirvjroddv4tk4q352rjg5ywqo0gur2a5ibaw517y9ed-6bwuuocgw1lx3anqsiy373uyn 192.168.1.10:2377[1::root@sun-host::~]# &gt;&gt;&gt;docker swarm join-token worker #查看加入工作节点的tockenTo add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-5n0yqdoirvjroddv4tk4q352rjg5ywqo0gur2a5ibaw517y9ed-5lo62wh31nrt439b679s2ulim 192.168.1.10:2377 查看集群中的服务12docker service ls docker service ls ps 服务名 查看服务部署在哪个节点1docker service ps 服务名 修改服务实例数1docker service scale nginx=3 删除节点1docker node rm node2 排除节点1docker node update --availability drain &lt;NODE-ID&gt; 恢复排除的节点1docker node update --availability active &lt;NODE-ID&gt; 删除shutdown的容器,和无用数据清理1docker system prune -f docker node常用命令12345678docker node ls #查看所有集群节点docker node rm #删除某个节点（-f强制删除）docker node inspect ##查看节点详情,标签 --pretty 显示信息比较规整docker node demote #节点降级，由管理节点降级为工作节点docker node promote #节点升级，由工作节点升级为管理节点# docker node promote node1 node2 # 提升node1 node2节点为管理节点docker node update #更新节点docker node ps #查看节点中的 Task 任务 docker service 常用命令12345678docker service create #创建服务, 如果编写compose文件，可以使用docker stack命令部署docker service inspect #查看服务的详细信息docker service ps #查看服务运行的节点docker service logs #查看某个服务的日志信息docker service rm #删除服务docker service ls #列出集群中所有服务docker service update #更新服务docker service update --image hub.com/image service_name #更新服务的镜像 docker swarm服务的动态命令设置123456789101112# 命令格式 docker service [option] servicedocker service update --env-adddocker service update --env-rm docker service update --host-add docker service update --host-rmdocker service update --hostnamedocker service update --mount-add type=volume,source=/data,target=/datadocker service update --mount-rm type=volume,source=/data,target=/datadocker service update --network-add name=my-network,alias=web1 # Add a networkdocker service update --network-rm name=my-network,alias=web1docker service update --publish-add published=8080,target=80 # Add or update a published portdocker service update --publish-rm published=8080,target=80 # Remove a published port by its target port 批量删除所有服务12docker service ls -1 # 获取所有service的IDdocker service ls -q | xargs docker service rm Docker Stack 部署多个集群服务docker stack使用文件docker-compose.yml批量部署服务创建编排文件docker-compose.yml12345678910111213141516version: '3'services: mynginx: image: hub.test.com:5000/almi/nginx:0.1 ports: - "8081:80" deploy: replicas: 3 busybox: image: hub.test.com:5000/busybox:latest volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: replicas: 2 使用docker-stack批量创建服务123docker stack deploy -c docker-compose.yml deploy-testdocker stack ps deploy-tes# docker stack部署的容器名称 deploy-test_&lt;service名称&gt;.随机后缀 docker stack 常用命令123456docker stack deploy #部署新的堆栈或更新现有堆栈docker stack ls #列出现有堆栈docker stack ps #列出堆栈中的任务docker stack rm #删除堆栈 （docker stack deploy部署的时候指定的服务名字）docker stack services #列出堆栈中的服务docker stack down #移除某个堆栈（不删数据） docker stack deploy 显示服务的状态accepted: 任务已经被分配到某一个节点执行preparing: 准备资源，一般是从网络拉取iamgerunning: 副本运行成功shutdown: 报错，终止，当一个任务被终止（stoped or killed），任务不能被重启，但是一个替代的任务会被重启 查看swarm中服务的ip1docker service inspect --format='&#123;&#123; json.Endpoint.VirtualIPs &#125;&#125;' 服务名]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker中使用supervisor管理进程]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker%E4%B8%AD%E4%BD%BF%E7%94%A8supervisor%E7%AE%A1%E7%90%86%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[docker file 中 ENTRYPOINT 和CMD的用法 ENTRYPOINT &amp;&amp; CMD在docker file中，如果同时指定了ENTRYPOINT和CMD，例如： CMD 的指令将作为参数传递给ENTRYPOINTENTRYPOINT 指定 /usr/bin/tini – /usr/bin/entrypoint.sh /usr/bin/tini 是转发信号，防止僵尸进程， /usr/bin/entrypoint.sh脚本指定了exec $@接受所有的参数，也就是会接受CMD传递过来的参数，启动supervisord服务 为何这样用呢？ 如果有些操作，需要在docker 容器运行前需要指定的操作，就可以通过shell写在ENTRYPOINT.sh脚本中，控制容器执行操作！]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker file</tag>
        <tag>ENTRYPOINT</tag>
        <tag>CMD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7绑定双网卡]]></title>
    <url>%2F2018%2F09%2F19%2Fcentos7%E7%BB%91%E5%AE%9A%E5%8F%8C%E7%BD%91%E5%8D%A1%2F</url>
    <content type="text"><![CDATA[Centos7绑定双网卡： #安装必需的包：1yum install teamd -y #停止NetworkManager123systemctl stop NetworkManagersystemctl disable NetworkManager #Creating a Network Team Using ifcfg Files12345678910111213cd /etc/sysconfig/network-scripts/vi ifcfg-team0DEVICE=team0DEVICETYPE=TeamONBOOT=yesBOOTPROTO=noneIPADDR=192.168.10.110PREFIX=24GATEWAY=192.168.10.254TEAM_CONFIG='&#123;"runner": &#123;"name": "activebackup"&#125;, "link_watch": &#123;"name": "ethtool"&#125;&#125;'#做好备份继续编辑需要绑定的网卡信息，调整prio优先级 1234567# cat ifcfg-eno1DEVICETYPE=TeamPortTEAM_MASTER=team0TEAM_PORT_CONFIG='&#123;"prio":100&#125;'NAME=eno1DEVICE=eno1ONBOOT=yes 12345678# cat ifcfg-eno2DEVICETYPE=TeamPortTEAM_MASTER=team0TEAM_PORT_CONFIG='&#123;"prio":99&#125;'NAME=eno2DEVICE=eno2ONBOOT=yes 123#重启网络systemctl restart network #检查端口状态12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697teamnl team0 ports1: eth0: up 1000Mbit FD2: eth1: up 1000Mbit FD#检查teaming状态teamdctl team0 statesetup: runner: activebackupports: eno1 link watches: link summary: up instance[link_watch_0]: name: ethtool link: up eno2 link watches: link summary: up instance[link_watch_0]: name: ethtool link: uprunner: active port: eno1#手动断开其中一条链路验证主备模式切换是否正常ip link set eno1 downteamdctl team0 statesetup: runner: activebackupports: eno1 link watches: link summary: up instance[link_watch_0]: name: ethtool link: up eno2 link watches: link summary: up instance[link_watch_0]: name: ethtool link: uprunner: active port: eno2]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux高阶命令使用]]></title>
    <url>%2F2018%2F09%2F19%2Flinux%E9%AB%98%E9%98%B6%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[编写shell脚本中，常用的一些awk grep getops 语法 awk1234567tailf access.log | awk 'substr($3,1,3)&gt;200'# 查看访问日志中，过滤非200状态码的日志请求# substr是一个内置函数substr($4,20) # 表示从第四个字段里的第20个字符开始，一直到设定的分隔符 结束substr($4,1,3) # 表示从第四个字段里的第1个字符开始，截取3个字符结束substr($4,3,6) # 表示从第四个字段里的第3个字符开始，截取6个字符结束 getopsgetops指定参数，获取值 1234567891011121314151617181920[root@test-host tmp]# cat test.shwhile getopts “:h:p:” optname;do case “$optname” in “h”) echo “ -h选项的值是 $OPTARG” ;; “p”) echo “-p 选项的值是 $OPTARG” ;; “?” ) echo “不知道此选项” ；； “:”) echo “此选项没有值” ;; “*”) echo “错误信息” ；； esacdone 1234Usage: ./test.sh -h 192.168.1.18 -p 22"-h 选项的值是 192.168.1.18""-p 选项的值是 22" fgrep12fgrep -c "hello" test.txt #匹配hello字符在test.txt文件中匹配行的数目fgrep -l "hello" test.txt #显示匹配hello的文件名 du命令统计目录大小1du -h --max-depth=1 &#123;path&#125; #只显示目录的层级是一级，但是列出的大小，是属于整个文件夹的 pkill12#提出当前登录用户的终端sudo pkill -kill -t pts/15 脚本执行，获取当前路径1cur_dir="$(cd "$(dirname "$[BASH_SOURCE[0]]")"; pwd)" echo输出颜色1echo -e "\e[31m 我要输入的内容 \e[0m" #输出内容为红色 sed获取域名解析的ip地址1nslookup www.baidu.com | sed -n -e '4,$p' | awk '/Address/&#123;print $2&#125;' tr分割符123456789testinfo="python,java,php"for i in $testinfo;do echo $testinfo | tr ',' '\n' #将逗号隔开，\n换行 , \n也可以使用别的字符替换done#结果输出:pythonjavaphp 123# 使用-- 拼接[42::root@test-host:: test]# &gt;&gt;&gt; for i in $testinfo;do echo $testinfo | tr ',' '--'; donepython-java-php eval命令12eval ls $pipe wc -l# shell第1次扫描命令行时，它替换出pipe的值｜，接着eval使它再次扫描命令行，这时shell把｜作为管道符号了。]]></content>
      <categories>
        <category>linux高阶命令</category>
      </categories>
      <tags>
        <tag>awk getopts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志检索常用命令]]></title>
    <url>%2F2018%2F09%2F19%2Fnginx%E6%97%A5%E5%BF%97%E6%A3%80%E7%B4%A2%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[查找特定时间点的日志1cat access.log | awk '$1 &gt;="[21/Jul/2014:14:37:50" &amp;&amp; $1 &lt;="[21/Jul/2014:14:38:00"' 禁止特定ip访问12封掉此IP： iptables -t mangle -I PREROUTING -s 192.168.1.53 -j DROP解封命令： iptables -t mangle -D PREROUTING -s 192.168.1.53 -j DROP 获取IP前101awk '&#123;print $7&#125;' access.log | sort | uniq -c | sort -n | tail 计算文件中列的和12345678[root@test-host /tmp]# cat test.txt12345#求列的和awk 'BEGIN&#123;sum=0&#125;&#123;sum+=$1&#125;END&#123;print sum&#125;' test.txt]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown语法积累]]></title>
    <url>%2F2018%2F09%2F19%2FMarkdown%E8%AF%AD%E6%B3%95%E7%A7%AF%E7%B4%AF%2F</url>
    <content type="text"><![CDATA[markdwon语法积累图片加载显示图片1![加载图片](/images/custome.png) 引用1&gt; 代表引用 标题1234# 一级标题## 二级标题### 三级标题......... 依次类推 表格单元格和表头使用 | 来分割不同的单元格 12345| name | description || ---- | --- ||ansible_ssh_host | 执行的主机 | |ansible_ssh_user | ssh连接的用户名 ||ansible_ssh_port | ssh目标主机的端口号 | name description ansible_ssh_host 执行的主机 ansible_ssh_user ssh连接的用户名 ansible_ssh_port ssh目标主机的端口号 对齐 :— 代表左对齐 :–: 代表居中对齐 —: 代表右对齐]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英语学习一]]></title>
    <url>%2F2018%2F09%2F18%2F%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[英语爱好者的词汇积累 Bus No.38 has a regular schedule.第38路车有一个固定的时间表regular: [/‘rɛgjəlɚ/] 定期的，有规律的schedule: [/ˈskedʒʊl; skɛdʒʊl/] vt.安排，计划 It comes every 15 minutes.每15分钟就有一次 3.Bus No.47 comes less often.第47路公共汽车很少 It comes at 8:20,8:45,and 9:25.它是在8:20,8:45和9:25 Bus No.60 is the earliest bus.第60路公共汽车是最早的。earliest： [ /‘ɝlɪɪst/] 早的，初期的 It comes at 8:05,8:30,and 9:00时间是8:05,8:30和9:00 Bus No.38 has stops at the main train station and the airport.38路公共汽车停在火车总站和机场 Bus No.60 stops at the main train station,but doesn’t go to the airport.第60路公共汽车停在火车站，但不去机场 Bus No.47 doesn’t go to either the main train station or the airport.第47路公共汽车即不去火车站也不去机场either：[/‘iðɚ/] adj.两者之中任一的 prep. 任何一个 The last bus to the airport left 15 minutes ago,at 8:55.最后一班去机场的巴士15分钟前，8点55分 Here is a bus scheduel at a bus stop.这是公共汽车站的公交时刻表 It has the schedule for 3 buses between 8:00 and 9:30 in the morning.有3辆公共汽车的时间表在早上8:00到9:30之间]]></content>
      <categories>
        <category>英语学习</category>
      </categories>
      <tags>
        <tag>常明学英语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible的playbook文件的语法]]></title>
    <url>%2F2018%2F09%2F18%2Fansible%E7%9A%84playbook%E6%96%87%E4%BB%B6%E7%9A%84%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[记录工作中使用到的编写playbook文件的一些语法 ansible中编写playbook文件，通过不同的角色执行操作首先看一份playbook文件, 文件名 testInstallDocker.yml12345678#入口playbook文件---- hosts: 'test-1' sudo: yes roles: - docker - yum 执行命令12ansible-playbook testInstallDocker.yml#这条命令执行，接下来，会发生什么呢？ 首先会找到testInstalldocker.yml文件中定义的内容， — 代表注释， - hosts: test-1 指定要操作的主机是test-1 sudo: yes 表示允许普通用户执行sudo权限 roles: roles 会默认去ansible的默认/etc/ansible/roles目录下找 docker yum, 当然此目录也可以通过ansible.cfg文件修改 进入/etc/ansible/roles目录1234567891011121314151617181920212223以下可以看到/etc/ansible/roles/&#123;docker,yum&#125; 目录下创建的文件[sun@test-host roles]$ tree -L 2 dockerdocker ├── files #在playbook语法中，指定源文件，从此目录中查找│ ├── daemon.json│ └── docker-ce.repo├── handlers #定义触发操作，在playbook中通过notify定义│ └── main.yml├── meta #定义当前角色的依赖关系│ └── main.yml└── tasks #入口文件 └── main.yml4 directories, 5 files[sun@test-host roles]$ tree -L 2 yumyum├── Readme.txt├── tasks│ └── main.yml└── vars └── main.yml2 directories, 3 files 以上两个目录docker yum，就可以称之为角色， 通过刚才的入口文件，调用角色 看一下角色中创建的各文件都是什么意思？ files/：存放由copy或script模块等调用的文件；templates/:template模块查找所需要模板文件的目录；tasks/：至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含；handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含；vars/：至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含；meta/：至少应该包含一个名为main.yml的文件，定义当前角色的特殊设定及其依赖关系；其它的文件需要在此文件中;default/：设定默认变量时使用此目录中的main.yml文件； 在角色中的入口文件，就是tasks目录，查看docker角色的tasks目录下的main.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[sun@test-host /etc/ansible/roles/docker/tasks] cat main.yml---# 删除旧版本- name: Ensure old versions of Docker are not installed. package: #调用ansible的package模块，安装rpm包 name: '&#123;&#123; item &#125;&#125;' #&#123;&#123; item &#125;&#125; 使用模板变量语法，item可以迭代执行元素， 就是with_items中定义的元素 state: absent # package安装包的几种状态 absent代表删除软件包 present 监测是否安装，否，则安装 with_items: - lxc-docker - docker-engine - docker - docker-common - docker.io#安装存储库- name: Ensure depend package is installed package: name: '&#123;&#123; item &#125;&#125;' state: present with_items: - yum-utils - device-mapper-persistent-data - lvm2# 添加 repo- name: Add Docker repository. copy: # 调用copy模块，拷贝文件 src: docker-ce.repo # src指定的文件路径，就是docker角色中files 目录中的文件 dest: /etc/yum.repos.d/docker-ce.repo #目标主机的路径 owner: root group: root mode: 0644# 安装指定版本- name: Install docker package: name: "docker-ce-17.09.1.ce-1.el7.centos" state: present enablerepo: docker-ce-stable# 添加 /etc/docker/- name: Ensure /etc/docker/ exist file: path=/etc/docker/ mode=0600 state=directory #调用file模块， state=directory，表示path指定的路径是一个目录，不存在则创建# 启动服务器- name: Ensure Docker is started and enabled at boot. systemd: #调用systemd控制服务状态 name: docker state: started #启动docker服务 enabled: yes #开机自启动 docker角色定义依赖关系12345# cat //etc/ansible/roles/docker/meta/main.yml# yum角色执行完后，再执行docker角色---dependencies: - &#123; role: yum &#125; 查看yum角色中的tasks目录下的main.yml文件12345678910111213141516---- name: Install epel repo yum: #调用yum模块 name: 'epel-release.noarch' state: latest- name: install the 'Development tools' package group yum: name: "@Development tools" state: present- name: Install packages yum: #调用yum模块 name: "&#123;&#123; pkg_list &#125;&#125;" #这里的pkg_list 变量会从 当前角色的vars目录下的main.yml中获取 state: latest #更新到最新版本 1234[sun@test-host /etc/ansible/roles/yum/vars]$ cat main.yml pkg_list: - bash-completion - bash-completion-extras 在playbook中，yum模块和package的区别： yum是centos 和redhat系列系统的默认安装rpm包命令 如果是ubuntu系统或者opensuse系统，那么就得使用package的模块了，该模块会为每个系统调用相关的包模块（apt，yum等） 最开始的那条命令，ansible-playbook testInstallDocker.yml ，就会找到docker角色，yum角色，并且根据角色中的入口文件执行相应操作！理解ansible-playbook的路由关系后，就可以熟练编写playbook文件，定义不同模块的角色执行。 ansible-playbook命令使用123ansible-playbook --syntax-check /path/to/playbook.yml #测试playbook文件中定义的语法是否正确ansible-playbook -C /path/to/playbook.yml #只测试运行，并无真正执行ansible-playbook /path/to/playbook.yml #执行playbook文件 playbook文件中各模块的语法systemd服务systemd控制服务运行状态 service服务12- name: Enable firewalld service: name=firewalld state=started enabled=yes user模块user模块的用法: 添加或者删除用户，根据state 指定state: present 用户存在，不执行操作，不存在，添加state:absent: 删除用户 with_items,对于元素迭代使用 如果是多个元素呢？ 多个元素迭代使用方法： gourp模块goup模块的用法 file模块file模块创建目录1234567---- name: "创建目录" file: path=&#123;&#123; item &#125;&#125; state=directory with_items: - /usr/local/nginx - /usr/local/src/nginx file模块创建软连接, 将/usr/local/python3/bin/python3 软连接到/usr/bin/python3 file模块设置权限 unarchive解压模块用于解压文件，模块包含如下选项： copy：在解压文件之前，是否先将文件复制到远程主机，默认为yes。若为no，则要求目标主机上压缩包必须存在。 creates：指定一个文件名，当该文件存在时，则解压指令不执行 dest：远程主机上的一个路径，即文件解压的路径 grop：解压后的目录或文件的属组 list_files：如果为yes，则会列出压缩包里的文件，默认为no，2.0版本新增的选项 mode：解决后文件的权限 src：如果copy为yes，则需要指定压缩文件的源路径owner：解压后文件或目录的属主示例如下：123 - unarchive: src=foo.tgz dest=/var/lib/foo - unarchive: src=/tmp/foo.zip dest=/usr/local/bin copy=no- unarchive: src=https://example.com/example.zip dest=/usr/local/bin copy=no 根据条件判断是否执行12345678910111213141516171819- name: "查看python3是否安装，忽略提示" shell: python3 #执行一条命令，将结果赋值给register定义的result register: result ignore_errors: True #忽略错误提示#拷贝Python-3.6.5- name: "copy Python3-6.5 to dest" copy: src=Python-3.6.5.tgz dest=/usr/local/src/Python-3.6.5.tgz when: result is failed #当result返回的是个错误的时候，执行此tasks#编译安装python3.6.5- name: "compile install" shell: pip install --upgrade supervisor requests;cd /usr/local/src/;tar zxf Python-3.6.5.tgz; cd Python-3.6.5;./configure --prefix=/usr/local/python3 --with-ssl;make;make install when: result is failed#软连接python3- name: "ln -s python3" file: src=/usr/local/python3/bin/python3 dest=/usr/bin/python3 state=link when: result is failed yum模块yum 模块使用 copy模块触发handlers的操作copy触发handlers的操作 handlers/main.yml文件12- name: reload crond command: systemctl restart crond rsync模块1234567- synchronize: src: /usr/local/src/uploadfile/ dest: /usr/local/src/uploadfile/ delete: yes rsync_opts: - "--exclude=logs" - "-avz" notify触发handlers的用法注意: notify后的名字，必须和handlers中定义的名字相同 handlers/main.yml12- name: restart supervisor systemd: name=supervisord state=restarted 角色中的meta定义依赖关系123456meta/main.yml---dependencies: - &#123; role: docker &#125; playbook中变量的定义123456789---- hosts: test-host vars: http_port: 80 remote_user: root tasks: - name: firewalld set firewalld: port=&#123;&#123; http_port &#125;&#125;/tcp permanent=true state=enabled immediate=yes ansible关闭selinux，并等待重启完成，继续执行task123456789101112131415161718192021222324252627- name: install libselinux-python yum: name: libselinux-python state: present tags: - optimize - selinux- name: turn off selinux selinux: state: disabled register: se tags: - optimize - selinux - name: reboot host and wait for it to return shell: sleep 5 &amp;&amp; shutdown -r now "reboot for disable selinux" async: 1 poll: 0 ignore_errors: true when: se.reboot_required == True- name: Wait for the server to finish rebooting wait_for_connection: delay: 5 ansible执行策略优化 ansible并发程序执行的等待优化ansible的任务执行，是并发操作，默认开启5个进程执行，可以执行-f 定义并发进程数ansible默认5个并发进程，如果控制主机比较多，例如20个主机，那么会并行执行5台主机，只有这5台主机全部执行完一次任务，再继续下一批的5台执行任务，如果其中一台执行完任务，那么它默认也会等待那四台主机完成，然后再5台并行执行任务，这样的话，就会影响执行效率； 如果目标主机的网络稳定性不好，开启的进程就会一直等待最后一个任务执行完成，才继续下一个任务 在使用playbook文件中，可以指定 strategy: free 表示异步执行，尽快切换到下一台主机，默认为linear ansible的清单文件中的参数 name description ansible_ssh_host 执行的主机 ansible_ssh_user ssh连接的用户名 ansible_ssh_port ssh目标主机的端口号 以上也是工作中常用到的，没有写的太详细，就是忘记语法的时候，翻出来看看！]]></content>
      <categories>
        <category>自动化运维工具</category>
      </categories>
      <tags>
        <tag>ansible的playbook语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible命令与模块的使用]]></title>
    <url>%2F2018%2F09%2F18%2Fansible%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[主要记录一下，平常使用ansible的一些命令和模块的使用 ansible定义主机组清单文件默认路径: /etc/ansible/hosts 也可以在ansible.cfg中指定其他路径123[test] # 定义主机组test-1 #主机列表 这里的主机，使用了主机名定义，方便后续在playbook中设置主机hostname，获取清单的变量test-2 当然需要在宿主机的hosts文件指定ipansible的清单文件也可以调用脚本的方式 ansible的命令语法1ansible &#123;主机 | 主机组&#125; -m &#123;指定模块&#125; -a &#123;执行的命令&#125; ansible模块command模块12ansible test -m command -a 'hostname' #默认就是command，所以不需要执行-m commandansible test -a "hostname" shell模块12ansible test -m shell -a 'echo "root:testpassword" | chpasswd'#此命令，使用到了管道符号，就必须使用shell模块，command模块不支持管道操作 copy模块12ansible test -m copy -a 'src=/tmp/test.txt dest=/tmp/test.txt'# 将源主机的/tmp/test.txt文件推送到目标主机的/tmp/test.txt synchronize模块12ansible test -m synchronize -a 'src=/tmp/directory1/ dest=/tmp/directory1/'#将源主机的directory1目录推送到目标主机 ** 注意:同步目录的时候，源路径目录必须以/ 结尾，要不然同步过去会生成子目录 /tmp/directory1/directory1 script模块ansible test -m script -a '/tmp/test.sh' #ansible会把本地/tmp/test.sh脚本推送到目标主机，并执行脚本，执行完删除脚本，退出]]></content>
      <categories>
        <category>自动化运维工具</category>
      </categories>
      <tags>
        <tag>ansible命令</tag>
        <tag>ansible模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[firewalld自定义服务开放端口]]></title>
    <url>%2F2018%2F09%2F18%2Ffirewalld%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%8D%E5%8A%A1%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[在使用docker swarm集群的时候，各工作节点需要开放通信的端口，手动一个一个加，又比较麻烦 索性写成firewalld的服务，然后直接添加此服务即可！ 自定义firewalld服务路径： /usr/lib/firewalld/services/ 新增docker-swarm.xml文件12345678910&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;service&gt;&lt;short&gt;docker-swarm&lt;/short&gt;&lt;description&gt;Default ports for docker swarm&lt;/description&gt;&lt;port protocol="tcp" port="2376"/&gt; &lt;!--For Docker Machine --&gt;&lt;port protocol="tcp" port="2377"/&gt; &lt;!--It only needs to be opened on manager nodes --&gt;&lt;port protocol="tcp" port="7946"/&gt; &lt;!--For container network discovery --&gt;&lt;port protocol="udp" port="7946"/&gt; &lt;!--For container network discovery --&gt;&lt;port protocol="udp" port="4789"/&gt; &lt;!--For container ingress networking --&gt;&lt;/service&gt; firewall-cmd添加自定义的服务12firewall-cmd --add-service=docker-swarm --permanentfirewall-cmd --reload 查看是否添加成功1firewall-cmd --list-all #列出默认区域的防火墙配置]]></content>
      <categories>
        <category>Centos7防火墙</category>
      </categories>
      <tags>
        <tag>firewalld</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo Next主题使用配置]]></title>
    <url>%2F2018%2F09%2F16%2Fhexo-Next%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[当前主题采用版本信息 Next Version: v6.0.0 Hexo Version: v5.1 记录初次使用hexo的基本配置，做个笔记文档！所有的记录，都是在hexo的官网，和别人的博客中找到的，感谢分享的这些文档，让我可以参照部署出自己的博客。 hexo站点使用配置博客的title打开站点配置文件123456789# Sitetitle: Changming's blogssubtitle: 坚持是一种美德description: 命运给你一个比别人低的起点，是想告诉你，让你用一生的努力去奋斗出一个绝地反击的故事。这个故事关于独立，关于梦想，关于坚忍，关于勇气！keywords:author: 李常明language: zh-Hanstimezone:email: 15116973831@163.com 博客左侧导航栏配置打开主题配置文件：D:\hexo\themes\next123456789menu: home: / || home about: /个人简介/ || user tags: /标签/ || tags categories: /分类/ || th archives: /归档/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 上面为菜单的配置;在站点的使用逻辑关系home: 为站点中显示的命名/: 匹配的url|| home : 定义显示的图标 about: 站点中显示的名称/个人简介： 匹配的url ，需要hexo new page “个人简介” 创建与url匹配的页面user: 站点中显示的图标 博客左侧底部栏设置打开站点配置文件，site的区域配置123# Siteauthor: 李常明description: 描述信息 下面的日志 分类 标签，如果站点中，有文章，并添加分类，标签，会自动显示 分类 标签的使用分类 标签的关联关系分类： 文章属于哪一类标签： 文章的主题内容，根据标签判断文章的内容 使用，在hexo文件夹中执行以下命令12hexo new page "分类" #名称必须匹配在上述主题配置文件中Menu区域的匹配的urlhexo new page "标签" 以上页面创建完成后，会存在 D:\hexo\source{分类，标签}在分类，标签中，以上命令会默认创建index.md文件，分别编辑分类，标签中的index.md添加如下内容 标签12345---title: 标签date: 2018-09-16 16:07:36type: "tags" #添加tags--- 分类12345---title: 分类date: 2018-09-16 16:09:20type: "categories" #添加categories--- 新建一篇博客，查看分类和标签的使用1hexo new "hello_world" #新建博客的命令 上述命令执行完后，会生成D:\hexo\source_posts\hello_world.md文件 在hello_world.md文件添加分类和标签12345678---title: test 分类和标签使用date: 2018-09-16 16:09:20tags: - hexo部署配置categories: - 博客搭建--- 123hexo calenhexo generatehexo s #本地运行，访问查看分类和标签 在文章中，指定了标签和分类，那么文章就会归类到同名的标签和分类中，可以快速检索到文章 hexo站内搜索 进入hexo根目录，使用npm 安装插件1npm install hexo-generator-searchdb --save 打开站点配置文件，在Extensions下面添加123456# 搜索search: path: search.xml field: post format: html limit: 10000 打开主题配置文件，找到Local search，将enable设置为true123#站点内文章的搜索功能local_search: enable: true 友情链接添加打开主题配置文件,links区域123links: 追马: http://www.zhuimar.com/ jkzhao: http://jkzhao.github.io/ 设置文章只显示预览部分123auto_excerpt: enable: true #改为true，默认显示length设置的长度内容 length: 150 或者在文章中使用,会显示此标志之前的内容 基本上简约版的配置已经完成了，如果添加其它主题配置优化的，基本上网上也都有相似的文章 贴上几个笔者参考主题配置的urlhexo主题配置优化添加必力评论 后续更新markdown的语法，用于平常翻看！]]></content>
      <categories>
        <category>hexo博客配置与优化</category>
      </categories>
      <tags>
        <tag>hexo站点配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 部署(一)]]></title>
    <url>%2F2018%2F09%2F16%2Fhexo-%E9%83%A8%E7%BD%B2-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[让写作成为习惯，使用博客构建自己的写作平台 hexo博客搭建 折腾了好久的时间，终于使用hexo部署起来了自己的博客。初次使用hexo，也是各种纠结，看起来还不错，想用，但又感觉好麻烦，终于借着周六日休息的时间，把博客整起来了，特此记录下遇到的问题，哈哈！ hexo初体验 初体验的博客部署参考连接：jkzhao部署hexohexo简介 Hexo可以集成Github Pages展示自己的博客Hexo是一个可以快速生成静态页面的博客框架，通过编写mardown文件，转换成html文件，方便在浏览器中加载。 hexo的特点： 快速生成静态页面 支持Markdown 一键部署博客 丰富的插件支持 hexo部署 因个人机使用的win10系统，所以，以下环境都在windows上执行 安装依赖工具 Node.js Git 下载以上两个工具即可。 在GitHub上创建仓库 例如我的仓库： 上面的仓库地址，就是后续要访问的地址，格式必须为： name.github.io 配置本地windows可以免秘钥登录自己的仓库，这个这么简单的问题，就不叙述了。 使用Hexo创建博客框架-1. 在本地磁盘中，新建文件夹 自定义名称 例如hexo-2. 进入hexo文件夹，打开git bash,执行以下命令1234npm install -g hexo #使用npm安装hexo，npm需要安装node.js的支持hexo init #初始化项目结构hexo g #用于生成静态网站文件hexo s #在本地运行静态网页 上面的命令执行完成后，会提示：12345678910$ hexo sINFO Start processingWARN ===============================================================WARN ========================= ATTENTION! ==========================WARN ===============================================================WARN NexT repository is moving here: https://github.com/theme-nextWARN ===============================================================WARN It's rebase to v6.0.0 and future maintenance will resume thereWARN ===============================================================INFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 本地浏览器，访问http://localhost:4000(默认端口4000) 默认主题的博客已经可以显示： 配置本地文件部署到GitHub 在Hexo文件夹下找到_config.yml文件，站点配置文件 修改代码如下：1234deploy: type: git repository: git@github.com:MrLichangming/MrLichangming.github.io.git branch: master 部署到仓库123hexo cleanhexo generatehexo deploy #同步到github仓库，必须本地可以免秘钥，上面deploy字段中，仓库地址填写正确 更改默认主题为NexT在hexo文件夹下，使用git clone Next主题1git clone https://github.com/iissnan/hexo-theme-next themes/next 克隆Next主题到本地hexo文件夹下的thems/next,此路径下全是主题配置文件 启用Next主题打开站点配置文件 1.修改theme字段，将值更改为next 2.修改next主题的样式， scheme: Pisces 当然看个人爱好，可以使用其他样式 预览123hexo cleanhexo generatehexo s hexo的部署很简单，就能看到一个默认的雏形，第二篇文章会更新hexo的Next主题配置优化]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo部署配置</tag>
      </tags>
  </entry>
</search>
