<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Centos7升级内核]]></title>
    <url>%2F2020%2F03%2F31%2FCentos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8%2F</url>
    <content type="text"><![CDATA[Centos7系统升级系统内核 参考链接地址centos7升级内核至最新-博客园]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux当前PS终端美化]]></title>
    <url>%2F2020%2F03%2F31%2FLinux%E5%BD%93%E5%89%8DPS%E7%BB%88%E7%AB%AF%E7%BE%8E%E5%8C%96%2F</url>
    <content type="text"><![CDATA[PS终端美化备忘录 PS112]]></content>
  </entry>
  <entry>
    <title><![CDATA[GlusterFS使用中的一些命令积累]]></title>
    <url>%2F2020%2F03%2F25%2FGlusterFS%E4%BD%BF%E7%94%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%91%BD%E4%BB%A4%E7%A7%AF%E7%B4%AF%2F</url>
    <content type="text"><![CDATA[记录下GlusterFS的命令 分布式文件系统GlusterFS实战，参考文档： CHEGVA博客链接 install1234yum install centos-release-glusteryum install -y glusterfs glusterfs-server glusterfs-fuse glusterfs-rdmasystemctl start glusterd.servicesystemctl enable glusterd.service configuration123456789101112131415161718192021222324252627282930313233343536373839404142# 查看glusterfs版本信息glusterfs -V# 将节点加入存储池# 节点加入防火墙的时候，需要开放防火墙端口：firewall-cmd --add-service=glusterfsgluster peer probe lg1gluster peer probe lg2# 创建volume , 复制几份replica后的数字就是几 分布式复制模式gluster volume create test replica 2 transport tcp lg1:/var/test/data lg2:/var/test/data lg3:/var/test/data lg4:/var/test/data # 查看刚才创建卷gluster volume info#启动刚才创建的卷组 gluster volume start test #查看各节点状态gluster peer status ``` # gluster 性能调优：开启 指定 volume 的配额： (test 为 volume 名称)```bashgluster volume quota test enable限制 test 中 / (既总目录) 最大使用 80GB 空间gluster volume quota test limit-usage / 80GB# 设置 cache 4GBgluster volume set test performance.cache-size 4GB# 开启 异步 ， 后台操作gluster volume set test performance.flush-behind on# 设置 io 线程 32gluster volume set test performance.io-thread-count 32# 设置 回写 (写数据时间，先写入缓存内，再写入硬盘)gluster volume set test performance.write-behind on Mounts1mount -t glusterfs 127.0.0.1:test /var/data]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>GlusterFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s个人总结备忘录]]></title>
    <url>%2F2020%2F02%2F23%2Fk8s%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录下学习k8s的历程 好记性不如一个烂笔头 基础概念部分架构图备注: 图来自devops学院 《基于Kubernetes构建企业容器云》 视频教程 各个组件说明API serverSchedulerControl ManagerETCDKubeletkube-proxyDocker Enginekubelet: 每个工作节点运行的代理组件，确保容器都创建在pod中，kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。kubelet 不会管理不是由 Kubernetes 创建的容器]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis监控脚本]]></title>
    <url>%2F2020%2F02%2F18%2Fredis%E7%9B%91%E6%8E%A7%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[记录下redis监控的脚本 redis监控脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#!/usr/bin/env bash# Author: Sun# Description : monitor redis and send data to zabbix-server# -------------------------------------------------------------------------------------------# IDC1 dt-redis节点 存储数据缓存 ss-redis节点: 存储session数据# dt-redis-3 dt-redis-4 dt-redis-5 dt-redis-6 dt-redis-7 dt-redis-8 dt-redis-9 dt-redis-10# ss-redis-3 ss-redis-4 ss-redis-5 ss-redis-6 ss-redis-7 ss-redis-8 ss-redis-9 ss-redis-10# -------------------------------------------------------------------------------------------function check_cluster_status()&#123; # $1: redis-type (dt|ss) # $2: redis-node # $3: port status=`redis-cli -c -h $2 -p $3 cluster info | grep "cluster_state" | awk -F ':' '&#123;print $NF&#125;'` if echo $status | grep "ok" &gt;/dev/null;then zabbix_sender -z 47.75.134.140 -s redis-new -k $&#123;1&#125;-rd.redis.info.cluster_state -o $&#123;status&#125; else status="Fail" zabbix_sender -z 47.75.134.140 -s redis-new -k $&#123;1&#125;-rd.redis.info.cluster_state -o $&#123;status&#125; fi&#125;# redis 集群状态数据上报check_cluster_status dt 10.10.5.3 6379check_cluster_status ss 10.10.5.3 6380function get_data()&#123; # $1: redis-type (dt|ss) # $2: redis-node # $3: port # $4: check_key # $5: redis-number data=`/usr/bin/redis-cli -h $&#123;2&#125; -p $&#123;3&#125; info | grep -w $&#123;4&#125; | awk -F ':' '&#123;print $NF&#125;'` /usr/bin/zabbix_sender -z 47.75.134.140 -s redis-new -k $&#123;1&#125;-rd-$&#123;5&#125;.redis.info.$&#123;4&#125; -o $&#123;data&#125;&#125;# keys 注释#-----------------------------------------------------------# used_memory_peak: Redis使用内存的峰值，字节数# used_memory_peak_human: redis使用内存的峰值 单位G# connected_clients: 已连接客户端的数量(不包括通过从属服务器连接的客户端)# instantaneous_input_kbps: 瞬间的Redis输入网络流量(kbps)# instantaneous_output_kbps: 瞬间的Redis输出网络流量(kbps)# instantaneous_ops_per_sec: 服务器每秒钟执行的命令数量# keyspace_misses: 查找键未命中的次数# evicted_keys: 因内存used_memory达到maxmemory后，每秒被驱逐的key个数# expired_keys: 因为过期而被自动删除的数据库键数量# rejected_connections: 因连接数达到maxclients上限后，被拒绝的连接个数#-----------------------------------------------------------keys="used_memory_peak connected_clients instantaneous_input_kbps instantaneous_output_kbps instantaneous_ops_per_sec keyspace_misses evicted_keys expired_keys rejected_connections"# 获取redis info信息,并发送至zabbixfor i in $(seq 3 10);do for key in $keys;do get_data dt 10.10.5.$&#123;i&#125; 6379 $key $i get_data ss 10.10.5.$&#123;i&#125; 6380 $key $i donedone]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的sys.argv用法备忘录]]></title>
    <url>%2F2020%2F02%2F10%2Fpython%E7%9A%84sys-argv%E7%94%A8%E6%B3%95%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录在工作中使用python的基础备忘录 好记性不如烂笔头，特此记录下 1234import sysprint(sys.argv) # 输出所有的参数 包括文件名，一般第一个参数为文件名print(sys.argv[0]) # 输出当前文件名print(sys.argc[1]) # 输出当前文件名后面的参数]]></content>
      <categories>
        <category>python的积累</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux IO实时监控iostat命令详解]]></title>
    <url>%2F2020%2F02%2F04%2FLinux-IO%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7iostat%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[整理下iostat各参数含义 语法12# 语法iostat [ -c ] [ -d ] [ -h ] [ -N ] [ -k | -m ] [ -t ] [ -V ] [ -x ] [ -z ] [ device [...] | ALL ] [ -p [ device [,...] | ALL ] ] [ interval [ count ] ] 常用命令注解12345678iostat -d -k 2 10 # 查看TPS和吞吐量信息(磁盘读写速度单位为KB)iostat -d -m 2 10 # 查看TPS和吞吐量信息(磁盘读写速度单位为MB)iostat -d -x -k 1 10 # 查看设备使用率（%util）、响应时间（awaitiostat -c 1 10 # 查看cpu状态iostat -d -x -k 1 10# -d 显示设备(磁盘)使用状态 -k 某些使用block为单位的列强制使用Kilobytes为单位 2表示，数据显示每隔2秒刷新一次 10标识显示次数# -x 显示扩展数据 example123456789101112131415161718192021222324252627282930313233343536373839Linux 3.10.0-1062.1.1.el7.x86_64 (elk-1) 02/05/2020 _x86_64_ (8 CPU)Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 246.12 247.28 2109.43 2990563437 25511444304Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 82.00 12.00 468.00 24 936Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 71.00 0.00 378.00 0 756Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 97.50 0.00 1520.00 0 3040Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 71.50 0.00 318.00 0 636Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 87.00 0.00 404.00 0 808Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 89.50 0.00 480.00 0 960Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 72.00 0.00 800.00 0 1600Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 126.00 0.00 1908.00 0 3816Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 82.00 0.00 418.00 0 836# 解释如下tps: 该设备每秒的传输次数(Indicate the number of transfers per second that were issued to the device.)"一次传输"意思是"一次I/O请求"。多个逻辑请求可能会被合并为"一次I/O请求"。"一次传输"请求的大小是未知的。kB_read/s：每秒从设备（drive expressed）读取的数据量；kB_wrtn/s：每秒向设备（drive expressed）写入的数据量；kB_read：读取的总数据量；kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。上面的例子中，我们可以看到磁盘sda以及它的各个分区的统计数据，当时统计的磁盘总TPS是39.29，下面是各个分区的TPS。（因为是瞬间值，所以总TPS并不严格等于各个分区TPS的总和 1234567891011121314151617181920Linux 3.10.0-1062.1.1.el7.x86_64 (elk-1) 02/05/2020 _x86_64_ (8 CPU)Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 3.79 10.40 235.72 247.30 2109.42 19.15 0.28 1.13 21.62 0.22 0.33 8.24# 解释如下rrqm/s：每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge）；wrqm/s：每秒这个设备相关的写入请求有多少被Merge了。rsec/s：每秒读取的扇区数；wsec/：每秒写入的扇区数。rKB/s：The number of read requests that were issued to the device per second；wKB/s：The number of write requests that were issued to the device per second；avgrq-sz 平均请求扇区的大小avgqu-sz 是平均请求队列的长度。毫无疑问，队列长度越短越好。 await： 每一个IO请求的处理的平均时间（单位是微秒毫秒）。这里可以理解为IO的响应时间，一般地系统IO响应时间应该低于5ms，如果大于10ms就比较大了。 这个时间包括了队列时间和服务时间，也就是说，一般情况下，await大于svctm，它们的差值越小，则说明队列时间越短，反之差值越大，队列时间越长，说明系统出了问题。svctm 表示平均每次设备I/O操作的服务时间（以毫秒为单位）。如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长， 系统上运行的应用程序将变慢。%util： 在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8/1 = 80%，所以该参数暗示了设备的繁忙程度。一般地，如果该参数是100%表示设备已经接近满负荷运行了（当然如果是多磁盘，即使%util是100%，因为磁盘的并发能力，所以磁盘使用未必就到了瓶颈）。复制代码]]></content>
      <categories>
        <category>linux高阶命令</category>
      </categories>
      <tags>
        <tag>linux高阶命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git commit之后修改commit内容或者撤销commit操作说明]]></title>
    <url>%2F2019%2F12%2F12%2Fgit-commit%E4%B9%8B%E5%90%8E%E4%BF%AE%E6%94%B9commit%E5%86%85%E5%AE%B9%E6%88%96%E8%80%85%E6%92%A4%E9%94%80commit%E6%93%8D%E4%BD%9C%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[git commit 撤销 &amp; 修改commit内容 以下参考博客地址 撤销commit操作1git reset --soft HEAD^ # 只撤销commit操作，写的代码依然保留 HEAD^的意思是上一个版本，也可以写成HEAD~1如果你进行了2次commit，想都撤回，可以使用HEAD~2 –mixed意思是：不删除工作空间改动代码，撤销commit，并且撤销git add . 操作这个为默认参数,git reset –mixed HEAD^ 和 git reset HEAD^ 效果是一样的。 –soft不删除工作空间改动代码，撤销commit，不撤销git add . –hard删除工作空间改动代码，撤销commit，撤销git add . 注意完成这个操作后，就恢复到了上一次的commit状态 修改commit内容1git commit --amend 此时会进入默认vim编辑器，修改注释完毕后保存就好了]]></content>
      <categories>
        <category>Git基本操作技能</category>
      </categories>
      <tags>
        <tag>Git基本操作技能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty中lua获取nginx的参数]]></title>
    <url>%2F2019%2F08%2F07%2Fopenresty%E4%B8%ADlua%E8%8E%B7%E5%8F%96nginx%E5%86%85%E7%BD%AE%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[openresty学习之路的备忘录 获取uri12local uri = ngx.var.uri # 获取请求的uri,不带参数local uri = ngx.var.request_uri # 获取请求的uri,携带参数 字符串分割函数1234567891011function string.split(str, delimiter) if str == nil or str == '' or delimiter == nil then return nil end local result = &#123;&#125; for match in (str .. delimiter):gmatch("(.-)" .. delimiter) do table.insert(result, match) end return resultend 获取上游服务器ip地址1234-- 获取请求方的ipfunction get_request_ip() return ngx.var.http_x_forwarded_for and ngx.var.http_x_forwarded_for or ngx.var.remote_addrend 获取response内容12345-- 获取响应体内容 ngx.req.read_body() local postargs = ngx.req.get_post_args() local username = postargs["username"] ngx.log(ngx.ERR, '----username:',username, '----') 判断关键字是否在table中12345678910111213-- 排除的ID local limit_tb1 = &#123; 1222, 3232, 2121, &#125; local siteid = '1212' if siteid then if inTable(limit_tb1, tonumber(siteid)) then ngx.log(ngx.ERR, '排除的ID----- siteid: ', siteid) return end end]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty学习之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty学习路上的折腾]]></title>
    <url>%2F2019%2F08%2F07%2Fopenresty%E5%AD%A6%E4%B9%A0%E8%B7%AF%E4%B8%8A%E7%9A%84%E6%8A%98%E8%85%BE%2F</url>
    <content type="text"><![CDATA[openresty学习之路的备忘录 获取uri12local uri = ngx.var.uri # 获取请求的uri,不带参数local uri = ngx.var.request_uri # 获取请求的uri,携带参数]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty学习之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty在rewrite和access的处理逻辑顺序]]></title>
    <url>%2F2019%2F07%2F23%2Fopenresty%E5%9C%A8rewrite%E5%92%8Caccess%E7%9A%84%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[openresty在rewrite和access阶段的处理顺序 三种情况说明顺序 请求无缓存，先rewrite,再access 命中缓存,直接返回，走rewrite，无access HEAD请求不走rewrite，直接access]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elk日志收集系统使用备忘录]]></title>
    <url>%2F2019%2F07%2F14%2Felk%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录下工作中使用ELK系统的备忘录 version6.6.1 组件说明(记录下原理部分)公司业务采用架构为: filebeat+kafaka+zookeeper+logstash+elasticsearch+kibana+grafana Filebeat：filebat是一个用于转发和集中日志数据的轻量级shipper。作为代理安装在服务器上，filebeat监视指定的日志文件或位置，收集日志事件，并将它们转发给kafaka或者redis或者logstash进行索引 kafaka: Kafka是一种高吞吐量的分布式发布/订阅消息系统，这是官方对kafka的定义，kafka是Apache组织下的一个开源系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop平台的数据分析、低时延的实时系统、storm/spark流式处理引擎等。kafka现在它已被多家大型公司作为多种类型的数据管道和消息系统使用 zookeeper: ZooKeeper是一种为分布式应用所设计的高可用、高性能的开源协调服务，它提供了一项基本服务：分布式锁服务，同时，也提供了数据的维护和管理机制，如：统一命名服务、状态同步服务、集群管理、分布式消息队列、分布式应用配置项的管理等等 Logstash：Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到存储库 ElasticSearch：Elasticsearch 是基于 JSON 的分布式搜索和分析引擎，专为实现水平扩展、高可靠性和管理便捷性而设计 Kibana：Kibana 能够以图表的形式呈现数据，并且具有可扩展的用户界面，供您全方位配置和管理 Elastic Stack kafaka常用命令整理1234567891011121314151617181920212223# 显示topic列表bin/kafka-topics.sh --zookeeper zk1:2181,zk2:2181,zk3:2181 --list 也可以从一个节点上查看。下面简写查看一个节点。# 创建一个topic，并指定topic属性（副本数、分区数等）bin/kafka-topics.sh --create --zookeeper zk1:2181 --replication-factor 1 --partitions 3 --topic test - --partitions应等于或大于消费者# 查看某个topic的状态bin/kafka-topics.sh --zookeeper zk1:2181 --topic test --describe# 生产消息bin/kafka-console-producer.sh --broker-list kafka1:9092 --topic test # 消费消息bin/kafka-console-consumer.sh --bootstrap-server PLAINTEXT://kafka1:9092 --topic test# 查看实时消息，如果从头看可在后面加 --from-beginning kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning# 删除topicbin/kafka-topics.sh --delete --zookeeper zk1:2181 --topic test elasticsearch常用命令整理1234567891011# 查看集群状态curl http://127.0.0.1:9200/_cat/health?v # 查看集群节点curl http://127.0.0.1:9200/_cat/nodes?v# 查看索引列表curl http://127.0.0.1:9200/_cat/indices?v# 删除索引curl -XDELETE http://127.0.0.1:9200/索引名?pretty logstash正则匹配备忘录(%{URIPATHPARAM:uri}|-) # 匹配uri(%{GREEDYDATA:uri}|-) # 匹配uri 以上这两个的区别为: 在grok中，(%{URIPATHPARAM:uri}|-) 会解析出来多个字段，匹配uri带参数，并解析出URIPATH和URIPARAM ,GREEDYDATA匹配到url和参数值 例如: 12345678910111213141516171819日志: /www.baidu.com/sousuo/logstash/test/url/a/b/c?a=1grok正则为: (%&#123;URIPATHPARAM:uri&#125;) "uri": [ [ "/www.baidu.com/sousuo/logstash/test/url/a/b/c" ] ], "URIPATH": [ [ "/www.baidu.com/sousuo/logstash/test/url/a/b/c" ] ], "URIPARAM": [ [ "?a=1" ] ], grok的正则案例12]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix和grafana使用备忘录]]></title>
    <url>%2F2019%2F07%2F14%2Fzabbix%E5%92%8Cgrafana%E4%BD%BF%E7%94%A8%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[zabbix和grafana使用备忘录 注释事项 在整套环境中，需要确保各个节点的版本号一致性，在生产环境中出现问题12345# zabbix-proxy提示cannot send list of active checks to "10.10.6.3": host [test-3] not found# zabbix-agent提示no active checks on server [10.10.2.1:10051]: host [test-3] not found 以上问题，发现zabbix-proxy和zabbix-server版本不一致导致 port备注zabbix-server: 10051zabbix-proxy: 10051zabbix-agent: 10050 docker proxy run1docker run --name dayu-zabbix-proxy-sqlite3 --restart=always -v /etc/hosts:/etc/hosts -e ZBX_HOSTNAME=lc -e ZBX_SERVER_HOST=35.194.200.24 -p 10051:10051 -d zabbix/zabbix-proxy-sqlite3:latest zabbix的相关介绍应用集包含多个监控项监控项是具体的 数据定义的key值触发器用来 指定监控项的阈值进行报警]]></content>
      <categories>
        <category>监控</category>
      </categories>
      <tags>
        <tag>zabbix&amp;&amp;grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[因业务问题,nginx负载均衡时容错机制引发的问题]]></title>
    <url>%2F2019%2F07%2F12%2F%E5%9B%A0%E4%B8%9A%E5%8A%A1%E9%97%AE%E9%A2%98-nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%97%B6%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6%E5%BC%95%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[线上的tomcat发起了一次请求，在nginx代理转发的时候，后端收到了2次请求 这样的场景，如果在代码程度未能控制好多次请求造成的损耗，就会出现业务上的bug问题 因是支付请求，所以一笔转账在nginx的容错机制下，server1未能在超时时间内正常相应，继续转发到server2请求，一笔支付的请求就会发生2次转账了 从技术的角度上，深入了解下nginx负载均衡时，容错机制是如何实现的? 参考博客地址 以下内容为转载，博客地址如上. nginx就是常用的一种HTTP和反向代理服务器，支持容错和负载均衡nginx的重试机制就是容错的一种 主要有两部分配置: upstream server 和proxy_pass 1234upstream backend &#123; server 127.0.0.1:8081 max_fails=2 fail_timeout=10s weight=1; server 127.0.0.1:8082 max_fails=2 fail_timeout=10s weight=1;&#125; 通过配置上有服务器的max_fails 和fail_timeout，来指定每个上有服务器，当fail_timeout时间内失败了max_fails次请求，则认为该上游服务器不可用/不存活，然后会摘掉该上有服务器，fail_timeout时间后会再次将该服务器加入到存活上有服务器列表进行重试. 在nginx的配置文件中，proxy_next_upstream项定义了什么情况下进行重试，官网文档中给出的说明如下： 12341.Syntax: proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...; 2.Default: proxy_next_upstream error timeout; 3.Context: http, server, location 默认情况下，当请求服务器发生错误或超时时，会尝试到下一台服务器。 还有一个参数影响了重试的次数：proxy_next_upstream_tries，官方文档中给出的说明如下： 12341.Syntax: proxy_next_upstream_tries number; 2.Default: proxy_next_upstream_tries 0; 3.Context: http, server, location 4.This directive appeared in version 1.7.5. 具体配置: 1234upstream backend_server &#123; server 192.168.61.1:9080 max_fails=2 fail_timeout=10s weight=1; server 192.168.61.1:9090 max_fails=2 fail_timeout=10s weight=1;&#125; 12345678910111213server &#123; …… location /test &#123; proxy_connect_timeout 5s; proxy_read_timeout 5s; proxy_send_timeout 5s; proxy_next_upstream error timeout; proxy_next_upstream_timeout 0; proxy_next_upstream_tries 0; proxy_pass http://backend_server; add_header upstream_addr $upstream_addr; &#125;&#125; backend_server定义了两个上游服务器192.168.61.1:9080（返回hello）和192.168.61.1:9090（返回hello2）。 如上指令主要有三组配置：网络连接/读/写超时设置、失败重试机制设置、upstream存活超时设置。 网络连接/读/写超时设置。 proxy_connect_timeout time：与后端/上游服务器建立连接的超时时间，默认为60s，此时间不超过5s。 proxy_read_timeout time：设置从后端/上游服务器读取响应的超时时间，默认为60s，此超时时间指的是两次成功读操作间隔时间，而不是读取整个响应体的超时时间，如果在此超时时间内上游服务器没有发送任何响应，则Nginx关闭此连接。 proxy_send_timeout time：设置往后端/上游服务器发送请求的超时时间，默认为60s，此超时时间指的是两次成功写操作间隔时间，而不是发送 整个请求的超时时间，如果在此超时时间内上游服务器没有接收任何响应，则Nginx关闭此连接。 对于内网高并发服务，请根据需要调整这几个参数，比如内网服务TP999为1s，可以将连接超时设置为100~500毫秒，而读超时可以为1.5~3秒左右。 失败重试机制设置。 proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 |http_403 | http_404 | non_idempotent | off …：配置什么情况下需要请求下一台上游服务器进行重试。默认为“errortimeout”。error表示与上游服务器建立连接、写请求或者读响应头出错。 timeout表示与上游服务器建立连接、写请求或者读响应头超时。invalid_header表示上游服务器返回空的或错误的响应头。 http_XXX表示上游服务器返回特定的状态码。 non_idempotent表示RFC-2616定义的非幂等HTTP方法（POST、LOCK、PATCH），也可以在失败后重试下一台上游服务器（即默认幂等方法GET、HEAD、PUT、DELETE、OPTIONS、TRACE才可以重试）。 off表示禁用重试。 重试不能无限制进行，因此，需要如下两个指令控制重试次数和重试超时时间。 proxy_next_upstream_tries number：设置重试次数，默认0表示不限制，注意此重试次数指的是所有请求次数（包括第一次和之后的重试次数之和）。 proxy_next_upstream_timeout time：设置重试最大超时时间，默认0表示不限制。 即在proxy_next_upstream_timeout时间内允许proxy_next_upstream_tries次重试。如果超过了其中一个设置，则Nginx也会结束重试并返回客户端响应（可能是错误码）。 如下配置表示当error/timeout时重试upstream中的下一台上游服务器，如果重试的总时间超出了6s或者重试了1次，则表示重试失败（因为之前已经请求一次了，所以还能重试一次），Nginx结束重试并返回客户端响应。 proxy_next_upstream error timeout; proxy_next_upstream_timeout 6s; proxy_next_upstream_tries 2; 不了解这个机制，在日常开发web服务的时候，就可能会踩坑。 比如有这么一个场景： 一个用于导入数据的web页面，上传一个excel，通过读取、处理excel，向数据库中插入数据，处理时间较长（如1分钟），且为同步操作（即处理完成后才返回结果）。暂且不论这种方式的好坏，若nginx配置的响应等待时间（proxy_read_timeout）为30秒，就会触发超时重试，将请求又打到另一台。如果处理中没有考虑到重复数据的场景，就会发生数据多次重复插入！ 或者发送短信的业务功能,发送的业务时间超时，也会引起发送了多条的短信信息；]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flock用法详解备忘录]]></title>
    <url>%2F2019%2F07%2F08%2Fflock%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[配置在crontab的任务计划 针对命令执行操作的排它锁设置 flock命令flock详解命令博客地址 1flock -xn /var/run/flocktest.lock -c 'echo "hello world!!"']]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>flock命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker配置代理pull镜像]]></title>
    <url>%2F2019%2F07%2F08%2Fdocker%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86pull%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[业务场景需要，安装docker的主机没有外网环境，需要走代理pull镜像 配置代理12345678910111213141516# 创建目录mkdir /etc/systemd/system/docker.service.d# 新建文件touch /etc/systemd/system/docker.service.d/http-proxy.conf# 内容如下:[Service]Environment="HTTP_PROXY=http://proxy.ip.com:10080"# reload系统服务systemctl daemon-reloadsystemctl restart docker#检查变量是否加载systemctl show docker --property Environment]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux进程相关]]></title>
    <url>%2F2019%2F07%2F02%2Flinux%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[作为运维管理人员，如果linux内核了解甚少，就会对系统出现问题的时候束手无策 特收集一些工作中遇到的问题，查阅的资料整理 linux打开的进程数限制1cat /proc/sys/kernel/pid_max]]></content>
      <categories>
        <category>linux内核</category>
      </categories>
      <tags>
        <tag>linux内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产环境swarm集群的节点正常下线操作]]></title>
    <url>%2F2019%2F06%2F26%2F%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83swarm%E9%9B%86%E7%BE%A4%E7%9A%84%E8%8A%82%E7%82%B9%E6%AD%A3%E5%B8%B8%E4%B8%8B%E7%BA%BF%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[检查业务高可用配置在重启容器服务节点前，建议先检查或修正如下业务配置，以避免节点重启触发单点异常，进而导致业务可用性受损： 配置数据持久化策略建议为日志、业务配置等重要数据配置外部卷进行数据持久化，以避免容器重建后，原有容器被删除引发数据丢失。 关于容器服务数据卷的使用，可以参阅 产品文档。 配置重启策略建议为相应业务服务配置 restart: always 自重启策略，以便节点重启后，相应容器能自动拉起。 配置高可用策略建议结合产品架构，为相应业务配置 可用区调度(availability:az 属性)、指定节点调度（affinity、constraint 属性) 和 指定多节点调度（constraint 属性） 等亲和性、互斥性策略，以避免由于相应节点重启引发单点异常。比如，对于数据库业务，建议主备或多实例部署，然后结合前述特性，确保不同实例落在不同节点上，并且相关节点不会同时重启。 操作最佳实践建议首先参阅前述说明，检查业务高可用性配置。然后 在每个节点上（切忌同时对多个节点进行操作），依次按如下步骤操作： 4.1 快照备份：建议先对节点所有关联磁盘创建最新快照进行备份，以避免由于长时间未重启服务器，导致节点关机后启动过程中出现异常导致业务可用性受损。 4.2 验证业务容器配置有效性（Swarm Mode 集群忽略）：对于非 Swarm Mode 集群，重启节点上的相应业务容器，确保容器能正常被重新拉起。说明：Swarm Mode 集群的最小控制操作单元是服务。所以，不能直接在 Swarm Mode 集群节点上通过 docker start/stop 等操作直接处理业务容器，否则会引发相关报错。正确的做法，是在 容器服务管理控制台 通过重新 调整应用的 REPLICAS 的方式来对业务做自动调整。 4.3 修改节点角色（Swarm Mode 集群）如果相应节点是 Swarm Mode 集群内的 Manager 节点，则先将其 设置为 Worker 节点。 4.4 验证 Docker Engine 运行有效性尝试重启 docker daemon ，确保 docker enginger 能正常重新启动。 4.5 执行相关运维操作执行计划内的相关运维操作，比如业务代码更新、系统补丁安装、系统配置调整等。 4.6 重启节点在控制台或系统内部，正常重启节点。 4.7 重启后状态检查重启完节点后，到 容器服务管理控制台 ,检查节点健康状态，检查业务容器运行状态。 4.8 回调节点角色（Swarm Mode 集群）如果相应节点是 Swarm Mode 集群内的 Manager 节点，则先将其重新 设置为 Manager 节点。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty的lua代码备忘录]]></title>
    <url>%2F2019%2F06%2F04%2Fopenresty%E7%9A%84lua%E4%BB%A3%E7%A0%81%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[openresty中使用的lua代码学习记录 字符串分割函数1234567891011function string.split(str, delimiter) if str == nil or str == '' or delimiter == nil then return nil end local result = &#123;&#125; for match in (str .. delimiter):gmatch("(.-)" .. delimiter) do table.insert(result, match) end return resultend 获取上有服务器ip地址1234-- 获取请求方的ipfunction get_request_ip() return ngx.var.http_x_forwarded_for and ngx.var.http_x_forwarded_for or ngx.var.remote_addrend]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum指定包下载并包括依赖包命令备忘录]]></title>
    <url>%2F2019%2F05%2F20%2Fyum%E6%8C%87%E5%AE%9A%E5%8C%85%E4%B8%8B%E8%BD%BD%E5%B9%B6%E5%8C%85%E6%8B%AC%E4%BE%9D%E8%B5%96%E5%8C%85%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[在linux运维工作中，难免遇到需要离线安装一些包的，就需要先下载包并解决依赖关系，将依赖包也一并下载这时就要借助yum –downloadonly这个命令了 命令备忘录123456# --downloaddir指定下载的目录yum install --downloadonly --downloaddir=/tmp &lt;package -name&gt;# 如果包已经安装在本地的，使用reinstall下载yum install --downloadonly --downloaddir=/tmp &lt;package -name&gt;]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kibana查询语法备忘录]]></title>
    <url>%2F2019%2F04%2F09%2Fkibana%E6%9F%A5%E8%AF%A2%E8%AF%AD%E6%B3%95%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[使用kibana查询日志 语法备忘录 字段查询field: value 通配符? 匹配单个字符 例： H?bbs 匹配0到多个字符 例： H注意： ? 不能用作第一个字符，例如： ?text *text 范围查询age:[20 TO 30] age:{20 TO 30} 注：[ ] 表示端点数值包含在范围内，{ } 表示端点数值不包含在范围内 转义特殊字符 &amp;&amp; || ! () {} [] ^” ~ * ? : \]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的rewrite用法详解-摘抄备忘录]]></title>
    <url>%2F2019%2F03%2F31%2Fnginx%E7%9A%84rewrite%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3-%E6%91%98%E6%8A%84%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[备忘录: nginx的rewrite指令详解 参考文章: nginx的rewrite用法及常用rewrite讲解 nginx的rewrite用法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# rewrite 匹配模式 替换模式 [flag];rewrite ^(.*)$ /index.php$1 last;# 注释:^(.*)$ 匹配模式，表示匹配所有/index.php$1 替换模式，$1为(.*)中匹配的位置参数last 修饰符flag``` 修饰符的分类:- last: 表示当前的重写规则是最后的应用，在这条规则之后新额URL被nginx处理并且查找一个location区段，后面的rewrite指令将被忽略- break: 当前的重写规则被应用后，对于替换的URL不再重新搜索，后面的rewrite指令也将被忽略- redirect: 返回302重定向,并且通过一个替代的URL作为location的头，浏览器地址显示跳转后的URL地址- permanent:返回301永久重定向，浏览器地址会显示跳转后的URL地址. # rewrite中的条件结构nginx的if判断表达式- =或!=：表示变量等于(当操作符为=时)某个值或者变量不等于(!=)某个值时条件为真- - ~或!~：当变量匹配(~)或不匹配(!~)变个模式时条件为真（区分大小写）- - ~或!~：当变量匹配(~)或不匹配(!~)变个模式时条件为真（不区分大小写）- - -f 或!-f:表示文件存在(-f)或者文件不存在(!-f)- - -d或者!-d表示目录存在或者不存在- - -e或者!-e表示文件或目录存在或者不存在- - -x或!-x:表示文件是否存在并且可执行# rewrite中的指令1. break: 阻止后面的rewrite指令2. return: 中断请求，并且返回一个HTTP状态码 return 403;3. set: 初始化或者设置一个变量 set $X_system 'test-values';# rewrite指令的几个例子```bash# 判断如果请求的文件路径不存在，改写地址，在wordpress后面加上/index.php/$1为匹配的源url /wordpress/后面的路径location /wordpress/ &#123; if (!-e $request_filename) &#123; rewrite ^/wordpress/(.*)$ /wordpress/index.php/$1 last; &#125;&#125;#---------以下为主要描述使用rewrite匹配，然后改写url请求# 访问路径: category-3-b0-min0-max0-attr0.0.160.186-GSM%E6%89%8B%E6%9C%BA.html# 改写地址: category.php?id=3&amp;brand=0&amp;price_min=0&amp;price_max=0&amp;filter_attr=0.0.160.186rewrite ^(.*)/category-(d+)-b(d+)-min(d+)-max(d+)-attr((d+.)+d+)-(.*).html$ $1/category.php?id=$2&amp;brand=$3&amp;price_min=$4&amp;price_max=$5&amp;filter_attr=$6 last;# 访问地址: article-9-售后流程.html# 改写地址: article.php?id=9rewrite ^(.*)/article-(d+)-(.*).html$ $1/article.php?id=$2 last;]]></content>
      <categories>
        <category>nignx</category>
      </categories>
      <tags>
        <tag>nginx的rewrite指令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx安全认证-设置用户名和密码进行web访问]]></title>
    <url>%2F2019%2F03%2F22%2FNginx%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81-%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E5%AF%86%E7%A0%81%E8%BF%9B%E8%A1%8Cweb%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[有一些服务的监控软件，默认是没有权限管理功能，比如ELK rocketmq-consle web控制台 所以使用nginx作为代理，部署基于用户认证机制登录控制台 生成验证用户名和密码123456# htpasswd 需要安装httpd-tools工具[root@sun vhost]# htpasswd -c -d /usr/local/nginx/passwd.db ops //创建web认证账号，ops为用户名 New password: ******* //认证密码Re-type new password: ******** //再次确认认证密码 Adding password for user ops[root@sun vhost]# chmod 400 /usr/local/nginx/passwd.db nginx中设置在nginx.conf的server或单独站点配置文件的server中（比如绑定域名代码下方）添加如下代码1234567891011server &#123; listen 80; server_name beijinggushi.com; include conf.d/ip_allow.ini; auth_basic "secret"; #添加此配置 auth_basic_user_file /usr/local/openresty/nginx/conf/conf.d/passwd.db; #加载生成的密码文件 location / &#123; proxy_pass http://10.10.2.1:8080; &#125;&#125; 重载nginx1nginx -s reload]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rocketmq重点知识笔记]]></title>
    <url>%2F2019%2F03%2F20%2Frocketmq%E9%87%8D%E7%82%B9%E7%9F%A5%E8%AF%86%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[工作中，软件架构用到了rocketmq的集群，对rocketmq不太熟悉，在出现问题的时候，没有思路去排查问题，特此从网上查阅技术文档，了解相关知识 方便在出现问题的时候，第一时间追述到问题根源 参考的网络博客地址 RocketMQ集群部署方式总结rocketmq集群部署实战-双master-双slave-同步双写-异步刷盘rocketmq技术术语rocketmq源码分析高可用 rocketmq配置文件注释[root@rocketmq-7 conf]# tree -L 1.├── 2m-2s-async # 多Master多Slave模式，异步复制模式├── 2m-2s-sync # 多Master多Slave模式，同步双写├── 2m-noslave # 多Master模式├── 3m-3s-sync├── logback_broker.xml├── logback_filtersrv.xml├── logback_namesrv.xml├── logback_tools.xml├── main└── nm-ns-sync 6 directories, 4 files 在rocketmq中部署集群，根据brokerId判断主从关系，brokerId=0,表示master，非0表示slave 主配置文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0表示Master &gt;0表示SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=192.168.1.101:9876;192.168.1.102:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建TopicautoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/alibaba-rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/alibaba-rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/alibaba-rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/alibaba-rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/alibaba-rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/alibaba-rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=ASYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128 rocketmq集群的几种模式单个Master这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用，不建议线上环境使用 多Master模式一个集群无 Slave，全是 Master，例如 2 个 Master 或者 3 个 Master优点：配置简单，单个Master 宕机或重启维护对应用无影响，在磁盘配置为RAID10 时，即使机器宕机不可恢复情况下，由与 RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢）。性能最高。缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到受到影响。先启动 NameServer在机器 A，启动第一个 Master在机器 B，启动第二个 Master 多Master多Slave模式,异步复制每个 Master 配置一个 Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟，毫秒级。优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，因为Master 宕机后，消费者仍然可以从 Slave消费，此过程对应用透明。不需要人工干预。性能同多 Master 模式几乎一样。缺点：Master 宕机，磁盘损坏情况，会丢失少量消息。先启动 NameServer在机器 A，启动第一个 Master在机器 B，启动第二个 Master在机器 C，启动第一个 Slave在机器 D，启动第二个 Slave 多Master多Slave模式，同步双写每个 Master 配置一个 Slave，有多对Master-Slave，HA采用同步双写方式，主备都写成功，向应用返回成功。优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高缺点：性能比异步复制模式略低，大约低 10%左右，发送单个消息的 RT会略高。目前主宕机后，备机不能自动切换为主机，后续会支持自动切换功能。先启动 NameServer在机器 A，启动第一个 Master在机器 B，启动第二个 Master在机器 C，启动第一个 Slave在机器 D，启动第二个 Slave以上 Broker 与 Slave 配对是通过指定相同的brokerName 参数来配对，Master的 BrokerId 必须是 0，Slave 的BrokerId 必须是大与 0 的数。另外一个 Master下面可以挂载多个 Slave，同一 Master 下的多个 Slave通过指定不同的 BrokerId来区分。 rocketmq集群启动顺序启动顺序总结：1、先启动nameser集群所有节点 2、启动Broker所有的master节点 3、启动Broker所有slave节点 rocketmq-console控制台管理github地址:rocketmq-console 总结部分在生产环境中，部署rocketmq集群时，遇到的问题,在启动mqnamesrv的时候，启动失败，日志提示service or host not know,分析问题原因，rocketmq运行在docker容器中,mqnamesrv启动的时候，获取到主机名，不能解析主机名的ip地址，解决办法尝试在/etc/hosts中添加 127.0.0.1 [主机名] ,重新启动 解决问题 mqnamesrv集群中，各节点的namesrv互不通信，brocker将注册信息注册在各个namesrv中，producer生产消息，consumer消费信息namesrv只提供可用的broker提供给消费者消费消息]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>rocketmq笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chrony时间同步详解]]></title>
    <url>%2F2019%2F03%2F19%2Fchrony%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[时间同步服务chrony 因线上部署业务服务，由于系统时间总是和互联网时间有落差，造成业务访问有问题，所以更改系统同步互联网时间centos7已经默认使用chrony来同步时间，默认服务为chronyd 简单笔记下,chronyd的相关服务配置，命令使用,方便后续查阅 chronyd 是一个 daemon 守护进程，chronyc 是用来监控 chronyd 性能和配置参数的命令行工具 chrony的主配置文件: /etc/chrony.conf12345678910#chrony.conf配置文件注释# 上游公共ntp服务器server 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst#-----如果此服务器为服务端，允许的客户端连接# Allow NTP client access from local network.#allow 192.168.0.0/16 启动服务:1234systemctl enable chronyd #配置开机自启动systemctl start chronyd #启动chrony服务# 如果客户端同步服务端时间，防火墙开启ntp服务即可, ntp使用123/udp端口协议 查看时间同步命令12345timedatectl # 查看当前系统时区timedatectl list-timezones # 列出所有可用的时区timedatectl set-timezone Asia/Shanghai # 设置系统为Asia/Shanghai 上海时区 CSTtimedatectl status # 查看时间同步状态timedatectl set-ntp true # 开启网络时间同步 chronyc用法1234567891011121314## 查看 ntp_servers 状态chronyc sources -v## 查看 ntp_sync 状态chronyc sourcestats -v## 查看 ntp_servers 是否在线chronyc activity -v## 查看 ntp 详细信息chronyc tracking -v## 校准时间服务器chronyc tracking 客户端同步server的配置文件修改123# ----chrony.conf# 修改server的地址即可server [server端的ip地址] iburst]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>chrony</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的url匹配,location和proxy_pass以/结尾的问题]]></title>
    <url>%2F2019%2F03%2F17%2Fnginx%E7%9A%84url%E5%8C%B9%E9%85%8D-location%E5%92%8Cproxy-pass%E4%BB%A5-%E7%BB%93%E5%B0%BE%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[工作中遇到nginx的location 和proxy_pass 有无/(根)结尾的区别 在location中匹配的url最后有无/结尾，指的是模糊匹配与精确匹配的问题在proxy_pass中代理的url最后有无/结尾，指的是在proxy_pass 指定的url后要不要加上location匹配的url的问题 几种例子说明此问题 location只判断是模糊匹配还是精确匹配 1)没有&quot;/&quot;结尾时，location /abc/def 可以匹配/abc/defghi的请求，也可以匹配/abc/def/ghi ...... 2)有&quot;/&quot;结尾时,location /abc/def/ 不能匹配/abc/defghi的请求，只能精确匹配 /abc/def/ghi这样的请求 访问的url: http://blog.com/proxy/login.html1234567891011121314151617181920212223#情况1location /proxy/ &#123; proxy_pass http://myblog.com:8000/;&#125;# proxy_pass的最终地址就是: http://myblog.com:8000/login.html 因为proxy_pass 以/跟结尾，代表绝对路径，所以不会加上location匹配的proxy#情况2location /proxy/ &#123; proxy_pass http://myblog.com:8000;&#125;#proxy_pass 代理到 http://myblog.com:8000/proxy/login.html#情况3location /proxy/ &#123; proxy_pass http://myblog.com:8000/disquz/;&#125;#proxy_pass 代理到http://myblog.com:8000/disquz/login.html#情况4location /proxy/ &#123; proxy_pass http://myblog.com:8000/disquz;&#125;#proxy_pass 代理到http://myblog.com:8000/disquzlogin.html]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>/结尾的匹配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看linux性能相关命令详解]]></title>
    <url>%2F2019%2F03%2F15%2F%E6%9F%A5%E7%9C%8Blinux%E6%80%A7%E8%83%BD%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在工作中，会因为业务量比较庞大，访问qps比较高，会造成服务器负载比较高本文描述一些常用的排查系统性能瓶颈工具 uptimeuptime用来查看系统的负载1234[#1#root@proxy-server ~]# uptime 16:05:37 up 167 days, 8 min, 2 users, load average: 15.05, 14.83, 14.83#注释 开机时间 运行的时间 当前用户 负载 load average: 15.05, 14.83, 14.83 # 显示的是1分钟 5分钟 15分钟内的平均负载 查看CPU相关命令说明mpstat123456789101112131415Linux 3.18.27 (a1) 03/19/2019 _x86_64_ (24 CPU)02:31:57 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle02:31:57 PM all 23.11 0.00 1.56 0.39 0.00 1.33 0.00 0.00 0.00 73.60# ------------注释CPU 处理器IDuser 在internal时间段里，用户态的CPU时间（%），不包含 nice值为负进程 nice 在internal时间段里，nice值为负进程的CPU时间（%） system 在internal时间段里，核心时间（%） iowait 在internal时间段里，硬盘IO等待时间（%） irq 在internal时间段里，硬中断时间（%）soft 在internal时间段里，软中断时间（%） idle 在internal时间段里，CPU除去等待磁盘IO操作外的因为任何原因而空闲的时间闲置时间 （%)intr/s 在internal时间段里，每秒CPU接收的中断的次数 vmstatvmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写, 是实时系统监控工具。该命令通过使用knlist子程序和/dev/kmen伪设备驱动器访问这些数据，输出信息直接打印在屏幕。vmstat反馈的与CPU相关的信息包括：（1）多少任务在运行（2）CPU使用的情况（3）CPU收到多少中断（4）发生多少上下文切换 sarsar是System Activity Reporter（系统活跃情况报告）的缩写。顾名思义，sar工具将对系统当前的状态进行采样，然后通过计算数据和比例来表达系统的当前运行状态。它的特点是可以连续对系统采样，获得大量的采样数据；采样数据和分析的结果都可以存入文件，所需的负载很小。这些是检查历史数据和一些近来的系统事件。sar 用于检查的性能数据类似于vmstat, mpstat和 iostat的显示。 sar的数据是一段时间保存的内容，因此可以察看过去的信息。 lastcomm可以现在系统最近被执行的命令。这些可以用在系统审计中。sar可以在BSD和Linux中找到，它给用户在系统审计中更多的选项来收集信息。 在反馈CPU整体信息方面，sar 反馈的与CPU相关的信息包括：（1）多少任务在运行（2）CPU使用的情况（3）CPU收到多少中断（4）发生多少上下文切换 内存相关free1free -mh 网络相关nload 进程相关lsof命令详解]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>linux系统性能分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker swarm 一些理论知识手册]]></title>
    <url>%2F2019%2F03%2F13%2Fdocker-swarm-%E4%B8%80%E4%BA%9B%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[生产环境使用docker swarm深入理解部分 docker service update更新操作docker service update –image tomcat:9.0 my_tomcat Swarm将按照如下步骤执行滚动更新:(如果有多副本的情况下) 停止第一个副本。 调度任务，选择 worker node。 在 worker 上用新的镜像启动副本。 如果副本（容器）运行成功，继续更新下一个副本；如果失败，暂停整个更新过程。 默认配置下，Swarm 一次只更新一个副本，并且两个副本之间没有等待时间。我们可以通过 –update-parallelism 设置并行更新的副本数目，通过 –update-delay 指定滚动更新的间隔时间 docker service update --replicas 6 --update-parallelism 2 --update-delay 1m30s my_web service 增加到六个副本，每次更新两个副本，间隔时间一分半钟 Swarm 还有个方便的功能是回滚，如果更新后效果不理想，可以通过 –rollback 快速恢复到更新之前的状态请注意，–rollback 只能回滚到上一次执行 docker service update 之前的状态，并不能无限制地回滚 docker swarm调度策略Swarm 调度器调度是集群中十分重要的功能，Swarm目前支持三种调度策略：Spread、Binpack和random。 在执行swarm manage启动管理服务时，可通过–strategy参数指定调度策略，默认是：spread。 三种调度策略的优缺点： spread： 配置相同情况下，选择一个正在运行的容器数量最少的那个节点，平摊容器到各个节点。 binpack：尽可能将所有容器放在一台节点上运行，尽量少用节点，避免容器碎片化。 random： 直接随机分配，不考虑集群节点状态，方便进行测试使用 docker swarm中管理节点高可用的个数通常为了保证 Manager 节点的高可用，Docker 建议采用奇数个 Manager 节点，这样的话，你可以在 Manager 失败的时候不用关机维护，我们给出如下的建议： 3 个 Manager 节点最多可以同时容忍 1 个 Manager 节点失效的情况下保证高可用；5 个 Manager 节点最多可以同时容忍 2 个 Manager 节点失效的情况下保证高可用；N 个 Manager 节点最多可以同时容忍 (N−1)/2个 Manager 节点失效的情况下保证高可用；Docker 建议最多最多的情况下，使用 7 个 Manager 节点就够了，否则反而会降低集群的性能了]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker容器资源监控]]></title>
    <url>%2F2019%2F02%2F17%2Fdocker%E5%AE%B9%E5%99%A8%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[docker容器资源使用情况查看 查看docker容器使用的资源docker自带命令 docker stats参考链接地址 123456789101112131415161718[root@host-1 #] docker stats #每隔一秒钟刷新一次占用资源率CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDSfff30dce8883 2.56% 254.9MiB / 31.38GiB 0.79% 1.96TB / 313GB 234MB / 297MB 2174f662d20c98 0.15% 2.629GiB / 31.38GiB 8.38% 17.1MB / 10.5MB 33GB / 159MB 8355fb6ad03195 8.42% 209.2MiB / 31.38GiB 0.65% 7.47TB / 288GB 17.1MB / 51MB 5a992e1d7c6d4 2.40% 152.9MiB / 31.38GiB 0.48% 5.81TB / 237GB 20.1MB / 55.4MB 503c44c7c20a5 0.06% 190.5MiB / 31.38GiB 0.59% 2.01GB / 1.15GB 124MB / 2.12GB 40412c040b2db1 2.22% 3.462GiB / 31.38GiB 11.03% 17.8GB / 12.5GB 3.66GB / 2.23GB 138# 注释[CONTAINER]：以短格式显示容器的 ID。[CPU %]：CPU 的使用情况。[MEM USAGE / LIMIT]：当前使用的内存和最大可以使用的内存。[MEM %]：以百分比的形式显示内存使用情况。[NET I/O]：网络 I/O 数据。[BLOCK I/O]：磁盘 I/O 数据。 [PIDS]：PID 号 123docker stats --no-stream # 显示当前使用的资源率docker stats --no-stream registry &lt;容器ID&gt;docker stats $(docker ps --format=&#123;&#123;.Names&#125;&#125;) #CONTAINER 列显示容器的名称，而不是ID 12345678910111213141516171819#格式化输出结果# 1. 自定义输出内容docker stats --format "table &#123;&#123;.Name&#125;&#125;\t&#123;&#123;.CPUPerc&#125;&#125;\t&#123;&#123;.MemUsage&#125;&#125;"# 可以自定义的名称.Container 根据用户指定的名称显示容器的名称或 ID。.Name 容器名称。.ID 容器 ID。.CPUPerc CPU 使用率。.MemUsage 内存使用量。.NetIO 网络 I/O。 .BlockIO 磁盘 I/O。.MemPerc 内存使用率。.PIDs PID 号# 2. 以json格式输出docker stats --no-stream --format \ "&#123;\"container\":\"&#123;&#123; .Container &#125;&#125;\",\"memory\":&#123;\"raw\":\"&#123;&#123; .MemUsage &#125;&#125;\",\"percent\":\"&#123;&#123; .MemPerc &#125;&#125;\"&#125;,\"cpu\":\"&#123;&#123; .CPUPerc &#125;&#125;\"&#125;"]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker资源使用情况查看</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty借助lua实现动态跳转https，动态获取证书内容响应]]></title>
    <url>%2F2019%2F02%2F10%2Fopenresty%E5%80%9F%E5%8A%A9lua%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E8%B7%B3%E8%BD%AChttps%EF%BC%8C%E5%8A%A8%E6%80%81%E8%8E%B7%E5%8F%96%E8%AF%81%E4%B9%A6%E5%86%85%E5%AE%B9%E5%93%8D%E5%BA%94%2F</url>
    <content type="text"><![CDATA[内容描述: 借助openresty通过lua代码实现动态跳转https，并动态获取证书 nginx.conf配置文件1234567891011121314151617181920server &#123; listen 80; # 跳转https rewrite_by_lua 'rewrite_https("site")'; include /usr/local/openresty/nginx/conf/gb/site/facadehost_common.conf;&#125;server &#123; listen 443 ssl; ssl on; # ssl_certificate ssl_certificate_key用于满足Nginx配置的占位符 ssl_certificate /usr/local/openresty/nginx/conf/ssl/nginx.pem; ssl_certificate_key /usr/local/openresty/nginx/conf/ssl/nginx.key.pem; # 通过ssl_certificate_by_lua_file动态读取证书内容 ssl_certificate_by_lua_file /usr/local/openresty/nginx/script/lua/dynamicssl.lua; include /usr/local/openresty/nginx/conf/site/facadehost_common.conf; # location的存放文件&#125; 以上的配置文件，客户访问80端口，通过rewrite_by_lua 读取rewrite_https函数方法，满足条件跳转https, rewrite_https函数 定义在init.lua文件中，通过在http区域加载初始化lua代码导入这块不理解的可以看openresty处理请求的流程图 openresty执行阶段概念 1234567http &#123; include mime.types; lua_package_path "/usr/local/openresty/nginx/script/lua/?.lua;;"; init_by_lua_file /usr/local/openresty/nginx/script/lua/init.lua; lua_shared_dict lua_cache 128m; ...... init.lua12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455-- 是否强制httpsfunction is_force_ssl(stype) local value = get_env_var(stype, 'is_force_ssl') # 通过get_env_var函数读取json文件，判断is_force_ssl的值对应什么(通过json文件灵活配置是否跳转https) if value == nil then value = 'false' end return valueend--检查当前访问的域名是否有对应的ssl证书，用于是否强制跳转https的判断function is_have_ssl() local server_name = ngx.var.host local is_have_ssl = 'true' if server_name ~= nil then server_name = string.gsub(server_name, "^www%.", "") # www和顶级域名公用一份证书文件 local file = io.open("/usr/local/openresty/nginx/conf/ssl/" .. server_name .. ".pem") if file == nil then file = io.open("/usr/local/openresty/nginx/conf/letsencrypt/ssl/" .. server_name .. "/fullchain1.pem") if file == nil then is_have_ssl = 'false' else file.close() end else file:close() end end return is_have_sslendfunction rewrite_https(stype) -- 有证书也不跳https, 直接返回 -- 可以写不跳转https的逻辑代码，直接return返回 -- a)配置跳转 b)有证书 满足a并b 才会进行跳转 local is_force_ssl = is_force_ssl(stype) local is_have_ssl = is_have_ssl() if is_force_ssl == "true" and is_have_ssl == 'true' then local httpsPort = "" if ngx.var.server_port == "8787" then # 自定义的8787端口，然后跳转https的8989端口 local _uri = ngx.var.uri if string.match(_uri, "/rcenter/") or string.start(_uri, "/fserver/") or string.start(_uri, "/ftl/") or string.start(_uri, "/__purge/") then #url符合这些的也不跳https return #直接返回，不往下继续走了 end httpsPort = ":8989" # 8787访问跳转https8989 elseif ngx.var.server_port == "8383" then httpsPort = ":8585" # 8383跳转8585 end local _host = ngx.var.host local _request_uri = ngx.var.request_uri return ngx.redirect('https://'.._host..httpsPort.._request_uri, '301') else return endend 上面的lua代码，是判断满足条件跳转https，下面的代码描述动态获取证书 dynamicssl.lua12345678910111213141516171819202122232425262728293031local ssl = require "ngx.ssl"ssl.clear_certs()local server_name = ssl.server_name()if server_name ~= nil then server_name = string.gsub(server_name,"^www%.","") local file = io.open("/usr/local/openresty/nginx/conf/ssl/" .. server_name ..".pem") if file == nil then file = io.open("/usr/local/openresty/nginx/conf/letsencrypt/ssl/" .. server_name .."/fullchain1.pem") if file == nil then file = io.open("/usr/local/openresty/nginx/conf/ssl/nginx.pem") end end local f = assert(file) local pem_cert_chain = f:read("*a") local der_cert_chain, err = ssl.cert_pem_to_der(pem_cert_chain) ssl.set_der_cert(der_cert_chain) f:close() local kfile = io.open("/usr/local/openresty/nginx/conf/ssl/" .. server_name ..".key.pem") if kfile == nil then kfile = io.open("/usr/local/openresty/nginx/conf/letsencrypt/ssl/" .. server_name .."/privkey1.pem") if kfile == nil then kfile = io.open("/usr/local/openresty/nginx/conf/ssl/nginx.key.pem") end end local k = assert(kfile) local pem_priv_key = k:read("*a") local der_priv_key, err = ssl.priv_key_pem_to_der(pem_priv_key) ssl.set_der_priv_key(der_priv_key) k:close()end 读取证书内容，判断合法，继续匹配location，完成后续请求.]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux普通用户编辑文件保存方法]]></title>
    <url>%2F2019%2F02%2F03%2Flinux%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E7%BC%96%E8%BE%91%E6%96%87%E4%BB%B6%E4%BF%9D%E5%AD%98%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[普通用户使用vim编辑文件，临时保存的方法 1:w !sudo tee %]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3的print输出颜色字体]]></title>
    <url>%2F2019%2F01%2F16%2Fpython3%E7%9A%84print%E8%BE%93%E5%87%BA%E9%A2%9C%E8%89%B2%E5%AD%97%E4%BD%93%2F</url>
    <content type="text"><![CDATA[在编写脚本时，有些提示错误信息想输出带颜色的字体，特备注下 笔记原著:https://www.cnblogs.com/fangbei/p/python-print-color.html 实现过程： 终端的字符颜色是用转义序列控制的，是文本模式下的系统显示功能，和具体的语言无关。 转义序列是以ESC开头,即用\033来完成（ESC的ASCII码用十进制表示是27，用八进制表示就是033）。 书写格式： 开头部分：\033[显示方式;前景色;背景色m + 结尾部分：\033[0m 注意：开头部分的三个参数：显示方式，前景色，背景色是可选参数，可以只写其中的某一个；另外由于表示三个参数不同含义的数值都是唯一的没有重复的，所以三个参数的书写先后顺序没有固定要求，系统都能识别；但是，建议按照默认的格式规范书写。 对于结尾部分，其实也可以省略，但是为了书写规范，建议\033[***开头，\033[0m结尾。 数值表示的参数含义： 显示方式: 0（默认\）、1（高亮）、22（非粗体）、4（下划线）、24（非下划线）、 5（闪烁）、25（非闪烁）、7（反显）、27（非反显） 前景色: 30（黑色）、31（红色）、32（绿色）、 33（黄色）、34（蓝色）、35（洋 红）、36（青色）、37（白色） 背景色: 40（黑色）、41（红色）、42（绿色）、 43（黄色）、44（蓝色）、45（洋 红）、46（青色）、47（白色） 1234567891011print("显示方式：") print("\033[0;37;40m\t方倍实验室\033[0m") print("\033[1;37;40m\t方倍实验室\033[0m") print("\033[22;37;40m\t方倍实验室\033[0m") print("\033[4;37;40m\t方倍实验室\033[0m") print("\033[24;37;40m\t方倍实验室\033[0m") print("\033[5;37;40m\t方倍实验室\033[0m") print("\033[25;37;40m\t方倍实验室\033[0m") print("\033[7;37;40m\t方倍实验室\033[0m") print("\033[27;37;40m\t方倍实验室\033[0m") 123456789print("前景色：") print("\033[0;30;40m\t方倍实验室\033[0m") print("\033[0;31;40m\t方倍实验室\033[0m") print("\033[0;32;40m\t方倍实验室\033[0m") print("\033[0;33;40m\t方倍实验室\033[0m") print("\033[0;34;40m\t方倍实验室\033[0m") print("\033[0;35;40m\t方倍实验室\033[0m") print("\033[0;36;40m\t方倍实验室\033[0m") print("\033[0;37;40m\t方倍实验室\033[0m") 123456789print("背景色：") print("\033[0;37;40m\t方倍实验室\033[0m")print("\033[0;37;41m\t方倍实验室\033[0m")print("\033[0;37;42m\t方倍实验室\033[0m")print("\033[0;37;43m\t方倍实验室\033[0m")print("\033[0;37;44m\t方倍实验室\033[0m")print("\033[0;37;45m\t方倍实验室\033[0m")print("\033[0;37;46m\t方倍实验室\033[0m")print("\033[0;37;47m\t方倍实验室\033[0m")]]></content>
      <categories>
        <category>python的积累</category>
      </categories>
      <tags>
        <tag>python3的print颜色字体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx中的正则匹配表达式案例]]></title>
    <url>%2F2019%2F01%2F14%2Fnginx%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[记录下工作中遇到的nginx的正则表达式的书写案列 注意: nginx在location 匹配中， ^~ = @ 后不能使用正则表达式 UA匹配前言1： 因受到cc攻击，所以在location匹配mobile-api，获取访问的头部信息，拒绝攻击端直接穿透后端服务器，配置如下123456789101112location ^~ /mobile-api &#123; if ($http_user_agent ~~* (app_android)|(app_ios)) &#123; return 403 &#125; proxy_pass http://mobile-upstream;&#125;# 被cc攻击，通过代理服务器挡住请求 判断http_user_agent 符合哪些规则# 写在location中if ($http_user_agent !~* ((okhttp)|(app_((rn)|(ios)|(android))))) &#123; return 200 ;&#125; nginx的if语句判断多个条件同时成立的写法 nginx的配置中不支持if条件的逻辑与 逻辑或运算，并且不支持if的嵌套语法，可以使用变量的方法来实现 例子:1234567891011121314151617# 错误的书写方式，只是为了理解想表达 设置的意思if ($remote_addr ~ "^(12.34|56.78)" &amp;&amp; $http_user_agent ~* "spider") &#123; return 403;&#125;# 正确通过set变量实现上面的想法set $flag 0;if ($remote_addr ~ "^(12.34|56.78)") &#123; set $flag "$&#123;flag&#125;1";&#125;if ($http_user_agent ~* "spider") &#123; set $flag "$&#123;flag&#125;2";&#125;if ($flag = "012") &#123; return 403;&#125; ip匹配12/^(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))&#123;3,3&#125;$//(\d+)\.(\d+)\.(\d+)\.(\d+)/ location匹配一级url后面的内容123location ~* /static-file/.+\.(js|css|png)$ &#123; proxy_pass http://yunweiops.com;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx正则表达式书写方式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty的try_files指令说明]]></title>
    <url>%2F2019%2F01%2F03%2Fopenresty%E7%9A%84try-files%E6%8C%87%E4%BB%A4%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[OpenSUSE Leap 42.3使用]]></title>
    <url>%2F2019%2F01%2F03%2FOpenSUSE-Leap-42-3%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[总结下使用openSUSE系统的备忘录 安装软件openSUSE leap系统使用zypper管理软件包 12# 检查系统版本lsb_release -a 国内用户建议的更改源1234567sudo sypper mr -da #禁用所有的默认软件源# 以下为添加中科大的openSUSE 软件源sudo zypper ar -fc https://mirrors.ustc.edu.cn/opensuse/distribution/leap/42.1/repo/oss USTC:42.1:OSSsudo zypper ar -fc https://mirrors.ustc.edu.cn/opensuse/distribution/leap/42.1/repo/non-oss USTC:42.1:NON-OSSsudo zypper ar -fc https://mirrors.ustc.edu.cn/opensuse/update/leap/42.1/oss USTC:42.1:UPDATE-OSSsudo zypper ar -fc https://mirrors.ustc.edu.cn/opensuse/update/leap/42.1/non-oss USTC:42.1:UPDATE-NON-OSS 12345# 刷新软件源sudo sypper ref# 更新系统软件sudo sypper update 安装中文输入法安装Fcitx五笔拼音输入法1sudo zypper install fcitx fcitx-table-cn-wubi-pinyin 编辑/etc/sysconfig/language文件1sudo nano /etc/sysconfig/language 更改内容1INPUT_METHOD="" 改为1INPUT_METHOD="fcitx" 保存文件，编辑~/.bashrc文件1nano ~/.bashrc 追加以下内容到文件末尾123export GTK_IM_MODULE=fcitxexport XMODIFIERS=@im=fcitxexport QT_IM_MODULE=fcitx 保存文件，重启系统，输入以下命令打开Fcitx的配置窗口1fcitx-config-gtk3 打开后，点击左下角加号按钮添加一个输入法 去掉only show current language前面的勾，然后在文本框输入WubiPinyin 点击OK按钮以添加五笔拼音输入法. 配置完成后，就可以使用Ctrl + 空格键 调出Fcitx五笔拼音输入法了 zypper包管理命令介绍12345zypper ar [仓库源地址] [仓库源名称] #添加repo源 ar表示addrepozypper ref # 刷新软件库sudo zypper install [软件包名] # 安装rpm包sudo zypper search [软件包名] #查看软件包是否安装sudo zypper rm [软件包名] # 卸载软件包 安装oh My Zshgithub地址 我是用的主题是: agnoster zsh的主题插件位于目录: /home/sun/.oh-my-zsh/plugins 123chsh -s /bin/bash #切换回bash shell终端upgrade_oh_my_zsh # 更新zshuninstall_oh_my_zsh zsh 安装google-chrome浏览器12sudo zypper ar http://dl.google.com/linux/chrome/rpm/stable/x86_64 Google-Chromesudo zypper install google-chrome-stable 安装Anaconda直接官网安装即可，我安装的Anaconda 2018.12 Python3.7 version 下载是shell脚本，直接sh [对应版本号包名.sh]本人使用的是shell 是/bin/zsh 所以安装过程中，提示写入到~/.bashrc 文件的anaconda的路径，我选择的是n 未安装Vscode conda命令conda 创建虚拟环境conda 指定虚拟环境安装依赖包123conda list #查看安装了哪些包conda env list 或者 conda info -e 查看当前主机存在的虚拟环境conda update conda # 检查并更新conda 12345678# 创建虚拟环境conda create -n py27 python=2.7 #创建python2.7版本的虚拟环境conda create -n py36 python=3.6 #创建python3.6版本的虚拟环境source activate your_env_name(虚拟环境名称) #激活虚拟环境退出虚拟环境source deactivate 12# 在虚拟环境中安装包conda install -n your_env_name [package] #安装指定包到虚拟环境中 12345# 删除虚拟环境conda remove -n your_env_name(虚拟环境名称) --all# 删除环境中的某个包conda remove -n your_env_name package_name 安装wine12345# 添加源zypper ar http://download.opensuse.org/repositories/Emulators:/Wine/openSUSE_13.1/ Wine#安装zypper in wine]]></content>
      <categories>
        <category>openSUSE系统</category>
      </categories>
      <tags>
        <tag>openSUSE系统使用之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty动态实现url跳转]]></title>
    <url>%2F2018%2F12%2F31%2Fopenresty%E5%8A%A8%E6%80%81%E5%AE%9E%E7%8E%B0url%E8%B7%B3%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[openresty 通过lua代码，查询redis，获取后端proxy_pass的值，实现跳转 具体实现12345678910111213# server.conflocation / &#123; set $query_host &quot;&quot;; set $real_host &quot;&quot;; set_by_lua_file $full_proxy_pass /usr/local/openresty/nginx/conf/api-pay-env-rds.lua; if ($full_proxy_pass = &quot;&quot;)&#123; return 404; &#125; proxy_set_header Host $real_host; proxy_pass $full_proxy_pass; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# api-pay-env-rds.lua#!/usr/bin/env lua--function get_api_pay_key(_request_uri) local api_pay_key = string.split(_request_uri, "/")[2] if api_pay_key then return api_pay_key end return nilend-- redis取前半段 proxy_passfunction get_proxy_pass_pre_from_rds(api_pay_key) local key = api_pay_key local cmd = "redis-cli -h 127.0.0.1 -p 6379 -a gamebox123 -n 15 get "..key local f = io.popen(cmd) res = tostring(f:read()) f:close() if res ~= " " then return res end return nilend-- 直接从请求 request_uri 取后半段 proxy_pass ,(相当于rewrite,去掉 *-api|*-pay 上下文)function get_proxy_pass_suf(_request_uri, api_pay_key,proxy_pass_pre) local _match = "/"..api_pay_key local proxy_pass_suf, n, err = ngx.re.sub(_request_uri, _match, "", "a") if proxy_pass_suf then return proxy_pass_pre..proxy_pass_suf end return nilendfunction get_real_host(proxy_pass_pre) local url = require "url" local u = url.parse(proxy_pass_pre) local real_host = u.host if real_host then return real_host end return nilend-- 完整proxy_pass的拼接, request_uri带参数的完整urilocal _request_uri = ngx.var.request_urilocal api_pay_key = get_api_pay_key(_request_uri)local proxy_pass_pre = get_proxy_pass_pre_from_rds(api_pay_key)local proxy_pass_suf = get_proxy_pass_suf(_request_uri, api_pay_key, proxy_pass_pre)ngx.var.real_host = get_real_host(proxy_pass_pre) -- 修改nginx设置的 real_host 值,用于proxy_set_header Host $real_host;return proxy_pass_suf]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexoEditor编辑器使用帮助]]></title>
    <url>%2F2018%2F12%2F28%2FhexoEditor%E7%BC%96%E8%BE%91%E5%99%A8%E4%BD%BF%E7%94%A8%E5%B8%AE%E5%8A%A9%2F</url>
    <content type="text"><![CDATA[zhuzhuyule/HexoEditorgithub作者: zhuzhuyule使用electron编写的markdown编辑器软件 hexoEditor github地址 聊聊部署12345678910111213141516//if use Windows:npm config set prefix "C:/Program Files/nodejs/npm_global"npm config set cache "C:/Program Files/nodejs/npm_cache" //if use Linux\Mac:npm config set prefix "~/nodejs/npm_global"npm config set cache "~/nodejs/npm_cache" //If In China, China, China, you can set mirror to speed up !npm config set registry "https://registry.npm.taobao.org/"npm config set electron_mirror "https://npm.taobao.org/mirrors/electron/"git clone https://github.com/zhuzhuyule/HexoEditor.gitcd HexoEditornpm installnpm start 使用说明加载hexo的主配置文件 在hexoEditor复制粘贴图片时， 路径是:/hexoEditor编辑器使用帮助/20181228100729048.png 会默认在/d/hexo/source/images/下插件和文件名同名的文件夹，将图片存放此文件夹内， 在hexoEditor中可以显示图片，但在hexo中，加载图片的路径是 /images/hexoEditor编辑器使用帮助/20181228100729048.png 要加上/images 快捷方式]]></content>
      <categories>
        <category>markdown编辑器</category>
      </categories>
      <tags>
        <tag>hexoEditor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习-class面向对象]]></title>
    <url>%2F2018%2F12%2F27%2Fpython%E5%AD%A6%E4%B9%A0-class%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[python类学习]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python方法积累]]></title>
    <url>%2F2018%2F12%2F25%2Fpython%E6%96%B9%E6%B3%95%E7%A7%AF%E7%B4%AF%2F</url>
    <content type="text"><![CDATA[python的小笔记，一些方法的使用说明 python字符串相关模块方法str.strip([chars])str.strip 去除首尾指定的字符 123456789101112# Usagestr = " helloworld " str.strip() #默认去除首尾的空格output: "helloworld"str = "thelloworldt"str.strip("t") #去除头尾的t字符串output: "helloworld"]]></content>
      <categories>
        <category>python的积累</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习六-django模板页面和数据库模型操作]]></title>
    <url>%2F2018%2F12%2F21%2Fpython%E5%AD%A6%E4%B9%A0%E5%85%AD-django%E6%A8%A1%E6%9D%BF%E9%A1%B5%E9%9D%A2%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A8%A1%E5%9E%8B%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[django的类视图中的模板页面加载django的数据库模型增删改查 类视图定义模板页面1234567891011#视图函数 返回模板页面的定义# urls.pyurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login')#函数定义def loginView(request): return render(request, "login.html")# 在templates文件夹添加login.html 123456789101112131415161718# 类视图函数继承Viewfrom django.shortcuts import renderfrom django.http import HttpResponse,JsonResponsefrom django.contrib.auth.models import Userfrom django.contrib.auth import authenticate,loginfrom django.views.generic import View,TemplateView #导入TemplateView# urls.pyurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login'), url(r'^loginView/$', views.loginView1.as_view()), #定义loginView1类视图class loginView(View): def get(self, request, *args, **kwargs): return render(request, login.html) def post(self, request, *args, **kwargs): return HttpResponse("验证用户名和密码") 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 类视图返回模板# 类视图继承TemplateView# urls.pyurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login'), url(r'^loginView/$', views.loginView1.as_view()), #定义loginView1类视图# views.py# 导入模块from django.shortcuts import renderfrom django.http import HttpResponse,JsonResponsefrom django.contrib.auth.models import Userfrom django.contrib.auth import authenticate,loginfrom django.views.generic import View,TemplateView #导入TemplateViewfrom django.db.utils import IntegrityErrorclass loginView1(TemplateView): #继承TemplateView类 template_name = "login.html" #直接定义template页面，详情可以点击TemplateView看源码信息 def post(self, request, *args, **kwargs): return HttpResponse("验证用户名和密码")#from django.views.generic.dates import ( #默认类# ArchiveIndexView, DateDetailView, DayArchiveView, MonthArchiveView,# TodayArchiveView, WeekArchiveView, YearArchiveView,#)# 给模板页面传入变量# login.html&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&#123;&#123; title &#125;&#125;&lt;/title&gt; //定义模板变量&lt;/head&gt;# 传入变量class loginView1(TemplateView): template_name = "login.html" def get_context_data(self, **kwargs): #覆盖TemplateView类中的此函数 kwargs["title"] = "changMingStudyProject" return kwargs django模型什么是模型模型是你的数据唯一的、权威的信息源。它包含你所储存数据的必要字段和行为。每个模型对应数据库中唯一的一张表 在django中，通过模型映射数据库表结构，模型使用class类定义，继承models.Model 如何编写模型模型：每个模型都用一个类表示，该类继承自django.db.models.Model。每个模型有多个类的属性变量，而每一个类的属性变量又都代表了数据库表中的一个字段字段：每个字段通过Field类的一个实例表示 —— 例如字符字段CharField和日期字段DateTimeField。这种方法告诉Django，每个字段中保存着什么类型的数据字段名：每个Field 实例的名字（例如username）就是字段的名字，并且是机器可读的格式。你将在Python代码中使用到它的值，并且你的数据库将把它用作表的列名 模型字段官网字段类型123456789# 常用字段类型# 官网地址: https://docs.djangoproject.com/en/1.11/ref/models/fields/CharFieldBooleanFieldIntegerFieldDateField / DateTimeFieldEmailFieldTextFieldTimeField 自增主键字段默认情况下Django会给每个模型添加下面这个字段 id = models.AutoField(primary_key=True)如果Django看到你显式地设置了Field.primary_key， 就不会自动添加 id 列每个模型只能有一个字段指定primary_key=True （无论是显式声明还是自动添加） 字段的自述名每个字段类型都接受一个可选的位置参数——字段的自述名，如果没有给定自述名，Django将根据字段的属性名称自动创建自述名——将属性名称的下划线替换成空格ForeignKey、 ManyToManyField 和 OneToOneField 这三个可以使用verbose_name指定自述名 #例如：自述名为：”person’s first name” first_name = models.CharField(“person’s first name”, max_length=30) #例如：自述名为：”first name” first_name = models.CharField(max_length=30) 就是对字段的描述信息 字段选项字段选项 每个字段有一些特有的参数，例如，CharField（和它的派生类）需要max_length 参数来指定VARCHAR 数据库字段的大小123456nullblankchoicesdefaultprimary_keyunique null如果为True，Django将用NULL来在数据库中存储空值默认值：False 如果为True , 该字段允许不填默认值：False blanknull是纯数据库范畴，而blank是数据验证范畴的blank=True，表单验证允许该字段为空blank=False，该字段就是必须的 choices由二元组组成的一个可迭代对象（如列表或元组），用来给字段提供选择项，如果设置了choices， 默认的表单将是一个选择框，选择框的选择就是choices中的选项 YEAR_IN_SCHOOL_CHOICES = ( (‘FR’, ‘Freshman’), (‘SO’, ‘Sophomore’), (‘JR’, ‘Junior’), (‘SR’, ‘Senior’), ) default字段的默认值，可以是一个值或者调用对象 primary_key如果为True，那么这个字段就是模型的主键 unique如果该值设置为True，这个字段的值在整张表中必须是唯一的 index若值为 True, 则 django-admin sqlindexes 将会为此字段输出 CREATE INDEX 语句。（译注：为此字段创建索引） 模型meta选项使用内部的class Meta 定义模型的元数据，例如：12345from django.db import modelsclass User(models.Model): username = models.IntegerField() class Meta: ordering = ["username"] 模型元数据是“任何不是字段的数据”，比如排序选项（ordering），数据库表名（db_table）。在模型中添加class Meta是完全可选的，所有选项都不是必须的 db_tabledb_table是用于指定自定义数据库表名的。Django有一套默认的按照一定规则生成数据模型对应的数据库表名，如果你想使用自定义的表名，就通过这个属性指定若不提供该参数, Django 会使用 app_label + ‘_’ + module_name 作为表的名字Django 会根据模型类的名称和包含它的应用的名称自动指定数据库表名称。一个模型的数据库表名称，由这个模型的“应用名” 和模型类名称之间加上下划线组成。使用Meta类中的 db_table 参数来重写数据表的名称。当你通过db_table覆写表名称时，强烈推荐使用小写字母给表命名 order 这个字段是告诉Django模型对象返回的记录结果集是按照哪个字段排序的class Meta:ordering = [&apos;-order_date&apos;] 它是一个字符串的列表或元组。每个字符串是一个字段名，前面带有可选的“-”前缀表示倒序。前面没有“-”的字段表示正序。使用”?”来表示随机排序。 ordering = [‘order_date’] # 按订单升序排列ordering = [‘-order_date’] # 按订单降序排列，-表示降序ordering = [‘?order_date’] # 随机排序，？表示随机ordering = [‘-pub_date’, ‘author’] # 对 pub_date 降序,然后对 author 升序 app_labelapp_label这个选项只在一种情况下使用，就是你的模型类不在默认的应用程序包下的models.py文件中，这时候你需要指定你这个模型类是那个应用程序的12class Meta: app_label='myapp' get_latest_by由于Django的管理方法中有个lastest()方法，就是得到最近一行记录。如果你的数据模型中有 DateField 或 DateTimeField 类型的字段，你可以通过这个选项来指定lastest()是按照哪个字段进行选取的。一个 DateField 或 DateTimeField 字段的名字. 若提供该选项, 该模块将拥有一个 get_latest() 函数以得到 “最新的” 对象(依据那个字段):12class Meta: get_latest_by = "order_date" verbose_nameverbose_name的意思很简单，就是给你的模型类起一个更可读的名字：12class Meta: verbose_name = "pizza" managed由于Django会自动根据模型类生成映射的数据库表，如果你不希望Django这么做，可以把managed的值设置为False。默认值为True,这个选项为True时Django可以对数据库表进行 migrate或migrations、删除等操作。在这个时间Django将管理数据库中表的生命周期如果为False的时候，不会对数据库表进行创建、删除等操作。可以用于现有表、数据库视图等，其他操作是一样的。 注释: 如果操作第三方数据库，有必要把此值设置为false, 要不然执行migrate会和本地模型定义的数据库保持一致 编写模型123456789101112131415161718from django.db import models# Create your models here.class User(models.Model): username = models.CharField("备注信息用户", max_length=32, null=True) age = models.IntegerField("年龄", max_length=10, null=True) class Meta: managed = False # 是否和数据库数据保持一致 db_table = "user" # 自定义数据库表名 ordering = ["age"] # 排序 verbose_name = "定义用户表" # 描述信息class Idc(models.Model): name = models.CharField("idc名称", max_length=32, blank=False, null=True) # blank定义不能为空，但必须有默认值，可以使用default指定或者为空null=True area = models.CharField("IDC地址", max_length=64, default="") contactPhone = models.IntegerField("联系方式", max_length=32, null=True) contactUser = models.CharField("联系人员", max_length=32, null=True) 数据库迁移迁移是Django用于同步你的发生改变的模型(添加一个字段，删除一个模型，等等)到你的数据库 迁移命令makemigrations, 负责基于你的模型修改创建一个新的迁移（深层迁移）migrate, 负责执行迁移, 以及撤销和列出迁移的状态。sqlmigrate, 展示迁移的sql语句 创建了model模型，使用以下命令，同步到数据库1234567891011121314151617python manage.py showmigrations #显示需要迁移的数据表python manage.py makemigrations [app_name] # app_name为可选字段 ，执行这条命令，会在app的migrations目录下生成版本号命名的文件python manage.py migrate [app_name] #同步模型数据到数据库python manage.py showmigrations #查看模型版本信息---output:dashboard [X] 0001_initial# 如果有新增字段，或者修改字段，使用以下命令生成同步操作python manage.py makemigrations app_name # 查看修改内容的sql语句，根据migrations的版本号查看python manage.py sqlmigrate [app_name] [migration版本号或者全名]# 指定版本号同步数据库操作python manage.py migrate [app_name] [migration_name] 删除数据库表内的单条数据 delete from 表名 where id=14 在同步数据库的时候要注意: 确保models.py中创建的数据库表结构信息(存于django_migrations表)和migrations目录下的数据库源(版本)文件保持一致 如果数据库表django_migrations中的数据源文件信息和migrations目录下的数据源文件不一致，例如删除django_migrations表中的一条数据，使用python manage.py showmigrations可以看到app下的数据源文件显示未同步 [ ] 版本号_[migrations_name], 这时使用python manage.py makemigrations [app_name]会提示错误，因为数据库中已经有那条数据，刚才删除操作，只是针对版本文件不统一，可以使用 –fake选项，只同步版本文件信息，不同步sql语句 创建对象Django 使用一种直观的方式把数据库表中的数据表示成 Python 对象：一个模型类代表数据库中的一个表，一个模型类的实例代表这个数据库表中的一条特定的记录。 使用关键字参数实例化模型实例来创建一个对象，然后调用save() 把它保存到数据库中。 也可以使用一条语句创建并保存一个对象，使用create()方法 案例方式一: 通过实例化对象插入数据进入ipython终端1python manage.py shell 123456789In [1]: from dashboard.models import Idc In [2]: idc = Idc() #对模型的Idc类进行实例化 In [3]: idc.name = "九河机房" In [4]: idc.area = "北京" In [5]: idc.contactPhone = "1234567890" In [6]: idc.contactUser = "张三" In [7]: idc.number = "500" In [8]: idc.save() In [9]: 123456789MariaDB [devops]&gt; select * from dashboard_idc;+----+--------------+--------+--------------+-------------+--------+| id | name | area | contactPhone | contactUser | number |+----+--------------+--------+--------------+-------------+--------+| 1 | 九河机房 | 北京 | 1234567890 | 张三 | 500 |+----+--------------+--------+--------------+-------------+--------+1 row in set (0.00 sec)MariaDB [devops]&gt; 方式二: 通过Idc.objects.create创建12345678910In [9]: data = &#123;&#125; In [11]: data["name"] = "新世界机房" In [12]: data["area"] = "深圳" In [13]: data["contactPhone"] = "123456" In [14]: data["contactUser"] = "李四" In [15]: data["number"] = 1000 In [16]: Idc.object.create(**data) In [17]: Idc.objects.create(**data) Out[17]: &lt;Idc: Idc object&gt; 12345678910MariaDB [devops]&gt; select * from dashboard_idc;+----+-----------------+--------+--------------+-------------+--------+| id | name | area | contactPhone | contactUser | number |+----+-----------------+--------+--------------+-------------+--------+| 1 | 九河机房 | 北京 | 1234567890 | 张三 | 500 || 2 | 新世界机房 | 深圳 | 123456 | 李四 | 1000 |+----+-----------------+--------+--------------+-------------+--------+2 rows in set (0.00 sec)MariaDB [devops]&gt; 模型查询查询对象通过模型中的管理器构造一个查询集，来从你的数据库中获取对象。查询集(queryset)表示从数据库中取出来的对象的集合。它可以含有零个、一个或者多个过滤器。过滤器基于所给的参数限制查询的结果。 从SQL 的角度，查询集和SELECT 语句等价，过滤器是像WHERE 和LIMIT 一样的限制子句。你可以从模型的管理器那里取得查询集,每个模型都至少有一个管理器,它默认命名为objects。通过模型类来直接访问它管理器只可以通过模型的类访问，而不可以通过模型的实例访问，目的是为了强制区分“表级别”的操作和“记录级别”的操作。对于一个模型来说，管理器是查询集的主要来源。例如，User.objects.all() 返回包含数据库中所有User 对象的一个查询集。 获取所有对象获取一个表中所有对象的最简单的方式是全部获取。可以使用管理器的all() 方法：all()方法返回包含数据库中所有对象的一个查询集 User就是django的默认用户的class，需要from导入即可 all_users = User.objects.all() 使用过滤器获取特定对象all() 方法返回了一个包含数据库表中所有记录查询集。但在通常情况下，你往往想要获取的是完整数据集的一个子集要创建这样一个子集，你需要在原始的的查询集上增加一些过滤条件。两个最普遍的途径是：filter(kwargs) 返回一个新的查询集，它包含满足查询参数的对象。exclude(kwargs) 返回一个新的查询集，它包含不满足查询参数的对象。查询参数（上面函数定义中的**kwargs）需要满足特定的格式，下面字段查询一节中会提到 要获取年份为2006的所有文章的查询集，可以使用filter()方法： Entry.objects.filter(pub_date__year=2006) 利用默认的管理器，它相当于： Entry.objects.all().filter(pub_date__year=2006) 链式过滤查询集的筛选结果本身还是查询集，所以可以将筛选语句链接在一起。像这样： Entry.objects.filter( headline__startswith=’What’ ).exclude( pub_date__gte=datetime.date.today() ).filter( pub_date__gte=datetime(2005, 1, 30) ) 这个例子最开始获取数据库中所有对象的一个查询集，之后增加一个过滤器，然后又增加一个排除，再之后又是另外一个过滤器。最后的结果仍然是一个查询集，它包含标题以”What“开头、发布日期在2005年1月30日至当天之间的所有记录。 每次你筛选一个查询集，得到的都是全新的另一个查询集，它和之前的查询集之间没有任何绑定关系。每次筛选都会创建一个独立的查询集，它可以被存储及反复使用。 q1 = Entry.objects.filter(headline__startswith=”What”) q2 = q1.exclude(pub_date__gte=datetime.date.today()) q3 = q1.filter(pub_date__gte=datetime.date.today()) 查询集是惰性执行的 —— 创建查询集不会带来任何数据库的访问。你可以将过滤器保持一整天，直到查询集 需要求值时，Django 才会真正运行这个查询。 q = Entry.objects.filter(headline__startswith=”What”)q = q.filter(pub_date__lte=datetime.date.today())q = q.exclude(body_text__icontains=”food”)print(q) 虽然它看上去有三次数据库访问，但事实上只有在最后一行（print(q)）时才访问一次数据库。一般来说，只有在“请求”查询集 的结果时才会到数据库中去获取它们。当你确实需要结果时，查询集 通过访问数据库来求值 filter() 始终给你一个查询集，即使只有一个对象满足查询条件 —— 这种情况下，查询集将只包含一个元素。如果你知道只有一个对象满足你的查询，你可以使用管理器的get() 方法，它直接返回该对象： one_entry = Entry.objects.get(pk=1)可以对get() 使用任何查询表达式，和filter() 一样使用get() 和使用filter() 的切片[0] 有一点区别。如果没有结果满足查询，get() 将引发一个DoesNotExist 异常。这个异常是正在查询的模型类的一个属性 —— 所以在上面的代码中，如果没有主键为1 的Entry 对象，Django 将引发一个Entry.DoesNotExist。如果有多条记录满足get() 的查询条件，Django 也将报错。这种情况将引发MultipleObjectsReturned，它同样是模型类自身的一个属性。 可以使用Python 的切片语法来限制查询集记录的数目 。它等同于SQL 的LIMIT 和OFFSET 子句。 Entry.objects.all()[:5]Entry.objects.all()[5:10] 字段查询字段查询是指如何指定SQL WHERE 子句的内容。它们通过查询集方法filter()、exclude() 和 get() 的关键字参数指定。查询的关键字参数的基本形式是field__lookuptype=value（中间是两个下划线） Entry.objects.filter(pub_date__lte=’2006-01-01’) SELECT * FROM blog_entry WHERE pub_date &lt;= ‘2006-01-01’; exact “精确”匹配 iexact 大小写不敏感的匹配 contains 大小写敏感的包含指定字符串 icontains 大小写不敏感的包含指定字符串 startswith, endswith 以指字字符串开头或结尾 istartswith, iendswith in 在给定的列表内 gt 大于 gte 大于或等于 lt 小于 lte 小于或等于 range 在指定范围内 year /month / day/ week_day 对于日期和日期时间字段，匹配年/月/日/星期 Django 提供一个查询快捷方式pk ，它表示“primary key” 的意思 Blog.objects.get(id__exact=14)Blog.objects.get(id=14)Blog.objects.get(pk=14) 默认情况下，QuerySet 根据模型Meta 类的ordering 选项排序。你可以使用order_by 方法给每个QuerySet 指定特定的排序 Entry.objects.filter(pub_date__year=2005).order_by(‘-pub_date’, ‘headline’) 上面的结果将按照pub_date 降序排序，然后再按照headline 升序排序。”-pub_date” 前面的负号表示降序排序。隐式的是升序排序。若要随机排序，请使用”?”，像这样： Entry.objects.order_by(‘?’) 返回一个ValuesQuerySet —— QuerySet 的一个子类，迭代时返回字典而不是模型实例对象。每个字典表示一个对象，键对应于模型对象的属性名称。values() 接收可选的位置参数*fields，它指定SELECT 应该限制哪些字段。如果指定字段，每个字典将只包含指定的字段的键/值。如果没有指定字段，每个字典将包含数据库表中所有字段的键和值。 User.objects.values(“id”, “username”) 与values() 类似，只是在迭代时返回的是元组而不是字典。每个元组包含传递给values_list() 调用的字段的值 —— 所以第一个元素为第一个字段，以此类推。 User.objects.values_list(‘id’, ‘username’) 在一些复杂的数据建模情况下，您的模型可能包含大量字段，其中一些可能包含大量数据需要昂贵的处理来将它们转换为Python对象。（例如，文本字段），或者如果您在某些情况下使用查询集的结果，当您最初获取数据时不知道是否需要这些特定字段，可以告诉Django不要从数据库中检索它们 User.objects.defer(“username”, “email”) 删除对象使用delete()。这个方法将立即删除对象且没有返回值。 Entry.objects.filter(pub_date__year=2005).delete() 虽然没有内建的方法用于拷贝模型实例，但还是很容易创建一个新的实例并让它的所有字段都拷贝过来。最简单的方法是，只需要将pk 设置为None。 blog = Blog(name=’My blog’, tagline=’Blogging is easy’) blog.save() # blog.pk == 1 blog.pk = None blog.save() # blog.pk == 2 更新对象使用update() Entry.objects.filter(pub_date__year=2007).update(headline=’Everything is the same’) update() 方法会立即执行并返回查询匹配的行数(如果有些行已经具有新的值，返回的行数可能和被更新的行数不相等) F()允许Django在未实际链接数据的情况下具有对数据库字段的值的引用。通常情况下我们在更新数据时需要先从数据库里将原数据取出后方在内存里，然后编辑某些属性，最后提交。例如 order = Order.objects.get(orderid=’123456789’) order.amount += 1 order.save() 这时就可以使用F()方法，代码如下 from django.db.models import F order = Order.objects.get(orderid=’123456789’) order.amount = F(‘amount’) - 1 order.save() Q对象(django.db.models.Q)可以对关键字参数进行封装，从而更好地应用多个查询。可以组合使用 &amp;（and）,|（or），~（not）操作符，当一个操作符是用于两个Q的对象,它产生一个新的Q对象。 Order.objects.get( Q(desc__startswith=’Who’), Q(create_time=date(2016, 10, 2)) | Q(create_time=date(2016, 10, 6)) ) 相当于 SELECT * from polls WHERE question LIKE ‘Who%’ AND (pub_date = ‘2005-05-02’ OR pub_date = ‘2005-05-06’) 序列化模型对象 from django.core import serializers data = serializers.serialize(“json”, SomeModel.objects.all()) 序列化模型子集from django.core import serializers data = serializers.serialize(“json”, User.objects.all()[0:10], fields=(‘username’,’is_active’)) 模型关系关系数据库的威力体现在表之间的相互关联，Django提供了三种最常见的数据库关系：多对一（many-to-one），多对多（many-to-many），一对一（one-to-one） 多对一关系多对多关系一对一关系 多对一 django是使用django.db.models.ForeignKey 定义多对一关系 ForeignKey需要一个位置参数来指定本Model关联的Model，ForeignKey关联的Model是”一”, ForeignKey所在的Model是”多”比如汽车和制造商的例子，一辆汽车只能属于一个制造商，但是一个制造商有多辆汽车，这个关系，用Django的Model来表示，就是123456class Manufacturer(models.Model): name = models.CharField(max_length=30)class Car(models.Model): manufacturer = models.ForeignKey(Manufacturer) name = models.CharField(max_length=30) 多对一查询正向查询（ ForeignKey 所在的模型查询关联的模型） car = Car.objects.get(pk=2) car.manufacturer.all() #返回一条Manufacturer 对象 反向查询（ ForeignKey 指向的模型查询ForeignKey 所在的模型）如果模型有一个ForeignKey，那么该ForeignKey 所指的模型实例可以通过一个管理器返回前一个有ForeignKey的模型的所有实例。默认情况下，这个管理器的名字为foo_set，其中foo 是源模型的小写名称。该管理器返回的查询集可以用上一节提到的方式进行过滤和操作。 manufacturer = Manufacturer.objects.get(pk=1) manufacturer.car_set.all() # 返回多个car对象 多对多要实现多对多，就要使用django.db.models.ManyToManyField类，和ForeignKey一样，它也有一个位置参数，用来指定和它关联的Model如果不仅仅需要知道两个Model之间是多对多的关系，还需要知道这个关系的更多信息，比如Person和Group是多对多的关系，每个person可以在多个group里，那么group里可以有多个person 12345class Group(models.Model): #... class Person(models.Model): groups = models.ManyToManyField(Group) 建议以被关联模型名称的复数形式做为 ManyToManyField 的名字在哪个模型中设置 ManyToManyField 并不重要，在两个模型中任选一个即可——不要在两个模型中都设置 add(obj1, obj2, …) #添加一指定的模型对象到关联的对象集中。create(**kwargs) #创建一个新的对象，将它保存并放在关联的对象集中。返回新创建的对象。remove(obj1, obj2, …) #从关联的对象集中删除指定的模型对象。clear() #从关联的对象集中删除所有的对象 一对一一对一是通过django.db.models.OneToOneField来实现的，被关联的Model会被加上Unique的限制， OneToOneField要一个位置参数，与模型关联的类当某个对象想扩展自另一个对象时，最常用的方式就是在这个对象的主键上添加一对一关系 总结(案例)使用django内置的User表查询数据123456789101112131415161718# 启动django的shellpython manage.py shellfrom django.contrib.auth.models import User #导入User表# 通过类管理器# filterUser.objects.filter(name="sun-1")# getUser.objects.get(name="sun-1")# 通过get 查询其他数据In [5]: u = User.objects.get(username="sun-1") In [6]: u.username Out[6]: 'sun-1'In [7]: u.email Out[7]: 'sun-1@163.com']]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis学习笔记]]></title>
    <url>%2F2018%2F12%2F18%2Fredis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[redis学习笔记 命令加入集群的命令1redis-trib.rb create --replicas 1 10.90.0.16:6379 10.90.0.18:6379 10.90.0.20:6379 10.90.0.22:6379 10.90.0.24:6379 10.90.0.14:6379 查看集群状态1234567891011redis-cli -c cluster nodesredis-cli -c cluster info# 输出内容[root@rd-1 /]# redis-cli -c cluster nodes24f4751d30a8f3a6529e62b8d5132ec1103ee843 10.90.0.5:6379 slave fb6d70d68322f9b124f7371f96a351d05d7165f8 0 1549869293688 6 connected3b8acf45d73549b63701a4e50f1d0080c27b5b11 10.90.1.93:6379 myself,master - 0 0 1 connected 0-5460b3ee2afbea10272df14ad649b6c94094fd985e06 10.90.1.81:6379 slave 3b8acf45d73549b63701a4e50f1d0080c27b5b11 0 1549869294190 4 connectedfb6d70d68322f9b124f7371f96a351d05d7165f8 10.90.0.3:6379 master - 0 1549869294190 3 connected 10923-16383112a0ed3ef683b3606cd6a4189a0407923150b3c 10.90.1.94:6379 master - 0 1549869293189 2 connected 5461-10922d08fd1be3f346eea5a049e02df83ea226da799a8 10.90.1.91:6379 slave 112a0ed3ef683b3606cd6a4189a0407923150b3c 0 1549869292688 5 connected 删除/增加节点1234567# 删除从节点# redis-trib.rb del-node 从节点 从节点ID# 此命令需要注意，会将redis的进程退出，redis会停止服务运行redis-trib.rb del-node 10.90.1.81:6379 b3ee2afbea10272df14ad649b6c94094fd985e06# 添加从节点./redis-trib.rb add-node --slave --master-id fb6d70d68322f9b124f7371f96a351d05d7165f8 10.90.1.81:6379 10.90.1.91:6379 12345678910111213141516171819202122232425262728293031# 集群信息[root@rd-1 /]# redis-cli -c cluster nodes87ea8d6e024f83ac2746daf37855e0fa2b0fbbdb 10.200.0.9:6379 myself,master - 0 0 1 connected 0-54601c376c8c4489512bdc7306fe9682082d05e04812 10.200.0.4:6379 master - 0 1549874430617 2 connected 5461-10922a2bb8b309f2c7bf1b865b07eb4c67ac88864e1e7 10.200.0.10:6379 slave 1c376c8c4489512bdc7306fe9682082d05e04812 0 1549874429614 5 connected2f858550698c40500be85cfc94c1163581d7e21b 10.200.0.6:6379 slave bfab9a4f473c7c7d1537c9e9f7c114c9eacbbd23 0 1549874430617 6 connected6926eb64dd29eb8a2b8331ef6146c4df55f39d9e 10.200.0.3:6379 slave 1c376c8c4489512bdc7306fe9682082d05e04812 0 1549874431119 2 connectedbfab9a4f473c7c7d1537c9e9f7c114c9eacbbd23 10.200.0.5:6379 master - 0 1549874430115 3 connected 10923-16383# 删除主节点# 删除主节点，如果主节点被删除从节点将会自动代替主节点，如果主节点有分配的槽点（slot）那么先去掉分配的槽点（slot）,然后再删除节点# 取消节点下分配的槽点（slot）./redis-trib.rb reshard 10.200.0.4:6379......在执行的过程中，需要依次输入 1. 删除的槽点(slot)个数 2. 接受这些槽点(slot)的节点ID 3. 要删除槽点(slot)的节点ID 4. 执行...... 输入yes# 在上述执行中，会将准备删除节点的槽点(slot)转移到另一个节点上，转移完毕后，# 删除主节点# redis-trib.rb del-node 主节点地址 主节点IDredis-trib.rb del-node 10.200.0.4:6379 1c376c8c4489512bdc7306fe9682082d05e04812# 新增主节点# redis-trib.rb add-node 新增节点地址 已存在的任何一个主节点redis-trib.rb add-node 10.200.0.4:6379 10.200.0.9:6379# 重新分配槽点redis-trib.rb reshard 10.200.0.4:6379 新增slave节点123456789101112# 添加从节点./redis-trib.rb add-node --slave --master-id 主节点ID 新节点ip:port 主节点ip:port # 这条命令会将分配新节点为主节点的slave1)添加为从节点./redis-trib.rb add-node --slave --master-id 339a50df26f4722f14faba2a8fe3cad508059e88 192.168.17.168:7005 192.168.17.168:7001注释：--slave，表示添加的是从节点--master-id 339a50df26f4722f14faba2a8fe3cad508059e88,主节点的node id，这个id是7001的节点id 表示将新节点添加为7001的slave192.168.17.168:7005,新节点192.168.17.168:7001集群任一个旧节点 redis缓存的TTL值(过期时间设置)12345678910111213141516171819202122232425# 不存在的 keyredis&gt; FLUSHDBOKredis&gt; TTL key # key不存在，返回-2(integer) -2# key 存在，但没有设置剩余生存时间redis&gt; SET key valueOKredis&gt; TTL key(integer) -1# 有剩余生存时间的 keyredis&gt; EXPIRE key 10086(integer) 1redis&gt; TTL key(integer) 10084]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker swarm使用上的心得]]></title>
    <url>%2F2018%2F12%2F17%2Fdocker-swarm%E4%BD%BF%E7%94%A8%E4%B8%8A%E7%9A%84%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[聊聊生产环境中运行docker swarm的那些事 笔记swarm之间的通信端口Docker Swarm正常运行所需的网络端口： 2376用于安全Docker客户端通信的TCP端口。Docker Machine需要此端口才能工作。Docker Machine用于协调Docker主机 TCP端口2377。此端口用于Docker Swarm或集群的节点之间的通信。它只需要在管理器节点上打开 TCP和UDP端口7946用于节点之间的通信（容器网络发现） 4789用于覆盖网络流量的UDP端口（容器入口网络 问题Q: 容器启动速度慢 在一台主机运行38个容器后，继续部署容器，遇到容器启动超时的问题，总是启动不起来 A：目前采取的办法，就是减少同时启动容器的数量，控制在4个容器启动，然后将service中的程序减少，缩减到最精简版本 Q: firewalld的warning 使用docker stack部署service时，节点上/var/log/message提示 WARNING: COMMAND_FAILED …… failed: A：firewalld日志中与Docker相关的警告消息导致内部Docker启动完整性检查。Docker尝试在设置容器之前确保firewalld中没有现有规则，因此它告诉firewalld删除任何规则。但如果没有规则，firewalld就会记录这个事实, 可以被忽略的WARNING Q: docker swarm部署两个service，映射到宿主机端口，通信问题 docker swarm部署两个service到工作节点，都映射到宿主机端口，进入其中一个容器A，在A上无法telnet 宿主机ip B容器映射到宿主机的端口， telnet显示 No route to host A:目前查询资料显示，应该docker swarm自身网络的一个bug，正在查阅技术资料查找原因]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[siege压测工具使用说明]]></title>
    <url>%2F2018%2F12%2F16%2Fsiege%E5%8E%8B%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[siege工具使用 命令12siege -c 200 -r 100 "URL连接地址" #模拟200个用户并发，-r 重复次数100次siege -c 200 -t 10m "URL连接地址" siege结果报告12345678910111213siege报告:Transactions: 4000 hits #完成4000次处理Availability: 100.00 % # 成功率百分之百Elapsed time: 21.16 secs # 总共使用时间21.16Data transferred: 36.52 MB # 总数据传输36.52MBResponse time: 0.29 secs # 平均响应时间0.29Transaction rate: 189.04 trans/sec # 平均每秒处理请求次数189.04Throughput: 1.73 MB/sec # 平均每秒传送数据MBConcurrency: 54.53 # 实际最高并发连接数Successful transactions: 4000 # 成功处理次数Failed transactions: 0 # 失败处理次数Longest transaction: 1.33 # 满足一个请求所需最长时间Shortest transaction: 0.15 # ................最短时间]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>siege压测工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty学习知识点备忘录]]></title>
    <url>%2F2018%2F12%2F16%2Fopenresty%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录下学习openresty的一些小知识点，小命令方便忘记的时候查看 以下所有学习记录知识点都是从 ==&gt; 张开涛博客 《跟我学nginx+lua开发》博客地址链接 openresty中lua获取请求相关参数ngx.req.get_headers12345678910111213141516--请求头 local headers = ngx.req.get_headers() ngx.say("headers begin", "&lt;br/&gt;") ngx.say("Host : ", headers["Host"], "&lt;br/&gt;") ngx.say("user-agent : ", headers["user-agent"], "&lt;br/&gt;") ngx.say("user-agent : ", headers.user_agent, "&lt;br/&gt;") for k,v in pairs(headers) do if type(v) == "table" then ngx.say(k, " : ", table.concat(v, ","), "&lt;br/&gt;") else ngx.say(k, " : ", v, "&lt;br/&gt;") end end ngx.say("headers end", "&lt;br/&gt;") ngx.say("&lt;br/&gt;") 123456789101112131415161718192021222324252627282930313233343536--get请求uri参数 ngx.say("uri args begin", "&lt;br/&gt;") local uri_args = ngx.req.get_uri_args() for k, v in pairs(uri_args) do if type(v) == "table" then ngx.say(k, " : ", table.concat(v, ", "), "&lt;br/&gt;") else ngx.say(k, ": ", v, "&lt;br/&gt;") end end ngx.say("uri args end", "&lt;br/&gt;") ngx.say("&lt;br/&gt;") --post请求参数 ngx.req.read_body() ngx.say("post args begin", "&lt;br/&gt;") local post_args = ngx.req.get_post_args() for k, v in pairs(post_args) do if type(v) == "table" then ngx.say(k, " : ", table.concat(v, ", "), "&lt;br/&gt;") else ngx.say(k, ": ", v, "&lt;br/&gt;") end end ngx.say("post args end", "&lt;br/&gt;") ngx.say("&lt;br/&gt;") --请求的http协议版本 ngx.say("ngx.req.http_version : ", ngx.req.http_version(), "&lt;br/&gt;") --请求方法 ngx.say("ngx.req.get_method : ", ngx.req.get_method(), "&lt;br/&gt;") --原始的请求头内容 ngx.say("ngx.req.raw_header : ", ngx.req.raw_header(), "&lt;br/&gt;") --请求的body内容体 ngx.say("ngx.req.get_body_data() : ", ngx.req.get_body_data(), "&lt;br/&gt;") ngx.say("&lt;br/&gt;") 1234567891011ngx.var ： nginx变量，如果要赋值如ngx.var.b = 2，此变量必须提前声明；另外对于nginx location中使用正则捕获的捕获组可以使用ngx.var[捕获组数字]获取；ngx.req.get_headers：获取请求头，默认只获取前100，如果想要获取所以可以调用ngx.req.get_headers(0)；获取带中划线的请求头时请使用如headers.user_agent这种方式；如果一个请求头有多个值，则返回的是table；ngx.req.get_uri_args：获取url请求参数，其用法和get_headers类似；ngx.req.get_post_args：获取post请求内容体，其用法和get_headers类似，但是必须提前调用ngx.req.read_body()来读取body体（也可以选择在nginx配置文件使用lua_need_request_body on;开启读取body体，但是官方不推荐）；ngx.req.raw_header：未解析的请求头字符串；ngx.req.get_body_data：未解析的请求body体内容字符串 lua获取location使用正则匹配的部分12345678910111213141516location ~ /lua_request/(\d+)/(\d+) &#123; #设置nginx变量 set $a $1; set $b $host; default_type "text/html"; #nginx内容处理 content_by_lua_file /usr/example/lua/test_request.lua; #内容体处理完成后调用 echo_after_body "ngx.var.b $b"; &#125; # lua代码获取local var = ngx.var ngx.say("ngx.var.a : ", var.a, "&lt;br/&gt;") ngx.say("ngx.var.b : ", var.b, "&lt;br/&gt;") # 对于nginx location中使用正则捕获的捕获组可以使用ngx.var[捕获组数字]获取 ngx.say("ngx.var[2] : ", var[2], "&lt;br/&gt;") uri编码和解码12345678910111213--未经解码的请求uri local request_uri = ngx.var.request_uri; ngx.say("request_uri : ", request_uri, "&lt;br/&gt;"); --解码 ngx.say("decode request_uri : ", ngx.unescape_uri(request_uri), "&lt;br/&gt;"); --MD5 ngx.say("ngx.md5 : ", ngx.md5("123"), "&lt;br/&gt;") --http time ngx.say("ngx.http_time : ", ngx.http_time(ngx.time()), "&lt;br/&gt;")# ngx.escape_uri/ngx.unescape_uri ： uri编码解码；# ngx.encode_args/ngx.decode_args：参数编码解码；# ngx.encode_base64/ngx.decode_base64：BASE64编码解码；# ngx.re.match：nginx正则表达式匹配； 全局共享内存变量1234567891011121314--1、获取全局共享内存变量 local shared_data = ngx.shared.shared_data --2、获取字典值 local i = shared_data:get("i") if not i then i = 1 --3、惰性赋值 shared_data:set("i", i) ngx.say("lazy set i ", i, "&lt;br/&gt;") end --递增 i = shared_data:incr("i", 1) ngx.say("i=", i, "&lt;br/&gt;") set_by_lua_file or set_by_lua 获取变量123456789101112131415161718192021222324252627282930313233343536373839404142# Use help# set_by_lua_filelocation /lua_set_1 &#123; default_type "text/html"; set_by_lua_file $num /usr/example/lua/test_set_1.lua; echo $num; &#125; # set_by_lua_file：语法set_by_lua_file $var lua_file arg1 arg2...; 在lua代码中可以实现所有复杂的逻辑，但是要执行速度很快，不要阻塞；# test_set_1.lua文件内容local uri_args = ngx.req.get_uri_args() local i = uri_args["i"] or 0 local j = uri_args["j"] or 0 return i + j # set_by_lua语法set_by_lua $to_book ' local ngx_match = ngx.re.match local var = ngx.var local skuId = var.skuId local r = var.item_dynamic ~= "1" and ngx.re.match(skuId, "^[0-9]&#123;8&#125;$") if r then return "1" else return "0" end; '; set_by_lua $to_mvd ' local ngx_match = ngx.re.match local var = ngx.var local skuId = var.skuId local r = var.item_dynamic ~= "1" and ngx.re.match(skuId, "^[0-9]&#123;9&#125;$") if r then return "1" else return "0" end; '; #自营图书 if ($to_book) &#123; proxy_pass http://127.0.0.1/old_book/$skuId.html; &#125; #自营音像 if ($to_mvd) &#123; proxy_pass http://127.0.0.1/old_mvd/$skuId.html; &#125; #默认 proxy_pass http://127.0.0.1/proxy/$skuId.html; 连接redis1234567891011121314151617181920212223242526272829303132333435363738394041424344local function close_redis(red) if not red then return end local ok, err = red:close() if not ok then ngx.say("close redis error : ", err) end end local redis = require("resty.redis") --创建实例 local red = redis:new() --设置超时（毫秒） red:set_timeout(1000) --建立连接 local ip = "127.0.0.1" local port = 6660 local ok, err = red:connect(ip, port) if not ok then ngx.say("connect to redis error : ", err) return close_redis(red) end --调用API进行处理 ok, err = red:set("msg", "hello world") if not ok then ngx.say("set msg error : ", err) return close_redis(red) end --调用API获取数据 local resp, err = red:get("msg") if not resp then ngx.say("get msg error : ", err) return close_redis(red) end --得到的数据为空处理 if resp == ngx.null then resp = '' --比如默认值 end ngx.say("msg : ", resp) close_redis(red)]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志切割shell脚本]]></title>
    <url>%2F2018%2F12%2F16%2Fnginx%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2shell%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[nginx日志按天进行切割，通过写shell脚本，创建以日期命名文件 直奔主题12345678910111213141516171819202122232425262728293031#!/usr/bin/env bashset -e# 定义nginx 日志路径LOG_PATH="/var/gb/logs/"# 定义nginx 访问日志文件名称ACCESS_LOG="access.log"ERROR_LOG="error.log"for i in `find $LOG_PATH -name "$ACCESS_LOG"`; do cd $(dirname $i) # 切割access日志 if [[ -f $ACCESS_LOG ]]; then cp &#123;,$(date +%F)-&#125;$&#123;ACCESS_LOG&#125; : &gt; $ACCESS_LOG fi # 如果error日志&gt;20m，切 if [[ -f $ERROR_LOG ]]; then ERROR_SIZE=`ls -l $ERROR_LOG | awk '&#123; print $5 &#125;'` if [[ $ERROR_SIZE -gt 20971520 ]]; then cp &#123;,$(date +%F)-&#125;$&#123;ERROR_LOG&#125; : &gt; $&#123;ERROR_LOG&#125; fi fidone# 查找nginx 日志目录下7天前的日志并删除find $&#123;LOG_PATH&#125; -type f -name "*-$&#123;ACCESS_LOG&#125;" -mtime +7 -deletefind $&#123;LOG_PATH&#125; -type f -name "*-$&#123;ERROR_LOG&#125;" -mtime +7 -delete]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx日志切割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx根据http_useragent判断是手机端还是pc端]]></title>
    <url>%2F2018%2F12%2F16%2Fnginx%E6%A0%B9%E6%8D%AEhttp-useragent%E5%88%A4%E6%96%AD%E6%98%AF%E6%89%8B%E6%9C%BA%E7%AB%AF%E8%BF%98%E6%98%AFpc%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[nginx的location判断用户端是手机还是pc端配置 配置12345678910111213141516# 判断 pc 和 mobile 的 H5 location / &#123; set $is_mobile false; #设置一个初始值 if ( $http_cookie ~* "ACCESS_TERMINAL=mobile" ) &#123; #判断匹配手机端 set $is_mobile true; &#125; if ($http_user_agent ~* (android|ip(ad|hone|od)|kindle|blackberry|windows\s(ce|phone))) &#123; #匹配手机端类型 set $is_mobile true; &#125; if ($is_mobile = true) &#123; root /usr/local/openresty/nginx/html/mobile/; break; &#125; root /usr/local/openresty/nginx/html/pc/; &#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装配置NFS]]></title>
    <url>%2F2018%2F12%2F16%2FCentos7%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AENFS%2F</url>
    <content type="text"><![CDATA[在生产环境中，有些目录需要共享，想让其他节点挂载此共享目录使用场景： 日志目录，应用程序目录 安装环境说明:OS: Centos71yum -y install nfs-utils rpcbind nfs配置文件: /etc/exports共享目录: /home/data管理节点上配置: 12# cat /etc/exports/home/data 192.168.0.0/24(rw,async,insecure,anonuid=1000,anongid=1000,no_root_squash) 生效配置文件 1exportfs -rv nfs的配置参数说明 192.168.1.0/24 可以为一个网段，一个IP，也可以是域名，域名支持通配符 如: *.com rw：read-write，可读写； ro：read-only，只读； sync：文件同时写入硬盘和内存； async：文件暂存于内存，而不是直接写入内存； no_root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，也拥有root权限。显然开启这项是不安全的。 root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，拥有匿名用户权限，通常他将使用nobody或nfsnobody身份； all_squash：不论NFS客户端连接服务端时使用什么用户，对服务端分享的目录来说都是拥有匿名用户权限； anonuid：匿名用户的UID值 anongid：匿名用户的GID值。备注：其中anonuid=1000,anongid=1000,为此目录用户web的ID号,达到连接NFS用户权限一致。 defaults 使用默认的选项。默认选项为rw、suid、dev、exec、auto nouser与async。 atime 每次存取都更新inode的存取时间，默认设置，取消选项为noatime。 noatime 每次存取时不更新inode的存取时间。 dev 可读文件系统上的字符或块设备，取消选项为nodev。 nodev 不读文件系统上的字符或块设备。 exec 可执行二进制文件，取消选项为noexec。 noexec 无法执行二进制文件。 auto 必须在/etc/fstab文件中指定此选项。执行-a参数时，会加载设置为auto的设备，取消选取为noauto。 noauto 无法使用auto加载。 suid 启动set-user-identifier设置用户ID与set-group-identifer设置组ID设置位，取消选项为nosuid。 nosuid 关闭set-user-identifier设置用户ID与set-group-identifer设置组ID设置位。 user 普通用户可以执行加载操作。 nouser 普通用户无法执行加载操作，默认设置。 remount 重新加载设备。通常用于改变设备的设置状态。 rsize 读取数据缓冲大小，默认设置1024。–影响性能 wsize 写入数据缓冲大小，默认设置1024。 fg 以前台形式执行挂载操作，默认设置。在挂载失败时会影响正常操作响应。 bg 以后台形式执行挂载操作。 hard 硬式挂载，默认设置。如果与服务器通讯失败，让试图访问它的操作被阻塞，直到服务器恢复为止。 soft 软式挂载。服务器通讯失败，让试图访问它的操作失败，返回一条出错消息。这项功能对于避免进程挂在无关紧要的安装操作上来说非常有用。 retrans=n 指定在以软方式安装的文件系统上，在返回一条出错消息之前重复发出请求的次数。 nointr 不允许用户中断，默认设置。 intr 允许用户中断被阻塞的操作并且让它们返回一条出错消息。 timeo=n 设置请求的超时时间以十分之一秒为单位。 tcp 传输默认使用udp,可能出现不稳定，使用proto=tcp更改传输协议。客户端参考mountproto=netid （以上内容：参考：man nfs） 启动nfs1234systemctl enable rpcbindsystemctl start rpcbindsystemctl enable nfs-serversystemctl start nfs-server 客户端挂载 linux客户端挂载安装nfs服务，然后启动rpcbind服务 12systemctl enable rpcbind.servicesystemctl start rpcbind.service 查看服务端的共享目录 12# showmount -e nfs服务器IPshowmount -e 192.168.1.41 123456789# 开机自动挂载# cat /etc/fstab192.168.1.41:/home/data /home/data nfs4 rw,hard,intr,proto=tcp,port=2049,noauto 0 0# 手动挂载mount -t nfs 192.168.1.41:/home/data /home/data# NFS默认是用UDP协议，换成TCP协议达到稳定传输目的：mount -t nfs 192.168.1.41:/home/data /home/data -o proto=tcp -o nolock]]></content>
      <categories>
        <category>linux运维大杂烩</category>
        <category>NFS</category>
      </categories>
      <tags>
        <tag>NFS服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习五-django的日志输出配置]]></title>
    <url>%2F2018%2F12%2F16%2Fpython%E5%AD%A6%E4%B9%A0%E4%BA%94-django%E7%9A%84%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[django的日志管理 django日志Django 使用Python 内建的logging 模块打印日志，Python 的logging 配置由四个部分组成 记录器 —— Logger 处理程序 —— Handler 过滤器 —— Filter 格式化 —— Formatter 记录器 Logger Logger为日志系统的入口，每个logger命名都是bucket，可以向bucket写入需要处理的消息 每个logger都有一个日志级别，日志级别表示该logger将要处理的消息的严重性，python定义以下几种日志级别: DEBUG: 用于调试目的的底层系统信息 INFO：普通的系统信息 WARNING：表示出现一个较小的问题 ERROR：表示出现一个较大的问题 CRITICAL：表示出现一个致命的问题 写入logger 的每条消息都是一条日志。每条日志也具有一个日志级别，它表示对应的消息的严重性。每个日志记录还可以包含描述正在打印的事件的元信息。 当一条消息传递给logger 时，消息的日志级别将与logger 的日志级别进行比较。如果消息的日志级别大于等于logger 的日志级别，该消息将会往下继续处理。如果小于，该消息将被忽略。 Logger 一旦决定消息需要处理，它将传递该消息给一个Handler logger日志级别 级别 值 描述 CRITICAL 50 关键错误/消息 ERROR 40 错误 WARNING 30 警告消息 INFO 20 通知消息 DEBUG 10 调试 NOTSET 0 无级别 Logger配置logger 对应的值是个字典，其每一个键都是logger的名字，每一个值又是个字典，描述了如何配置对应的Logger实例。 level （可选的）。logger的级别。 propagate （可选的）。logger的传播设置。 filters （可选的）。logger的filter的标识符的列表。 handlers （可选的）。logger的handler的标识符的列表 Logger配置实例12345678LOGGING = &#123; 'loggers': &#123; 'log1': &#123; 'handlers': ['file_handler', 'console_handler'], 'level': 'DEBUG', &#125;, &#125;,&#125; 处理程序Handler Handler 决定如何处理logger 中的每条消息。它表示一个特定的日志行为，例如将消息写到屏幕上、写到文件中或者写到网络socket 与logger 一样，handler 也有一个日志级别。如果消息的日志级别小于handler 的级别，handler 将忽略该消息 Logger 可以有多个handler，而每个handler 可以有不同的日志级别。利用这种方式，可以根据消息的重要性提供不同形式的处理 Handler配置实例123456789LOGGING = &#123; 'handlers': &#123; 'log1': &#123; 'level': 'DEBUG', 'class': 'logging.StreamHandler', 'formatter': 'simple’, &#125; &#125;&#125; 过滤器 Filter Filter 用于对从logger 传递给handler 的日志记录进行额外的控制。 默认情况下，满足日志级别的任何消息都将被处理。通过安装一个filter，你可以对日志处理添加额外的条件。例如，你可以安装一个filter，只允许处理来自特定源的ERROR 消息 Filters 还可以用于修改将要处理的日志记录的优先级。例如，如果日志记录满足特定的条件，你可以编写一个filter 将日志记录从ERROR 降为WARNING Filters 可以安装在logger 上或者handler 上；多个filter 可以串联起来实现多层filter 行为 格式化 Formatters日志记录需要转换成文本。Formatter 表示文本的格式。Fomatter 通常由包含日志记录属性的Python 格式字符串组成；你也可以编写自定义的fomatter 来实现自己的格式 12345678910LOGGING = &#123; 'formatters': &#123; 'log1':&#123; 'format': '%(asctime)s - %(pathname)s:%(lineno)d[%(levelname)s] - %(message)s' &#125; 'simple': &#123; 'format': '%(asctime)s %(levelname)s %(message)s' &#125;, &#125;,&#125; Format日志消息格式 django日志配置管理demo写入文件的日志,用于生产环境1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# settings.py文件定义LOGGINGLOGGING = &#123; 'version': 1, 'disable_existing_loggers': False, 'loggers': &#123; 'reboot': &#123; 'handlers': ["reboot"], 'level': 'DEBUG', 'propagate': True &#125;, "django": &#123; 'handlers': ["django"], 'level': 'DEBUG', 'propagate': True &#125;, "django.server": &#123; 'handlers': ["django_server"], 'level': 'DEBUG', "propagate": True &#125; &#125;, 'handlers': &#123; 'reboot': &#123; 'level': 'DEBUG', 'class': 'logging.StreamHandler', 'formatter': 'simple', &#125;, 'file': &#123; 'level': 'DEBUG', 'class': 'logging.FileHandler', 'filename': '/tmp/django.log', 'formatter': 'json', &#125;, 'django': &#123; 'level': 'DEBUG', 'class': 'logging.FileHandler', 'filename': '/tmp/default.log', 'formatter': 'simple', &#125;, 'django_server': &#123; 'level': 'DEBUG', 'class': 'logging.FileHandler', 'filename': '/tmp/django_server.log', 'formatter': 'simple', &#125;, &#125;, 'formatters': &#123; 'json': &#123; 'format': '&#123;"levelname":"%(levelname)s","asctime":"%(asctime)s","module":"%(name)s","fullpath":"%(pathname)s","funcName":"%(funcName)s","lineno":"%(lineno)s","message":"%(message)s"&#125;' &#125;, 'reboot': &#123; 'format': '%(asctime)s - %(pathname)s:%(lineno)d[%(levelname)s] - %(message)s' &#125;, 'simple': &#123; 'format': '%(name)s %(asctime)s %(levelname)s %(message)s' &#125;, 'verbose': &#123; 'format': '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s' &#125;, &#125;, 'root': &#123; 'handlers': ["file"], 'level': 'DEBUG', &#125;&#125;# views.py定义输出日志import logginglogger = logging.getLogger(__name__)class userView2(View): def post(self, request, *args, **kwargs): logger.debug("创建用户") #输出日志 # 1. 获取提交数据 data = request.POST.dict() # 获取post提交的所有数据 logger.debug("请求数据转dict") # 2. 创建用户 try: logger.debug("执行用户创建") #输出日志 user = User.objects.create_user(**data) except IntegrityError: logger.debug("用户已存在") return JsonResponse(&#123;"errmsg": "用户已存在"&#125;) return JsonResponse(&#123;"id": user.id, "email": user.email, "username": user.username&#125;) 写入终端的日志,用于开发环境12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 复制一份manage_dev.py 用于使用这个文件启动webserver，日志输出到终端# 修改导入的settings配置if __name__ == "__main__": os.environ.setdefault("DJANGO_SETTINGS_MODULE", "devops.settings_dev") #修改此处，导入settings_dev文件 try: from django.core.management import execute_from_command_line except ImportError: # The above import may fail for some other reason. Ensure that the # issue is really that Django is missing to avoid masking other # exceptions on Python 2. try: import django except ImportError: raise ImportError( "Couldn't import Django. Are you sure it's installed and " "available on your PYTHONPATH environment variable? Did you " "forget to activate a virtual environment?" ) raise execute_from_command_line(sys.argv)# 复制一份settings文件为settings_dev.py# 输出到终端的日志格式定义LOGGING = &#123; 'version': 1, 'disable_existing_loggers': False, "loggers": &#123; "django": &#123; 'handlers': ["reboot"], 'level': 'DEBUG', 'propagate': False &#125;, &#125;, 'handlers': &#123; 'reboot': &#123; 'level': 'DEBUG', 'class': 'logging.StreamHandler', 'formatter': 'simple', &#125;, &#125;, 'formatters': &#123; 'simple': &#123; 'format': '%(name)s %(asctime)s %(levelname)s %(message)s' &#125;, &#125;, "root": &#123; 'handlers': ["reboot"], 'level': 'DEBUG', &#125;&#125;# 启动django，使用以下命令python manage_dev.py runserver 0.0.0.0:8000]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习(四)django的类视图函数]]></title>
    <url>%2F2018%2F11%2F24%2Fpython%E5%AD%A6%E4%B9%A0-%E5%9B%9B-django%E7%9A%84%E7%B1%BB%E8%A7%86%E5%9B%BE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[django 使用类定义视图 在django的视图中，通过定义class方法，调用 定义类视图函数123456789# urls.pyfrom django.conf.urls import url, includefrom . import viewsurlpatterns = [ url(r'^$', views.index, name='index'), url(r'^loginview/$', views.LoginView.as_view()) #必须使用as_view] 12345678910111213# views.pyfrom django.http import HttpResponse, QueryDict, JsonResponsefrom django.views import View #导入Viewfrom django.contrib.auth.models import Userfrom django.core.paginator import Paginatorfrom django.db.utils import IntegrityErrorimport loggingclass LoginView(View): #集成View类 def get(self, request, *args, **kwargs): #定义get属性 return HttpResponse("展示用户登陆页面") def post(self, request, *args, **kwargs): #定义post属性 return HttpResponse("验证用户名与密码") 以上就是定义类视图的方法，当在类中，定义的请求属性，在View类中不存在，会提示405状态码，抛出请求属性方法不被允许的warning，可进入View类方法中查看 数据分页12from django.contrib import User #导入django的User模型，查询数据库User.object.all() #获取数据库所有用户 12345678910111213# 创建测试数据python manage.py shell# 创建100个用户from django.contrib.auth import Userfor n in range(1,101): username = "sun-&#123;&#125;".format(n) User.objects.create_user(username, email="sun-&#123;&#125;@163.com".format(n), password=123456)# 查看用户python manage.py dbshell #进入django的dbshell 管理台use devops; #使用devops数据库select * from auth_user;select * from auth_user limit 10,20 #过滤数据，从第10个开始显示，显示20行数据 1234# 小插曲# for循环获取所有用户data = [&#123;"id" : user.id, "email": user.email, "username": user.username&#125; for user in User.object.all()]# User.object.all() 返回querySet类型，使用for将数据序列化，在前端使用JsonResponse响应 1234567891011121314151617181920212223# 定义类视图，显示数据# dashboard/urls.pyfrom . import viewsurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login'), url(r'^articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/(?P&lt;day&gt;[0-9]&#123;2&#125;)/$', views.ariticleView, name='article'), url(r'^user/$', views.userView.as_view())]# dashboard/views.pyfrom django.shortcuts import renderfrom django.http import HttpResponse,JsonResponsefrom django.contrib.auth.models import Userfrom django.contrib.auth import authenticate,loginfrom django.views import View # 导入Viewimport jsonclass userView(View): def get(self, request, *args, **kwargs): querySet = User.objects.all() data = [&#123;"id": user.id, "email": user.email, "username": user.username&#125; for user in querySet] return JsonResponse(data, safe=False) 访问http://127.0.0.1:8000/dashboard/user返回数据库的查询数据，刚才创建的100个用户 分页显示使用django自带的paginator模块(如果前后端分离的情况下，不再适用!)123456789101112131415# views使用paginator写法（精简）# 官网: https://docs.djangoproject.com/en/2.1/topics/pagination/class UserViewV2(View): def get(self, request, *args, **kwargs): queryset = User.objects.all() paginator = Paginator(queryset, 10) try: page = int(request.GET.get("page")) except: page = 1 if page &lt; 1: page = 1 page = paginator.page(page) data = [&#123;"id": user.id, "email": user.email, "username": user.username&#125; for user in page.object_list] return JsonResponse(data, safe=False) 练习创建用户接口，添加数据，并返回1234567891011121314151617181920212223242526# views.pyclass userView2(View): def post(self, request, *args, **kwargs): # 1. 获取提交数据 data = request.POST.dict() # 获取post提交的所有数据 # 2. 创建用户 user = User.objects.create_user(**data) return JsonResponse(&#123;"id": user.id, "email": user.email, "username": user.username&#125;)# 调用接口创建用户In [19]: data Out[19]: &#123;'username': 'sun101', 'email': 'sun101@163.com', 'password': '123456789'&#125;In [20]: data["username"] = "sun111" In [21]: data["email"] = "sun111@163.com" In [22]: result = requests.post("http://127.0.0.1:8000/dashboard/user_create/", data) In [23]: result.status_code Out[23]: 200In [24]: result.json Out[24]: &lt;bound method Response.json of &lt;Response [200]&gt;&gt;In [25]: result.json() Out[25]: &#123;'id': 105, 'email': 'sun111@163.com', 'username': 'sun111'&#125;]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器的上行和下行带宽理解]]></title>
    <url>%2F2018%2F11%2F23%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E4%B8%8A%E8%A1%8C%E5%92%8C%E4%B8%8B%E8%A1%8C%E5%B8%A6%E5%AE%BD%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[上行带宽 和下行带宽 理解 对于服务器而言: 上行带宽是指每秒钟服务器传给客户端的最大数据量， 下载图片消耗的是上行流量 下行带宽是指客户上传数据到服务器，对于服务器来说，下行带宽是不限制的，网络因素，取决于客户端当前的网络情况]]></content>
  </entry>
  <entry>
    <title><![CDATA[Vagrantfile配置虚拟机网络]]></title>
    <url>%2F2018%2F11%2F20%2FVagrantfile%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[了解下Vagrant创建虚拟机的几种网络模式 参考博客地址 Vagrantfile网络相关配置文件端口转发12# config.vm.network "forwarded_port"config.vm.network "forwarded_port", guest: 80, host: 8080 # guest: 80 虚拟机上的端口 host: 8080 本地电脑的8080端口， 这段配置含义: 将本机的8080转发到虚拟机的80端口，可根据虚拟机实际端口，开放 公有网络1# config.vm.network "public_network" # dhcp分配一个ip给虚拟机使用 私有网络1# config.vm.network "private_network", ip: "192.168.33.10" # 自定义一个内网ip，但是不能和宿主机处于同一个网段]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>Vagrantfile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[autoenv使用]]></title>
    <url>%2F2018%2F11%2F19%2Fautoenv%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[autoenv 进入目录，自动加载虚拟环境 安装12345678# 使用git clone到本地项目git clone https://github.com/kennethreitz/autoenv.git# 添加到bashrcecho 'source /opt/autoenv/activate.sh' &gt;&gt; ~/.bashrc# 加载到当前环境source ~/.bashrc 使用123456789# 进入/opt/myproject ,自动加载python3虚拟环境cd /opt/myproject# 创建.env文件# vim .env# 添加内容如下source /home/root/python36env/bin/activate # 需要提前创建python的虚拟环境# 初次进入/opt/myproject目录，会提示,输入y即可，下次，进入此目录，会自动加载python3的虚拟环境]]></content>
      <categories>
        <category>linux运维大杂烩</category>
        <category>偷懒的工具</category>
      </categories>
      <tags>
        <tag>autoenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习(三)django URL]]></title>
    <url>%2F2018%2F11%2F18%2Fpython%E5%AD%A6%E4%B9%A0-%E4%B8%89-django-URL%2F</url>
    <content type="text"><![CDATA[django 的url基础知识 django url请求 django 加载 ROOT_URLCONF指定的模块，并寻找可用的urlpatterns.它是django.conf.urls.url() 实例的一个Python 列表。 Django 依次匹配每个 URL，在与请求的URL 匹配的第一个url停下来 一旦其中的一个正则表达式匹配上，Django 将导入并调用给出的视图，它是一个简单的Python 函数（或者一个基于类的视图） 如果没有匹配到正则表达式，或者如果过程中抛出一个异常，Django 将调用一个适当的错误处理视图：handler404， handler500， handler403， handler400 url的几种写法:123456789101112131415161718# 1.urlpatterns = [ url( r'^$', RedirectView.as_view(url="/dashboard/")), url(r'^dashboard/', include("dashboard.urls")), url(r'^accounts/', include("accounts.urls")), url(r'^admin/', admin.site.urls),]# 2. urlpatterns = [ url(r"^user/", include([ url(r'^list/$', view.userlist, name="user_list"), url(r'^info/$', view.userinfo, name="userer_inf), url(r'^modify/', include([ url(r'status/$',view.modifystatus, name="user_modify_status"), ])) ]))] url参数定义位置参数12345678910111213141516171819# dashboard/urls.pyfrom django.conf.urls import url,includefrom .views import index,loginView,ariticleView #导入views中定义articleViewfrom . import views #导入viewsurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login'), url(r'^articles/([0-9]&#123;4&#125;)/([0-9]&#123;2&#125;)/([0-9]&#123;2&#125;)/$', views.ariticleView, name='article') # 匹配url dashboard/articles/2018/11/18]# views.pyfrom django.shortcuts import renderfrom django.http import HttpResponse,JsonResponsefrom django.contrib.auth.models import Userfrom django.contrib.auth import authenticate,loginimport json# Create your views here.def ariticleView(request, *args, **kwargs): # 通过args接受参数（位置参数） return HttpResponse(json.dumps(args)) 关键字参数12# 语法： (?P&lt;name&gt;pattern) 12345678910111213141516171819# dashboard/urls.pyfrom django.conf.urls import url,includefrom .views import index,loginView,ariticleViewfrom . import viewsurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login'), url(r'^articles/(?P&lt;year&gt;[0-9]&#123;4&#125;)/(?P&lt;month&gt;[0-9]&#123;2&#125;)/(?P&lt;day&gt;[0-9]&#123;2&#125;)/$', views.ariticleView, name='article') # 定义关键字参数]# views.pydef ariticleView(request, *args, **kwargs): return HttpResponse(json.dumps(kwargs)) # 输出关键字参数# 输出结果展示&#123; "year": "2018", "month": "11", "day": "12"&#125; 额外参数1234567891011# RLconfs 具有一个钩子，让你传递一个Python 字典作为额外的参数传递给视图函数# django.conf.urls.url() 函数可以接收一个可选的第三个参数，它是一个字典，表示想要传递给视图函数的额外关键字参数from django.conf.urls import urlfrom . import viewsurlpatterns = [ url(r'^blog/(?P&lt;year&gt;[0-9]&#123;4&#125;)/$', views.year_archive, &#123;'foo': 'bar'&#125;),]#请求地址：/blog/2005/#调用函数：views.year_archive(request, year='2005',foo='bar')]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习(二)django基础配置]]></title>
    <url>%2F2018%2F11%2F17%2Fpython%E5%AD%A6%E4%B9%A0-%E4%BA%8C-django%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[学习django路程一，基础配置 django基础概念第一篇文章中，搭建了开发环境，并创建了第一个django项目，名称为devops 看下django项目，默认目录的含义 最完成的devops/目录是项目的一个容器 manager.py 一个使用的命令行工具，可让你以各种方式与该 Django 项目进行交互 内层 devops/ 目录是你项目中的实际Python包。通过它你可以导入它里面的任何东西 devops/init.py: 一个空文件，告诉Python该目录是一个Python包 devops/settings.py: 该Django项目的配置文件 devops/urls.py: 该Django项目的 URL 声明 devops/wsgi.py: 一个WSGI兼容的Web服务器的入口启动项目的命令:1python manage.py runserver 0.0.0.0:8000 django的appdjango中有app的概念，本人的理解就是，在一个项目中，有实现不同功能的代码，那么把不同的功能的代码，存放于一个目录下，这个目录就称为django的app 新建app:123python manage.py startapp dashboard#或者django-admin startapp dashboard 创建了app，肯定需要在django项目中加载到此app目录，配置说明 在项目的settings配置文件 123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'dashboard', #加载刚刚创建的app] 配置路由，进入dashboard 12345678# 在主项目devops目录的urls.py中配置from django.conf.urls import url,includefrom django.contrib import adminurlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^dashboard/', include("dashboard.urls")), # 访问dashboard，加载dashboard目录下的urls] 1234567# dashboard目录下创建urls.py文件from django.conf.urls import url,includefrom .views import indexurlpatterns = [ url(r'^$', index, name='index'), #匹配所有，然后通过index的函数响应内容，如何找到views中的index函数，通过from .views import index 导入下面要定义的views.py中的index函数] 1234567# index的定义，需要去views.py中查找，这就是django项目的FBV 基于函数的视图# views.pyfrom django.http import HttpResponse# Create your views here.def index(request): return HttpResponse("Hello,this is dashboard url") 现在访问 http://127.0.0.1:8000/dashboard 就会出现我们刚刚定义的路由信息 HttpRequest对象属性官网地址 常用的request方法12345HttpRequest.get_host()HttpRequest.get_port()HttpRequest.get_full_path()HttpRequest.is_secure()HttpRequest.is_ajax() HttpResponse对象属性1234HttpResponse.contentHttpResponse.charsetHttpResponse.status_codeHttpResponse.reason_phrase HttpResponse的另一种写法 HttpResponse传入列表,通过json.dumps JsonResponse的使用使用JsonResponse传入列表数据，必须设置 safe=False参数，要不然会报错12345678from django.shortcuts import renderfrom django.shortcuts import renderfrom django.http import HttpResponse,JsonResponse# Create your views here.def index(request): data = ["a", "b", "c"] return JsonResponse(data, safe=False) django的request中GET与POST使用浏览器访问http://127.0.0.1:8000/dashboard/?name=changming&amp;&amp;age=23在上面url中使用?号传入参数当访问这个url时，我们可以根据request.get获取数据，数据类型是request.get方法获取数据123# GETrequest.GET.get("name") #获取key对应的值，返回字符串request.GET.getlist("name") #如果key对应多个值，使用此方法，返回列表 在chrome使用postman插件，模拟发送post请求12# POSTrequest.POST.get("name") 实例化QueryDictQueryDict官网地址12345678910111213QueryDict.__init__(query_string=None, mutable=False, encoding=None)&gt;&gt;&gt; QueryDict('a=1&amp;a=2&amp;c=3') &lt;QueryDict: &#123;'a': ['1', '2'], 'c': ['3’]&#125;&gt;通过fromkeys实例化QueryDict (1.11新增)QueryDict.fromkeys(iterable, value=”, mutable=False, encoding=None)&gt;&gt;&gt; QueryDict.fromkeys(['a', 'a', 'b'], value='val') &lt;QueryDict: &#123;'a': ['val', 'val'], 'b': ['val']&#125;&gt;# 除了GET POST请求发送的数据，都会存于request.body()中request.body获取的数据，可以使用QueryDict 转换数据 完成用户登录请求练习request方法使用，判断用户和密码实现登录1234567891011121314151617181920212223242526272829303132333435363738394041# dashboard/views.pydef login(request): if request.method == "GET": return HttpResponse("Hello world") elif request.method == "POST": username = request.POST.get("username") userpass = request.POST.get("userpass") if username == "lichangming" and userpass == "123456": msg = "登录成功" return HttpResponse(msg) else: msg = "登录失败" return HttpResponse(msg)# dashboard/urls.pyfrom django.conf.urls import url,includefrom .views import index,loginurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', login, name='login')]#使用ipython模拟POST发送数据(python36env) [1::vagrant@localhost::~]$ &gt;&gt;&gt;ipythonIn [2]: import requestsIn [3]: data = &#123;&#125;In [5]: data["username"]="lichangming" In [6]: data Out[6]: &#123;'username': 'lichangming'&#125;In [7]:data["userpass"]=123456In [8]: data Out[8]: &#123;'username': 'lichangming', 'userpass': 123456&#125;In [9]: url="http://127.0.0.1:8000/dashboard/login/" In [11]: r = requests.post(url,data) In [13]: r.status_code Out[13]: 200In [14]: r.contentOut[14]: b'\xe7\x99\xbb\xe5\xbd\x95\xe6\x88\x90\xe5\x8a\x9f'In [16]: r.content.decode("utf8")Out[16]: '登录成功' django操作数据库123python manage.py dbshell # 进入数据库python manage.py showmigrations #列出未同步的模型数据python manage.py migrate #同步数据库 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# User模型的使用, python manage.py shell 进入终端(python36env) [14::vagrant@localhost::/vagrant/devops]$ &gt;&gt;&gt;python manage.py shellPython 3.6.6 (default, Nov 1 2018, 14:42:57) Type 'copyright', 'credits' or 'license' for more informationIPython 7.1.1 -- An enhanced Interactive Python. Type '?' for help.In [1]: from django.contrib.auth.models import User In [2]: ?User.objects.create_user Signature: User.objects.create_user(username, email=None, password=None, **extra_fields)Docstring: &lt;no docstring&gt;File: ~/python36env/lib/python3.6/site-packages/django/contrib/auth/models.pyType: methodIn [3]: User.objects.create_user("lichangming", "changming@163.com", "123456") Out[3]: &lt;User: lichangming&gt;# 进入数据库，查询刚刚创建的用户(python36env) [15::vagrant@localhost::/vagrant/devops]$ &gt;&gt;&gt;python manage.py dbshellReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -AWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 35Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [devops]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || devops || mysql || performance_schema |+--------------------+4 rows in set (0.00 sec)MariaDB [devops]&gt; select * from auth_user;+----+-------------------------------------------------------------------------------+------------+--------------+-------------+------------+-----------+-------------------+----------+-----------+---------------------+| id | password | last_login | is_superuser | username | first_name | last_name | email | is_staff | is_active | date_joined |+----+-------------------------------------------------------------------------------+------------+--------------+-------------+------------+-----------+-------------------+----------+-----------+---------------------+| 1 | pbkdf2_sha256$36000$2nCUpnjFR8DS$FqMKTt2+fz2mp+d8lHvgN2JGb89SgoZ4CmAQz/H3bKw= | NULL | 0 | lichangming | | | changming@163.com | 0 | 1 | 2018-11-18 04:59:54 |+----+-------------------------------------------------------------------------------+------------+--------------+-------------+------------+-----------+-------------------+----------+-----------+---------------------+1 row in set (0.00 sec)MariaDB [devops]&gt; select * from auth_user\G;*************************** 1. row *************************** id: 1 password: pbkdf2_sha256$36000$2nCUpnjFR8DS$FqMKTt2+fz2mp+d8lHvgN2JGb89SgoZ4CmAQz/H3bKw= last_login: NULLis_superuser: 0 username: lichangming first_name: last_name: email: changming@163.com is_staff: 0 is_active: 1 date_joined: 2018-11-18 04:59:541 row in set (0.01 sec)ERROR: No query specifiedMariaDB [devops]&gt;# 创建管理员账户python manage.py shellUser.objects.create_superuser("admin", "admin@163.com", "123456")# 或者通过python manage.py 创建python manage.py create_superuser #根据提示创建管理用户# 修改密码python manage.py shell&gt;&gt;&gt; from django.contrib.auth.models import User&gt;&gt;&gt; u = User.objects.get(username='lichangming')&gt;&gt;&gt; u.set_password('sunpwd@123')&gt;&gt;&gt; u.save()# 或者python manage.pypython manage.py changepassword lichangming 小实验(用户登录)需求: 获取用户输入的用户和密码，数据库查询数据，完成登录验证操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 新建login.html页面，使用form表单提交数据&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;用户登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;ul&gt; &lt;form method="post"&gt; &lt;li&gt; &lt;span&gt;用户名： &lt;/span&gt; &lt;input type="text" name="username" /&gt; &lt;/li&gt; &lt;li&gt; &lt;span&gt;密码： &lt;/span&gt; &lt;input type="password" name="userpass" /&gt; &lt;/li&gt; &lt;li&gt; &lt;input type="submit"&gt; &lt;/li&gt; &lt;/form&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt;# 配置urlfrom django.conf.urls import url,includefrom .views import index,loginView # 注意需要导入views.py中的loginViewurlpatterns = [ url(r'^$', index, name='index'), url(r'^login/$', loginView, name='login')]# 编写views函数，查询数据库使用django 的User模块完成查询数据from django.shortcuts import renderfrom django.contrib.auth.models import Userdef loginView(request): if request.method == "POST": username = request.POST.get("username") userpass = request.POST.get("userpass") try: User.objects.get(username=username) except User.DoesNotExist: return HttpResponse("用户不存在") return render(request,"login.html") # 第二种方式使用django自带的authtication方法def loginView(request): if request.method == "POST": username = request.POST.get("username") userpass = request.POST.get("userpass") user = authenticate(request, username=username, password=userpass) if user is not None: #判断返回的用户和密码是否正确，正确返回对象，错误返回失败 login(request, user) return HttpResponse("用户登陆成功") else: return HttpResponse("用户登陆失败") return render(request, 'login.html')]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的ConfigParser总结]]></title>
    <url>%2F2018%2F11%2F16%2FPython%E7%9A%84ConfigParser%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[python操作配置文件读取写入的ConfigParser模块python version: python3 代码如下12345678910# cat config.ini[db]db_port = 3306db_user = rootdb_host = 127.0.0.1db_pass = sun[concurrent]processor = 20thread = 10 12345678910111213141516171819202122232425262728293031323334353637# 获取配置文件定义的内容# -*- coding: utf-8 -*-# Author: LiChangMing# Time: 2018/11/16# Blog: https://MrLichangming.github.iofrom configparser import ConfigParsercf = ConfigParser() #实例化cf.read("config.ini") #读取配置文件secs = cf.sections() #获取所有sections，以列表返回 ["db","concurrent"]print("sections: ", secs, type(secs)) opts = cf.options("db") # 获取sections db下所有options，也就是keyprint("options: ", opts, type(opts))kvs = cf.items("db") # 以列表返回print("db: ", kvs, type(kvs))输出：db: [('db_port', '3306'), ('db_user', 'root'), ('db_host', '127.0.0.1'), ('db_pass', 'sun')] &lt;class 'list'&gt;#获取value，cf.get 以str返回db_host = cf.get("db", "db_host")db_port = cf.get("db", "db_port") db_user = cf.get("db", "db_user")db_pass = cf.get("db", "db_pass")print("db_host: ", db_host, type(db_host))print("db_port: ", db_port)print("db_user: ", db_user)print("db_pass: ", db_pass)# 获取value,cf.getint 以int类型返回数据concurrent_processor = cf.getint("concurrent", "processor")concurrent_thread = cf.getint("concurrent", "thread")print("conncurrent_processor; ", concurrent_processor, type(concurrent_processor))print("conncurrent_thread: ", concurrent_thread, type(concurrent_thread)) 123456789101112131415161718192021222324252627282930313233# ConfigParser的修改操作# cat config2.ini[hexo]url = https://localhost:4000user = guest2pass = guestpwd@123# modify# -*- coding: utf-8 -*-# Author: LiChangMing# Time: 2018/11/16# Blog: https://MrLichangming.github.iofrom configparser import ConfigParserimport oscf = ConfigParser()# modify cf, be sure to read!cf.read("config2.ini")cf.set("hexo", "user", "changming")cf.set("hexo", "pass", "king@pwd@123")# write filewith open("config2.ini", "w+") as f: cf.write(f) f.close()结果:[hexo]url = https://localhost:4000user = changmingpass = king@pwd@123 ConfigParser写入操作12345678910111213141516171819202122232425# -*- coding: utf-8 -*-# Author: LiChangMing# Time: 2018/11/16# Blog: https://MrLichangming.github.iofrom configparser import ConfigParserimport oscf = ConfigParser()# add section / set option &amp; valuecf.add_section("myblog")cf.set("myblog", "url", "https://localhost:4000")cf.set("myblog", "user", "guest")cf.set("myblog", "pass", "testpwd@123")# write to filewith open("config2.ini", "w+") as f: cf.write(f) f.close()查看内容[myblog]url = https://localhost:4000user = guestpass = testpwd@123]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python的ConfigParser</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的argparse总结]]></title>
    <url>%2F2018%2F11%2F16%2Fpython%E7%9A%84argparse%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[argparse是python内置的一个用于命令选项与参数解析的模块argparse 将会从 sys.argv 中解析出这些参数，并自动生成帮助和使用信息 使用python3操作 参考博客地址 argparse使用 创建ArgumentParser()对象 调用add_argument()方法添加参数 使用parse_args()解析添加的参数12345678910111213# cat python_argparse.py# -*- coding: utf-8 -*-import argparseparser = argparse.ArgumentParser()parser.add_argument("value", type=int, help="显示输出的值")args = parser.parser_args()print(args.value)# 执行python python_argparse.py 100100 以上定义的参数value称为定位参数，必须输入value值，并且是数字类型 可选参数定义12345678910111213141516# -*- coding: utf-8 -*-import argparseparser = argparse.ArgumentParser()parser.add_argument("--square", help="display a square of a given number", type=int)parser.add_argument("--cubic", help="display a cubic of a given number", type=int)args = parser.parse_args()if args.square: print args.square**2if args.cubic: print args.cubic**3 12345678# 执行python python_argparse.py --square 864python python_argparse.py --cubic 28(python36env) [25::vagrant@localhost::/vagrant/practice]$ &gt;&gt;&gt;python python_argparse.py --cubic 28]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python的argparse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python脚本积累1]]></title>
    <url>%2F2018%2F11%2F15%2Fpython%E8%84%9A%E6%9C%AC%E7%A7%AF%E7%B4%AF1%2F</url>
    <content type="text"><![CDATA[总结下工作中写过的python脚本以下脚本内容，主要控制容器服务的启动和停止，采用多线程，并发执行 脚本思路展示 定义变量文件，key=value格式，使用python自带的文件读取模块，读取所有行，以=号分割存储为字典格式 使用os.popen执行linux的bash命令，并获取结果，os.popen(‘hostname’).read().strip() 使用re模块，匹配内容 123456789value = "HTTP/1.1 200 OKServer: nginx/1.15.5Date: Thu, 15 Nov 2018 12:43:43 GMTContent-Type: text/html; charset=utf-8Connection: keep-alive"findPattern = re.compile(r'200') result = findPattern.findall(value) 使用sys模块，获取参数 sys.argc[1] len(sys.argv) 使用python3的threading123for num in range(2, len(sys.argv)): threads = threading.Thread(target=controlService().stop, args=[sys.argv[num]]) threads.start() 脚本内容123456789101112# appServiceControl.conf# Decription: 控制各主机容器服务启停，定义的变量# 变量内容根据脚本主要定义: 1. 项目,获取项目值进入容器 2. 反注册dubbo的url请求 3. check监测tomcat的状态url请求# 基础变量project=app#反注册dubbo的url请求tomcat_dubbo_off=curl -s http://localhost:8080/destroy/serviceStop | grep success# tomcat的check请求app-service=/lt-service/health/check.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#!/usr/bin/env python3#coding: utf-8# python_version : 3.5.3# __author__ == "Sun"#Description: a主机控制容器中的tomcat服务 启动 停止import os,sys,re,time,threadingclass controlService: env_file = os.path.join(os.getcwd(),"appServiceControl.conf") hostname = os.popen('hostname').read() def get_env(self, key): #读取变量文件，转换成python字典 env_dict = &#123;&#125; if os.path.exists(self.env_file): with open(self.env_file) as f: for line in f.readlines(): line = line.strip("\n") if len(line) != 0 and not line.startswith('#'): k = line.split("=")[0] v = line.split("=")[1] env_dict[k] = v if env_dict.__contains__(key): return env_dict.get(key) else: result = self.env_file + "未定义此变量" + key return result else: result = self.env_file + "变量文件不存在" return result def getContainerName(self, app): #获取容器名 project = self.get_env('project') containerName = os.popen('docker ps --format "&#123;&#123;.Names&#125;&#125;" --filter name=' + project + '-' + app + "." + self.hostname).read().strip() return containerName def get_check(self, app): #停止服务后，进行check请求，确认服务是否停止 check_url = "curl -s -I http://" + self.get_env('project') + "-" + app + "." + self.hostname + ":8080" + self.get_env(app) container_name = self.getContainerName(app) response = os.popen("docker exec " + container_name + ' ' + check_url).read() statusCode = re.compile(r'200') result = statusCode.findall(response) if result: return True else: return False def stop(self, *apps): # 停止服务 for app in apps: container_name = self.getContainerName(app) app_dubbo_off = app + "_dubbo_off" dubbo_off = self.get_env(app_dubbo_off) print("反注册dubbo服务-------" + app) os.system("docker exec " + container_name + ' ' + dubbo_off) check_value = self.get_check(app) if not check_value: result = "反注册dubbo成功，check状态码为非200,开始执行stop" #调试信息 print(result) os.system("docker exec " + container_name + ' ' + 'stop.sh') print("休眠20秒，进行check监测是否停止服务") time.sleep(20) check_info = self.get_check(app) if not check_info: result = "服务已停止 " print(result + app) return result else: return_info = os.popen("docker exec " + container_name + ' ' + "status.sh").read().strip() print("反注册dubbo服务失败" + '--服务状态信息----' + return_info ) def start(self, *apps): #启动服务 for app in apps: print("监测服务是否是停止状态-check-----" + app) check_value = self.get_check(app) if check_value: print("服务已是运行状态 !!...... " + app) return False else: container_name = self.getContainerName(app) print("启动服务---" + app) os.system('docker exec ' + container_name + ' ' + 'start.sh') print("休眠20秒，开始进行check监测启动是否成功-----------" + app) time.sleep(20) check_value = self.get_check(app) if check_value: result = app + "服务已启动，check状态码为200" print(result) return result else: result = app + "服务启动失败，请手动查看日志" print(result) return resultif __name__ == "__main__": try: parameter = sys.argv[1] except IndexError: print("检查参数是否正确") else: if parameter == "stop": for num in range(2, len(sys.argv)): threads = threading.Thread(target=controlService().stop, args=[sys.argv[num]]) threads.start() # controlService().stop(sys.argv[num]) elif parameter == "start": for num in range(2,len(sys.argv)): threads = threading.Thread(target=controlService().start, args=[sys.argv[num]]) threads.start() # controlService().start(sys.argv[num])]]></content>
      <categories>
        <category>python实践</category>
      </categories>
      <tags>
        <tag>python脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python学习(一)搭建开发环境]]></title>
    <url>%2F2018%2F11%2F15%2Fpython%E5%AD%A6%E4%B9%A0-%E4%B8%80-%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[学习来源： 51Reboot学院搞运维，不管写python脚本，还是python的项目，都希望在linux环境中调试代码所以使用，以下方式搭建自己的本地开发环境使用vagrant+virtualbox+pycharm 安装软件OS: windows software: vagrant virtualboxvagrant和virtualbox直接google搜索下载即可， vagrant使用 下载vagrant的centos7镜像centos-7.2镜像下载地址 下载完后，在windows，创建目录D:\studyProject\51Reboot\vagrant CMD进入终端，使用以下命令进行初始化镜像,从而启动虚拟机12345# 格式 vagrant box add 初始化名称 镜像vagrant box add centos-7.2 vagrant-centos-7.2.box # 在目录下需要存在镜像vagrant box list # 可以查看当前主机模板vagrant init centos-7.2 # 进行初始化 初始化完镜像后，会在当前路径下生成Vagrantfile文件，修改此文件修改： 将本地的8000端口转到虚拟机中8000端口 1234567vagrant up #启动刚刚初始化的虚拟机vagrant ssh #可以直接进入linux主机中vagrant halt #关闭虚拟机vagrant suspend #暂停虚拟机vagrant resume #恢复虚拟机vagrant destroy #删除虚拟机 可以使用xshell链接:123456IP： 127.0.0.1Port: 2222User: vagrantpassword: vagrant# 切换到root用户，直接sudo -s即可！ 使用vagrant启动的虚拟机，会把本地宿主机的目录映射到虚拟机中的 /vagrant目录cd /vagrant 可以看到，就是宿主机的目录 在虚拟机中安装python12345678wget https://www.python.org/ftp/python/3.6.6/Python-3.6.6.tgz# 安装依赖包yum install openssl-devel readline-devel unzip -y# 编译安装./configure --prefix=/usr/local/python36make &amp;&amp; make install 创建虚拟环境创建虚拟环境，有利于项目的迁移，那些依赖包，可以直接将venv目录拷走即可1234567891011#普通用户执行sudo /usr/local/python36/bin/pip3 install virtualenv# 创建虚拟环境/usr/local/python36/bin/virtualenv ./python36env # 注意: 后续pycharm需要使用vagrant配置连接此主机，所以虚拟环境需要在普通用户目录下# 虚拟环境生效source ./python36env/bin/activate# 在虚拟环境中安装djangopip install "django&gt;=1.11,&lt;2.0" 安装数据库123456789101112131415161718192021222324252627# 在虚拟机中安装mariadbsudo yum -y install mariadb mariadb-server mariadb-devel#修改mariadb配置文件# sudo vim /etc/my.cnf[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemddefault-storage-engine=innodb #添加此内容 --startinnodb_file_per_tablecollation-server=utf8_general_ciinit-connect='SET NAMES utf8'character-set-server=utf8 # --stop[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid## include all files from the config directory#!includedir /etc/my.cnf.d 12345678910# 启动mariadb服务sudo systemctl start mariadbsudo systemctl enable mariadb# 初始化数据库mysql_secure_installation#创建数据库mysql -u root -p #登录数据库create database devops CHARACTER SET utf8; 12# 在python的虚拟环境中安装mysqlclientpip3 install mysqlclient 启动django项目在虚拟机中，进入/vagrant 目录执行以下命令，初始化一个django项目1django-admin startproject devops #启动django项目 windows配置pycharm打开远端项目打开pycharm，点击file ==&gt; settings ==&gt; project Interpreter在右侧project Interpreter 的齿轮标记 点击 Add… 左侧选择 Vagrant目录选择刚刚在虚拟机 /vagrant目录下 创建的devops项目，并且此目录要有Vagrantfile文件， pycharm才能加载vagrant使用 Python interpreter path: 此处选择在主机创建的pytohn3虚拟环境 配置django的数据库123456789101112131415# 在devops目录# settings文件DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'devops', 'USER': 'root', 'PASSWORD': '123456', 'HOST': '127.0.0.1', 'PORT': '3306', 'OPTIONS': &#123; 'init_command': 'SET default_storage_engine=INNODB;', &#125;, &#125;&#125; 运行django在虚拟机中执行命令运行123source python36env/bin/activate #在宿主目录执行cd devopspython manage.py runserver 0.0.0.0:8000 #浏览器访问1http://127.0.0.1:8000 #Vagrantfile 文件中设置了本机的8000端口转发到linux虚拟机8000 pycharm运行：点击manage.py ，在if name == “main__”: 区域，左边有播放按钮，点击在pycharm的 右上方 选项框会出现manage字符，点击三角部位，选择 Edit Configure 配置run参数 即可运行django项目 Parameters: 填写此参数: runserver 0.0.0.0:8000 在pycharm的Terminal 也可以输入vagrant ssh进入linux主机进行操作! 使用vagrant注意:电脑关机，下次需要通过在cmd终端，进入Vagrantfile文件当前路径，输入vagrant up启动虚拟机，会把当前的目录挂载到虚拟机中去。]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty添加nginx_dynamic_upstream模块]]></title>
    <url>%2F2018%2F11%2F12%2Fopenresty%E6%B7%BB%E5%8A%A0nginx-dynamic-upstream%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[openresty version : 1.13.6.2编译nginx添加nginx_dynamic_upstream模块，提供api接口，动态控制后端upstream的server上下线 模块下载地址nginx_dynamic_upstream github 地址 聊聊编译的那些事 openresty 1.13.6.2封装的nginx也是1.13.6 添加第三方模块，只需要重新编译openresty即可，添加编译参数 –add-module=/usr/local/src/nginx_dynamic_upstream 编译完后，使用nginx -V 查看是否正确安装nginx_dynamic_upstream模块 nginx_dynamic_upstream接口使用说明文档配置12345678910111213141516171819202122# nginx.confupstream backends &#123; zone zone_for_backends 1m; #zone_for_backends为指定zone的name，可以自定义name server 127.0.0.1:6001; server 127.0.0.1:6002; server 127.0.0.1:6003;&#125;server &#123; listen 6000; location /dynamic &#123; allow 127.0.0.1; deny all; dynamic_upstream; &#125; location / &#123; proxy_pass http://backends; &#125;&#125; API指定upstream name列出所有的server12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends"server 127.0.0.1:6001;server 127.0.0.1:6002;server 127.0.0.1:6003; 指定upstream name列出所有server的详细信息12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;verbose="server 127.0.0.1:6001 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6002 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6003 weight=1 max_fails=1 fail_timeout=10; 更新server参数12345678910[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;server=127.0.0.1:6003&amp;weight=10&amp;max_fails=5&amp;fail_timeout=5"server 127.0.0.1:6001 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6002 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6003 weight=10 max_fails=5 fail_timeout=5;# 支持更新的参数 weight max_fails fail_timeout 下线节点 Down12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;server=127.0.0.1:6003&amp;down="server 127.0.0.1:6001 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6002 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6003 weight=1 max_fails=1 fail_timeout=10 down; 上线节点 up12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;server=127.0.0.1:6003&amp;up="server 127.0.0.1:6001 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6002 weight=1 max_fails=1 fail_timeout=10;server 127.0.0.1:6003 weight=1 max_fails=1 fail_timeout=10; 添加节点 add123456[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;add=&amp;server=127.0.0.1:6004"server 127.0.0.1:6001;server 127.0.0.1:6002;server 127.0.0.1:6003;server 127.0.0.1:6004; 移除节点 remove12345[::root@test::~] curl "http://127.0.0.1:6000/dynamic?upstream=zone_for_backends&amp;remove=&amp;server=127.0.0.1:6003"server 127.0.0.1:6001;server 127.0.0.1:6002;server 127.0.0.1:6004;]]></content>
      <categories>
        <category>openresty</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7中设置目录的ACL规则]]></title>
    <url>%2F2018%2F11%2F02%2Fcentos7%E4%B8%AD%E8%AE%BE%E7%BD%AE%E7%9B%AE%E5%BD%95%E7%9A%84ACL%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[centos系统设置目录的ACL控制权限 获取ACL1getfacl 目录 # 查看目录的ACL规则 设置ACL1setfacl -m u:test:rw /data/data1/ #对data1目录设置允许test用户读取写入]]></content>
      <categories>
        <category>linux运维大杂烩</category>
        <category>Centos7相关内容</category>
      </categories>
      <tags>
        <tag>Centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty中lua代码调试日志]]></title>
    <url>%2F2018%2F10%2F27%2Fopenresty%E4%B8%ADlua%E4%BB%A3%E7%A0%81%E8%B0%83%E8%AF%95%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[openresty中，如何使用了lua代码，调试信息输出到log中 1ngx.log(ngx.ERR,"判断一个变量的值: ---", value) #输出value的值到错误日志中]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客美化添加live2d]]></title>
    <url>%2F2018%2F10%2F24%2Fhexo%E5%8D%9A%E5%AE%A2%E7%BE%8E%E5%8C%96%E6%B7%BB%E5%8A%A0live2d%2F</url>
    <content type="text"><![CDATA[hexo添加live2d的使用 live2d-github地址 使用说明文档安装插件 在hexo的根目录下执行 1npm install --save hexo-helper-live2d 安装完插件后，可以安装喜欢的模型模型名称:模型展示图 live2d-widget-model-chitose live2d-widget-model-epsilon2_1 live2d-widget-model-gf live2d-widget-model-haru live2d-widget-model-haruto live2d-widget-model-hibiki live2d-widget-model-hijiki live2d-widget-model-izumi live2d-widget-model-koharu live2d-widget-model-miku live2d-widget-model-ni-j live2d-widget-model-nico live2d-widget-model-nietzsche live2d-widget-model-nipsilon live2d-widget-model-nito live2d-widget-model-shizuku live2d-widget-model-tororo live2d-widget-model-tsumiki live2d-widget-model-unitychan live2d-widget-model-wanko live2d-widget-model-z16 本人安装的是live2d-widget-model-haruto1npm install live2d-widget-model-haruto 配置使用 在hexo的根目录创建名为live2d_models的文件夹 把之前安装的模型文件夹从node_modules文件夹复制到live2d_models中 比如我这里安装的是live2d-widget-model-haruto 从hexo的根目录的node_modules中找到这个文件夹，复制到live2d_models文件夹中 在hexo根目录下的_config.yml中的最后面添加以下内容12345678910111213141516live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-haruto display: position: right width: 150 height: 300 mobile: show: true]]></content>
      <categories>
        <category>hexo美化</category>
      </categories>
      <tags>
        <tag>hexo添加看板图片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openresty的lua语法学习一]]></title>
    <url>%2F2018%2F10%2F24%2Fopenresty%E7%9A%84lua%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[openresty的lua语法学习 lua的popen获取命令的执行结果 1234567891011121314151617181920212223242526272829-- 打开文件local myfile = io.popen("pwd", "r")if nil == myfile then print("open file for dir fail!!")endprint("\n=========command dir result:")-- 读取文件内容for cnt in myfile:lines() do print(cnt)end-- 关闭文件myfile:close()local secondfile = io.popen("ifconfig")if nil == secondfile then print("open file for ifconfig fail!!")endprint("\n==========command ifconfig result:")-- 读取文件内容local content = secondfile:read("*a")print(content)-- 关闭文件secondfile:close() openresty调用lua脚本通过openresty的web服务提供一个接口，执行系统脚本，停止某个服务，并返回结果 1234567891011121314151617# 调用 http://192.168.1.12/testapi?value=stoplocation = /testapi &#123; default_type &apos;text/plain&apos;; content_by_lua_block &#123; local value = ngx.var.arg_value if value ~= nil then local command = &quot;/usr/bin/bash /usr/local/src/stopService.sh &quot;..value local handle = io.popen(command) local result = handle:read(&quot;*a&quot;) handle:close() ngx.say(result) ngx.exit(200) else ngx.exit(404) end &#125;&#125; lua语法的字符串分割，自定义方法123456789101112131415--定义函数，分割字符串function string.split(str, splitParameter) local result = &#123;&#125; string.gsub(str,'[^'..splitParameter..']+', function(w) table.insert(result, w) end) return resultend# 可能不太好理解的就是 string.gsub中使用了另一个函数# 先看下string.gsub的使用格式 string.gsub (s, pattern, repl [,m])# s 为原字符串， pattern 为匹配的模式 repl 替换的内容 m 只查找pattern匹配的m个子串# repl 为常规字符串，成功匹配的字串会被repl直接替换# repl 是一个表，每次匹配中的第一个子串将会作为整个表的键，取table[匹配子串]来替换所匹配出来的子串，当匹配不成功时，函数会使用整个字符串来作为table的键值# repl 为函数，每一次匹配的字串都将作为整个函数的参数，取function(匹配字串)来替换所匹配出来的子串,当匹配不成功时，函数会使用整个字符串来作为函数的参数。如果函数的返回值是一个数字或者是字符串，那么会直接拿来替换，如果它返回false或者nil，替换动作将不会发生，如果返回其他的值将会报错 lua语法读取文件12345678910111213141516171819202122232425262728# 此配置简写nginx的配置文件，动态匹配url，根据文件定义proxy_pass的值function FileRead() local file_path = "/usr/local/openresty/nginx/conf/gb/3rd/api-pay-env.conf" local file = io.open(file_path, "r") for line in file:lines() do local splitValues = string.split(line, "=") if splitValues[1] == location_uri then -- 判断访问的location匹配的uri 是否存在文件 local proxy_pass_split = string.split(splitValues[2], "/")[2] -- 获取proxy_pass中的host，将端口去掉 local valueMatch = string.match(proxy_pass_split, ":") if valueMatch ~= nil then local proxy_pass_split = string.split(proxy_pass_split, ":")[1] end ngx.var.query_host = proxy_pass_split -- 修改nginx设置的query_host值,用于proxy_set_header Host $query_host; local uri = ngx.re.sub(ngx.var.request_uri, "^/.*-api/(.*)", "$1", "o") local resultProxyPass = splitValues[2] .. uri ngx.log(ngx.ERR, "set_host的值: ", proxy_pass_split) ngx.log(ngx.ERR, "proxy_pass的值: ", resultProxyPass) return resultProxyPass end endend# cat /usr/local/openresty/nginx/conf/gb/3rd/api-pay-env.confdsi-api=http://beijingxinagwang.com/api/sb-api=http://woaibeijing.com:8084/im-api=http://it.com/ 获取location匹配的url12345678910111213ngx.var.uri --获取访问的url，不带参数ngx.var.request_uri --带参数的url--获取location匹配的url--定义函数，分割url路径function string.split(str, splitParameter) local result = &#123;&#125; string.gsub(str,'[^'..splitParameter..']+', function(w) table.insert(result, w) end) return resultendlocal request_uri = ngx.var.uri --获取访问的url，不带参数local location_uri = string.split(request_uri, "/")[1] nginx修改客户访问的uri12345rewrite_by_lua' local uri = ngx.re.sub(ngx.var.request_uri, "^/.*-api/(.*)", "/$1", "o") ngx.req.set_uri(uri) ngx.log(ngx.ERR, "set_uri: ", uri) '; lua读取json文件通过lua获取get或者post提交的参数12345678910111213141516171819202122set $service ''; rewrite_by_lua ' local request_method = ngx.var.request_method if request_method == "GET" then local arg = ngx.req.get_uri_args()["service"] or 0 ngx.var.service = arg elseif request_method == "POST" then ngx.req.read_body() local arg = ngx.req.get_post_args()["service"] or 0 ngx.var.service = arg end;'; if ($service = 'register') &#123; proxy_pass http://userinfo; &#125; proxy_redirect off; proxy_set_header HOST $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>openresty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的server_name正则表达式匹配]]></title>
    <url>%2F2018%2F10%2F23%2Fnginx%E7%9A%84server-name%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[nginx的server_name 匹配正则 参考文档链接: Nginx技巧:灵活的server_name server_name如果使用了正则，优先级匹配 精确匹配server_name 1234server &#123; listen 80; server_name test1.com test2.com;&#125; 以* 通配符开始的字符串 1234server &#123; listen 80; server_name *.test.com;&#125; 以*通配符结束的字符串 1234server &#123; listen 80; server_name www.*;&#125; 匹配正则 1234server &#123; listen 80; server_name ~^api(?.+)\.test\.com #匹配api*.test.com *代表所有&#125;]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的json模块]]></title>
    <url>%2F2018%2F10%2F21%2Fpython%E7%9A%84json%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[python的json模块笔记 1import json json.dumps: 将Python对象编码成JSON字符串json.loads: 将已编码的JSON字符串解码为Python对象]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose文件对应docker版本号]]></title>
    <url>%2F2018%2F10%2F15%2Fdocker-compose%E6%96%87%E4%BB%B6%E5%AF%B9%E5%BA%94docker%E7%89%88%E6%9C%AC%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[docker-compose 文件格式版本对应docker版本 docker-compose github地址 Compose file format compatibility matrix Compose file format Docker Engine 1 1.9.0+ 2.0 1.10.0+ 2.1 1.12.0+ 2.2, 3.0, 3.1, 3.2 1.13.0+ 2.3, 3.3, 3.4, 3.5 17.06.0+ 2.4 17.12.0+ 3.6 18.02.0+ 3.7 18.06.0+]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell匹配数字]]></title>
    <url>%2F2018%2F10%2F15%2Fshell%E5%8C%B9%E9%85%8D%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[使用bash匹配数字1234567str="1222"if [[ $str =~ ^[0-9]+$ ]];then echo "True"else echo "False"fi]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[获取registry私有仓库的镜像信息]]></title>
    <url>%2F2018%2F10%2F14%2F%E8%8E%B7%E5%8F%96registry%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E7%9A%84%E9%95%9C%E5%83%8F%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[docker官方registry镜像的一些操作命令 获取registry的镜像1curl -X GET http://&#123;IP_Address&#125;:5000/v2/_catalog 获取镜像的标签列表1curl -X GET http://&#123;IP_Address&#125;:5000/v2/&#123;镜像名&#125;/tags/list]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>registry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker命令总结]]></title>
    <url>%2F2018%2F10%2F12%2Fdocker%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[docker命令总结 docker操作镜像命令导出镜像1docker save -o centos7.tar centos 导入本地镜像1docker load --input centos7.tar docker获取容器名12# docker ps获取容器完整名称docker ps --format '&#123;&#123;.Names&#125;&#125;' --filter name=匹配的关键字 获取本机容器名称1docker ps --format &#123;&#123;.Names&#125;&#125; 获取容器ID1docker ps -q 删除dead的容器1docker rm $(docker ps --all -q -f status=dead)]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker遇到的问题总结]]></title>
    <url>%2F2018%2F10%2F12%2Fdocker%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[总结在工作中，线上使用docker遇到的问题总结 swarm集群相关问题Error response from daemon: context deadline exceededQ: docker swarm集群中节点未离开集群，异常重启机器，删除节点，再次加入提示，已在集群中，docker swarm leave -f提示以下信息1Error response from daemon: context deadline exceeded A: 解决办法 删除/var/lib/docker/swarm目录 systemctl restart docker 重启docker服务 加入集群参考链接: docker swarm leave in daemon error response docker运行nginx，nginx中获取$remote_addr获取的是宿主机网桥的ip地址A: 解决办法centos7的firewalld开启地址伪装后，nginx中获取的地址就是宿主机和容器关联的那个网桥IP，也是容器的网关12345678# 检查是否允许伪装IPfirewall-cmd --query-masquerade# 允许防火墙伪装IPfirewall-cmd --add-masquerade# 禁止防火墙伪装IPfirewall-cmd --remove-masquerade 删除容器提示device or resource busy问题:123[::root@host:: ~] docker rm 834bea2c7324Error response from daemon: driver "overlay" failed to remove root filesystem for 834bea2c7324398542943babb6c9d93704cc04b93df494f5dd24719acf6645a9: remove /var/lib/docker/overlay/b4e0ef61ac822c75e5eb8c9cc6b9f2286c76f6e3ee1cccffdec482517792baa4/merged: device or resource busy 解决方法: 先查看是哪个进程pid在占用device 123456789101112# device路径: /var/lib/docker/overlay/b4e0ef61ac822c75e5eb8c9cc6b9f2286c76f6e3ee1cccffdec482517792baa4/merged# 在系统挂载设备信息中检索是哪个进程在占用[::root@host:: ~] grep b4e0ef61ac822c75e5eb8c9cc6b9f2286c76f6e3ee1cccffdec482517792baa4 /proc/*/mountinfo/proc/3594/mountinfo:799 787 0:78 / /var/lib/docker/overlay/b4e0ef61ac822c75e5eb8c9cc6b9f2286c76f6e3ee1cccffdec482517792baa4/merged rw,relatime shared:196 - overlay overlay rw,seclabel,lowerdir=/var/lib/docker/overlay/b7b47a8adc4753582404b1e666c015d094d79f04eb793d727afb222f44ffe7ba/root,upperdir=/var/lib/docker/overlay/b4e0ef61ac822c75e5eb8c9cc6b9f2286c76f6e3ee1cccffdec482517792baa4/upper,workdir=/var/lib/docker/overlay/b4e0ef61ac822c75e5eb8c9cc6b9f2286c76f6e3ee1cccffdec482517792baa4/work# 根据pid查询进程名[::root@host:: ~] ps -p 3594 -o comm=chronyd# 查看chronyd服务使用pid 3594也在使用/var/lib/docker/overlay/b4e0ef61ac822c75e5eb8c9cc6b9f2286c76f6e3ee1cccffdec482517792baa4/merged,这就是为什么无法删除相关容器并返回device or resource busy错误 重启chronyd服务，然后删除容器 12systemctl restart chronyddocker rm &lt;container-id&gt;]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>docker问题总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看证书有效期bash命令]]></title>
    <url>%2F2018%2F10%2F11%2F%E6%9F%A5%E7%9C%8B%E8%AF%81%E4%B9%A6%E6%9C%89%E6%95%88%E6%9C%9Fbash%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[openssl查看证书有效期 123456# 找到证书的CERTIFICATE文件openssl x509 -in cert1.pem -noout -dates#输出结果notBefore=Sep 20 05:07:48 2018 GMTnotAfter=Dec 19 05:07:48 2018 GMT]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>openssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7挂载windows共享文件夹]]></title>
    <url>%2F2018%2F10%2F11%2FCentos7%E7%9A%84mount%E6%8C%82%E8%BD%BDwindows%E7%9A%84%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[记录一下linux系统挂载windows共享文件夹 挂载windows的共享文件夹: 1mount -t cifs -o username="administrator",password="testPWD" //192.168.1.2/software /mnt/share 永久挂载 123vim /etc/fstab #编辑fstab文件,新增以下内容//192.168.1.2/software /mnt/share cifs auto,username="administrator",password="testPWD" 0 0]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>fstab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7编译安装python3，进入python终端不能使用退格和上下键翻动]]></title>
    <url>%2F2018%2F10%2F09%2Fcentos7%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85python3%EF%BC%8C%E8%BF%9B%E5%85%A5python%E7%BB%88%E7%AB%AF%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E9%80%80%E6%A0%BC%E5%92%8C%E4%B8%8A%E4%B8%8B%E9%94%AE%E7%BF%BB%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[编译安装的python3，进入终端不能使用退格，和上下翻键 解决办法: 1yum -y install readline-devel.* 安装以上依赖包，重新编译安装python3即可！]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vsftpd中umask数字的含义]]></title>
    <url>%2F2018%2F10%2F09%2Fvsftpd%E4%B8%ADumask%E6%95%B0%E5%AD%97%E7%9A%84%E5%90%AB%E4%B9%89%2F</url>
    <content type="text"><![CDATA[之前一直搞不懂vsftpd服务中，local_umask 设置的数值有什么含义，特此记录下所知，所得 参考链接：csdn博客:vsftpd中umask值的介绍及计算 个人总结如下:local_umask: 设置本地用户的上传文件或者目录的权限anon_umask: 设置匿名用户上传的文件或者目录的权限 文件或者目录的权限： 读取： 4 写入： 2 执行： 1 文件最高权限为666目录最高权限为777 local_umask=022 # 022 如果是文件，最高权限为666,022代表从666权限中抽走的权限，剩下644]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>vsftpd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisord提示refused connection]]></title>
    <url>%2F2018%2F10%2F09%2Fsupervisord%E6%8F%90%E7%A4%BArefused-connection%2F</url>
    <content type="text"><![CDATA[记录下在工作中，遇到docker容器的supervisord提示 refused connection 错误提示:123[root@sun-host ~]# supervisorctl statusunix:///var/run/supervisor.sock refused connection 问题追溯： 灵感获知：overlayfs不适用于unix域套接字 docker在使用overlayfs时，unix域套接字似乎不起作用，当我使用设备映射器，将/var/run挂载到容器中/var/run，这时supervisord创建的sockt文件，写入挂载的目录 /var/run/supervisor.sock 使用命令supervisorctl status查看的时候，就不再提示此错误了。 可是为了不挂载此路径，再继续翻阅技术文档，完美的解决办法就是修改docker默认的存储驱动 123456789vim /etc/docker/daemon.json #添加以下内容&#123; "storage-driver": "devicemapper" &#125;# 停止docker服务# 删除以前创建的容器数据，rm -rf /var/lib/docker/*# 启动docker服务# 使用docker info可以查看 Storage Driver的类型，默认是overlay]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>supervisord</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看linux系统CPU相关信息]]></title>
    <url>%2F2018%2F10%2F08%2F%E6%9F%A5%E7%9C%8Blinux%E7%B3%BB%E7%BB%9FCPU%E7%9B%B8%E5%85%B3%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[文档说明: 查看linux系统CPU， 物理个数 逻辑个数 单个CPU的核心数 查看物理CPU个数cat /proc/cpuinfo | grep “pysical id” | sort | uniq | wc -l 查看单个CPU的核心数cat /proc/cpuinfo | grep “cpu cores” | uniq 查看逻辑CPU的个数cat /proc/cpuinfo | grep “processor” | wc -l 物理CPU:很好理解，实际服务器插槽上的cpu个数 逻辑CPU:CPU使用超线程技术，在逻辑上在分一倍数量的cpu core出来1逻辑cpu = 物理cpu * 单个cpu核心数 * 2 CPU核心数： 官方话： 一块CPU上面能处理数据的芯片组的数量]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo Next主題给文章加密]]></title>
    <url>%2F2018%2F10%2F05%2Fhexo-Next%E4%B8%BB%E9%A1%8C%E7%BB%99%E6%96%87%E7%AB%A0%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[hexo 文章加密 插件: hexo-blog-encrypt 参考链接地址https://github.com/MikeCoder/hexo-blog-encrypt/blob/master/ReadMe.zh.md 效果展示:]]></content>
      <categories>
        <category>hexo博客配置与优化</category>
      </categories>
      <tags>
        <tag>hexo_Next主题文章加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux用户管理]]></title>
    <url>%2F2018%2F10%2F05%2Flinux%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[向组中添加用户：1usermod -G groupname username]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>linux用户</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安裝google身份认证]]></title>
    <url>%2F2018%2F10%2F05%2FCentos7%E5%AE%89%E8%A3%9Dgoogle%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[记录在Centos7上安装Google身份认证 安装epel源1yum -y install epel-release Qrencode1yum install -y qrencode # 谷歌身份验证器通过该程序生成二维码 安装google身份验证器1234567891011git clone https://github.com/google/google-authenticator-libpam.gitcd google-authenticator-libpam./bootstrap.sh./configure –prefix=/usr/local/google-authenticator# 编译时如果提示一下错误configure: error: Unable to find the PAM library or the PAM header files# 安装pam-devle库yum -y instlal pam-devel# 再次执行./configuremake &amp;&amp; make install 拷贝google的身份验证器pam模块到系统下1cp /usr/local/google-authenticator/lib/security/pam_google_authenticator.so /lib64/security/ 配置sshd的pam认证123vim /etc/pam.d/sshd# 写在auth include password-auth 基于密码认证的上面一行,先基于google验证码认证auth required pam_google_authenticator.so 修改ssh服务配置123vim /etc/ssh/sshd_configChallengeResponseAuthentication yes 重启ssh服务配置1systemctl restart sshd 开始生成google认证码1234# 进入刚才克隆下来的 google-authenticator-libpam 目录，执行./google-authenticator #基于当前用户做验证，如果切换别的系统用户，请登陆其他用户，执行此命令即可Do you want authentication tokens to be time-based (y/n) y #输入y， 提示是否基于时间的认证# 接下来会生成一张二维码图片： 手机上下载身份验证器app软件，扫描此二维码 1234567891011121314151617181920212223242526272829303132333435Your new secret key is: JS57SLVUDEEA7SQ7LD6BEBWGAA #此安全key需要备份，用于后续更换手机或者二维码丢失，浏览器的身份验证丢失后，通过此安全key获取新的验证吗 Your verification code is 005421 #扫描上述二维码后，查看验证吗，输入Your emergency scratch codes are:# 以下验证吗，是后续备用的，只能验证一次4541236521522365851246328512463114785216 Do you want me to update your “/root/.google_authenticator” file (y/n) y Do you want to disallow multiple uses of the same authenticationtoken? This restricts you to one login about every 30s, but it increasesyour chances to notice or even prevent man-in-the-middle attacks (y/n) Do you want to disallow multiple uses of the same authenticationtoken? This restricts you to one login about every 30s, but it increasesyour chances to notice or even prevent man-in-the-middle attacks (y/n) y By default, tokens are good for 30 seconds. In order to compensate forpossible time-skew between the client and the server, we allow an extratoken before and after the current time. If you experience problems withpoor time synchronization, you can increase the window from its defaultsize of +-1min (window size of 3) to about +-4min (window size of17 acceptable tokens).Do you want to do so? (y/n) y# 安全相关，默认继续 If the computer that you are logging into isn’t hardened against brute-forcelogin attempts, you can enable rate-limiting for the authentication module.By default, this limits attackers to no more than 3 login attempts every 30s.Do you want to enable rate-limiting (y/n) y# 安全相关，默认继续 使用xshell连接xshell终端的连接方式改为：keyboard Interactive 输入验证码： 输入密码：]]></content>
      <categories>
        <category>linux运维大杂烩</category>
        <category>Centos7安全配置</category>
      </categories>
      <tags>
        <tag>Google身份认证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python正则表达式]]></title>
    <url>%2F2018%2F10%2F04%2Fpython%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[python正则表达式 python获取字符串中的数字 123456import retestStr = "100abc"Number = re.sub("\D", "", testStr)print Number100]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>pyton</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows编辑的文件上传linux显示^M问题]]></title>
    <url>%2F2018%2F10%2F02%2Fwindows%E7%BC%96%E8%BE%91%E7%9A%84%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0linux%E6%98%BE%E7%A4%BA-M%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[记录一下在windows中编辑文件上传到linux的坑 windows上编辑的文件上传到linux中，使用vim打开，会显示^M 的问题 ^M 是因为windows操作系统用的文本换行符和UNIX/Linux操作系统用的不同，Windows系统下输入的换行符在UNIX/Linux下不会显示为“换行”，而是显示为 ^M 这个符号 使用vi的替换功能替换 ^M： 使用键盘的ctrl + v ctrl + M :%s/^M//g]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>^M问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sshfs 配置使用]]></title>
    <url>%2F2018%2F09%2F30%2Fsshfs-%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[sshfs: 通过ssh挂载远程的Linux文件系统或目录 以下总结参考: sshfs配置参考文档来源 安装12yum -y install epel-releaseyum -y install sshfs 使用1234567891011# 挂载远程主机的logs到本机 allow_other参数，允许普通用户读取，如果没有，只能root用户访问sshfs -o allow_other root@192.168.1.17:/var/logs/ /var/logs/testMountLogs/#Ubuntu挂载方式sudo sshfs -o allow_other root@192.168.1.17:/var/logs/ /var/logs/testMountLogs/#基于ssh秘钥授权sshfs -o IdentityFile=~/.ssh/id_rsa root@192.168.1.17:/var/lb/logs/ /var/logs/testMountLogs/#Ubuntu挂载方式sudo sshfs -o allow_other,IdentityFile=~/.ssh/id_rsa root@192.168.1.17:/var/lb/logs/ /var/logs/testMountLogs/ 永久挂载使用12345sshfs#root@192.168.1.17:/var/lb/logs/ /var/logs/testMountLogs/ fuse.sshfs defaults 0 0 基于秘钥的挂载：sshfs#root@192.168.1.17:/var/lb/logs/ /var/logs/testMountLogs/ fuse.sshfs IdentityFile=~/.ssh/id_rsa defaults 0 0]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>sshfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grep检索出ip地址]]></title>
    <url>%2F2018%2F09%2F29%2Fgrep%E6%A3%80%E7%B4%A2%E5%87%BAip%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[grep匹配ip地址 1grep -E "([0-9]&#123;1,3&#125;[\.])&#123;3&#125;[0-9]&#123;1,3&#125;"]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose相关内容]]></title>
    <url>%2F2018%2F09%2F28%2Fdocker-compose%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[记录下工作中常用的docker-compose相关内容 开机自启动docker-compose部署的容器开机自动运行找到/etc/rc.d/rc.local文件,添加以下脚本1/usr/local/bin/docker-compose -f /usr/local/nginx/docker-compose.yml up -d docker-stack 部署的compose文件语法simple example:1234567891011121314151617181920212223242526version: "3.3"networks: swarm-net: external: trueservices: rd-1: image: hub.dayu-boss.com/core/redis networks: swarm-net: aliases: - ss-rd-1 ports: - target: 6379 published: 6381 protocol: tcp mode: host hostname: rd-1 deploy: placement: # 部署在指定的节点 constraints: [node.labels.redis == 1] restart_policy: condition: on-failure ports映射123456#docker stack部署时，使用的ports映射ports: - target: 6379 # 容器的端口 published: 6381 # 宿主机映射的端口 protocol: tcp # 协议 mode: host # host用于在每个节点上发布主机端口，或者ingress用于负载平衡的群集模式端口 docker-compose up 部署的compose文件12345678910networks: t-net: driver: bridge driver_opts: com.docker.network.enable_ipv6: "false" ipam: driver: default config: - subnet: 172.30.31.0/24 gateway: 172.30.31.1]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python OS模块的学习积累]]></title>
    <url>%2F2018%2F09%2F28%2Fpython-OS%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%A7%AF%E7%B4%AF%2F</url>
    <content type="text"><![CDATA[python的学习就是不断的撸，才能对这项技能有更深入的了解 聊聊工作中用到的最基础的功能 os模块目录结构 os.walk 返回可迭代对象os.getcwd 返回当前路径 1234567891011121314151617181920212223242526272829303132333435dir = “/var/lb/apps”# 以下，输出目录下的所有文件，包括二级目录下的文件&gt;&gt;&gt; for root,subdirs,files in os.walk(dir):... print(files)... []['world.txt']['index.html'][][]['test.txt', 'test']# 以下，输出所有目录的绝对路径&gt;&gt;&gt; for root,subdirs,files in os.walk(dir):... print(root)... /var/lb/apps/var/lb/apps/pc-h5/var/lb/apps/mobile-h5/var/lb/apps/server/var/lb/apps/server/WEB-INF/var/lb/apps/server/classes以下输出所有目录，包括二级目录&gt;&gt;&gt; for root,subdirs,files in os.walk(dir):... print(subdirs)... ['pc-h5', 'mobile-h5', 'server'][][]['WEB-INF', 'classes'][][]&gt;&gt;&gt; 12345# 读取文件内容，转为Python字典格式# 文件/etc/environment 内容定义为host=devops1file=testapps=tensorflow 1234567891011121314151617#将以上内容转为字典#!/usr/bin/env python#coding: utf-8import osenv_file = "/etc/environment"def get_env_dict(env_file): env_dict = &#123;&#125; if os.path.exists(env_file): with open(env_file) as f: for line in f.readlines(): line = line.strip("\n") if len(line) != 0 and not line.startswith('#'): k = line.split("=")[0] v = line.split("=")[1] env_dict[k] = v return env_dict]]></content>
      <categories>
        <category>python学习之路</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx缓存静态资源proxy_cache的一些指令的含义]]></title>
    <url>%2F2018%2F09%2F28%2Fnginx%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[记录nginx的缓存proxy_cache的指令的含义 proxy_cache相关的指令proxy_cache_path : 设置缓存路径/tmp/proxy_cache levels=1:2，表示第一级目录1个字符，第2级目录两个字符。 keys_zone=cache_www:100m表示这个zone的名字叫cache_www，分配内存的大小为100MB。inactive表示如果这个资源在inactive规定的时间内没有被访问到就会被删除。max_size表示这个zone可以使用的硬盘空间。 add_header ： 在给客户端的返回中，增加名为X-Cache-Status的header，其值是缓存命中情况，比如MISS，HIT等等。 proxy_cache ： 设置缓存资源的zone proxy_cache_key ： 设置缓存文件中的key，硬盘中缓存文件的名字key值的MD5。譬如key是test.xnow.me/，则在硬盘上的md5值是c9d71dc81143d6d9a60165bdcb1b9c9f，计算方法： echo -n “test.xnow.me/“ | md5sum proxy_cache_valid 200 304 301 302 10d： 设置缓存的状态码，把返回状态是200和304的请求缓存起来。缓存时间是60分钟，过了缓存时间之后，设置缓存状态为EXPIRED，这是绝对时间，和上次更新时间相比。10d代表缓存的时间，为10天proxy_cache_use_stale 返回码出错的时候，使用缓存数据。譬如出现超时，502和503等等情况 Example配置nginx的缓存，通过两个指令控制：proxy_cache_pathproxy_cache 12345678910111213141516proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;server &#123;...location / &#123;proxy_cache my_cache;proxy_cache_lock on;proxy_cache_key $uri$is_args$args # $uri: 请求的URI，可能和最初的值不同，比如经过重定向之类的 # $is_args: 请求行中是否匹配参数，如果有参数返回?,没有返回空字符串 # args: 请求中的参数proxy_cache_valid 200 304 10d;proxy_pass http://my_upstream;expires 7d;&#125;&#125; 注释：proxy_cache_path：/path/to/cache 设置缓存文件的存放路径 levels=1:2 设置缓存文件存放目录层级结构，1:2表示第一级目录一个字符，第二级目录2个字符，这样存放的目的，提高文件的读取速度，默认会存放于一个目录中key_zone=my_cache:10m 共享内存区的名称，用于存储缓存键和元数据，设置空间大小10MBmax_size=10g 设置缓存的上限大小，默认允许缓存不断增长，直到用尽可用的磁盘空间inactive=60m 指定在内存中的缓存文件，在60分钟内没有被访问，就会自动删除use_temp_path=off 关闭临时存储区域，开启状态，会把一个写入缓存的文件，先放入一个临时存储区域，建议关闭，可以避免文件系统中不必要的数据拷贝 在location中 使用proxy_cache 共享内存区名称 ，启用匹配location的内容进行缓存 缓存优化参数：proxy_cache_lock on 启用此配置，如果请求到没有存在缓存中的文件时，将只有第一个请求去源服务器获取内容，后续请求从缓存中获取数据。 清除缓存模块ngx_cache_purge说起nginx缓存模块，必须要知道proxy_cache_key设置的nginx的内置变量获取的是什么内容,贴一张图Nginx内置绑定变量 安装此模块，下载模块到本地，只需要重新编译nginx，添加参数–add-module=/usr/local/src/ngx_cache_purge即可 使用ngx_cache_purge12345678#配置# 静态资源清除，在nginx的配置文件添加 location ~ /__purge(/.*) &#123; proxy_cache_purge cache_one $1$is_args$args; #这个是根据我上述proxy_cache_key设置的缓存key进行清除 &#125;# 使用# 浏览器访问此接口，后面加上清除的单个静态资源文件即可]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx_proxy_cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置健康监测中指令的含义]]></title>
    <url>%2F2018%2F09%2F28%2Fnginx%E9%85%8D%E7%BD%AE%E5%81%A5%E5%BA%B7%E7%9B%91%E6%B5%8B%E4%B8%AD%E6%8C%87%E4%BB%A4%E7%9A%84%E5%90%AB%E4%B9%89%2F</url>
    <content type="text"><![CDATA[记录在nginx的upstream后端健康监测配置中，各指令的含义 比较常见的配置方式12345678910upstream backend1 &#123; sticky; server 192.168.0.125:8080 max_fails=1 fail_timeout=10s weight=1; server 192.168.0.126:8080 max_fails=1 fail_timeout=10s weight=1; server 192.168.0.127:8080 max_fails=1 fail_timeout=10s weight=1; keepalive 16; check interval=3000 rise=1 fall=3 timeout=2000 type=http; check_http_send "HEAD hall/health/check.html HTTP/1.0\r\nUser-Agent:check\r\n\r\n"; check_http_expect_alive http_2xx http_3xx;&#125; 以上配置，采用http的方式，对后端tomcat的做健康监测，通过tomcat中提供的check.html接口返回的状态，判断tomcat是否存活。 指令的各含义server中指令含义 max_fails=1 允许失败的次数为1次，配合fail_timeout使用fail_timeout=10s 在10s内允许的失败次数 加上上面一条指令，指的是，在10秒内的期间如果失败次数为1此，即认为后端不可用，不转发请求到此后端 check指令 interval: 向后端发送的健康检查包的间隔fall: 如果失败次数达到定义的数，服务器就认为是downrise: 如果成功次数达到定义的数,服务器就认为是uptimout: 后端健康请求的超时时间default_down: 设定初始时服务器的状态,如果是true,就说明默认是down的，如果是false，就是up的，默认值为true，也就是一开始服务器认为是不可用的，要等健康检查包达到一定成功次数以后才会被认为是健康的type： 健康监测的类型,常见的类如下: tcp: 简单的tcp连接，如果连接成功，说明后端正常 ssl_hello: 发送一个输出的SSL hello包并接受服务器的SSL hello 包 http: 发送http请求，通过后端的回复包的状态来判断后端是否存活 mysql: 向mysql服务器连接，通过接受Cpong包来判断后端是否存活 ajp: 向后端发送AJP协议的Cping包，通过接受Cpong包来判断后端是否存活port: 指定后端服务器的检查端口. 1234567891011121314151617# TCP健康监测upstream gb-core-idc1 &#123; ip_hash; keepalive 30; server 192.168.1.10 max_fails=1 fail_timeout=5s weight=10; # r1 server 192.168.1.11 max_fails=1 fail_timeout=5s weight=10; # r2 server 192.168.1.12 max_fails=1 fail_timeout=5s weight=10; # r3 server 192.168.1.13 max_fails=1 fail_timeout=5s weight=10; # r4 server 192.168.1.14 max_fails=1 fail_timeout=5s weight=10; # r1 server 192.168.1.15 max_fails=1 fail_timeout=5s weight=10; # r2 server 192.168.1.16 max_fails=1 fail_timeout=5s weight=10; # r3 server 192.168.1.17 max_fails=1 fail_timeout=5s weight=10; # r4 check interval=3000 rise=3 fall=3 timeout=2000 type=tcp; check_http_send "GET / HTTP/1.1\r\n\r\n"; check_http_expect_alive http_2xx http_3xx;&#125;]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx中常见的一些变量]]></title>
    <url>%2F2018%2F09%2F28%2Fnginx%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[常见的日志变量 $remote_addr, $http_x_forwarded_for 记录客户端IP地址 $remote_user记录客户端用户名称 $request记录请求的URL和HTTP协议(GET,POST,DEL,等) $status记录请求状态 $body_bytes_sent发送给客户端的字节数，不包括响应头的大小； 该变量与Apache模块mod_log_config里的“%B”参数兼容。 $bytes_sent发送给客户端的总字节数。 $connection连接的序列号。 $connection_requests 当前通过一个连接获得的请求数量。 $msec 日志写入时间。单位为秒，精度是毫秒。 $pipe如果请求是通过HTTP流水线(pipelined)发送，pipe值为“p”，否则为“.”。 $http_referer 记录从哪个页面链接访问过来的 $http_user_agent记录客户端浏览器相关信息 $request_length请求的长度（包括请求行，请求头和请求正文）。 $request_time 请求处理时间，单位为秒，精度毫秒；从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止。 $time_iso8601 ISO8601标准格式下的本地时间。 $time_local通用日志格式下的本地时间]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的location配置优先级]]></title>
    <url>%2F2018%2F09%2F28%2Fnginx%E7%9A%84location%E9%85%8D%E7%BD%AE%E4%BC%98%E5%85%88%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[记录下，平常工作中容易混淆的nginx的location 优先级匹配的问题 location表达式类型~ 表示执行一个正则匹配，区分大小写~* 表示执行一个正则匹配，不区分大小写^~ 表示普通字符匹配，使用前缀匹配。如果匹配成功，则不再匹配其他location= 进行普通字符精确匹配。完全匹配 location优先级说明注意： 在nginx的location配置中，和顺序没有太大关系，相同类型的表达式，字符串长的会优先匹配 优先级排列说明: 第一优先级，等号类型，一旦匹配成功，则不再查找其他匹配项 第二优先级，^~ 类型表达式，一旦匹配成功，则不再查找其他匹配项 第三优先级，正则表达式类型(~ ~*)的优先级次之，如果有多个location的正则能匹配的话，则使用正则表达式最长的那个 第四优先级，常规字符串匹配类型，按前缀匹配]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lsyncd的配置与使用]]></title>
    <url>%2F2018%2F09%2F26%2Flsyncd%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简要说明下lsyncd的配置与使用 lsyncd： 持续监控目录下的文件，有变动，实时同步 安装环境描述: OS: centos7 12yum -y install epel-releaseyum install -y lsyncd 配置需求： 两台远程主机之间，目录同步， host1目录： /var/vm1 host2目录： /var/vm2不能加delete=true,因为，在host1的目录如果删除，会同步到host2，把host2中存在的也删除了 lsyncd.conf配置 配置参数说明lsyncd.conf配置选项说明(列出工作中常用的) settings123456789settings &#123; logfile="/var/log/lsyncd.log", #定义日志文件路径 statusFile="/var/log/lsyncd.status", #定义哪些文件发生变动的状态日志 statusInterval=5, # 将lsyncd的状态写入statusFile的间隔，默认为10秒 maxDelays=3, # 累计到多少所监控的事件激活一次同步 inotifyMode="CloseWrite or Modify", # 指定inotify监控的事件，默认CloseWrite（关闭写入操作） nodaemon=false, # 表示不启用守护模式 maxProcesses=1, # 同步进程的最大个数，执行rsync的进程数，如果设置3个进程，有20个文件同步，最大有3个rsync进程&#125; sync12345678sync &#123; default.rsyncssh, #指定同步参数，以什么模式运行 source="/var/data/", #监控的源目录 host="10.10.4.2", # 目标主机 targetdir="/var/data/", #目标目录 exclude=&#123; "*.swp","*.swx" #排除同步的文件 &#125;, rsync 参数12345678910rsync = &#123; binary = "/usr/bin/rsync", archive = true, compress = true, verbose = true, _extra = &#123;"--delete=false"&#125;, &#125;, ssh=&#123; port=22 &#125; default.rsync配置 1234567891011121314151617181920212223242526272829settings &#123; logfile = "/var/log/lsyncd/lsyncd.log", statusFile = "/var/log/lsyncd/lsyncd-status.log", statusInterval = 10, insist = true&#125;sync &#123; -- rsync , rsyncssh , direct 三种模式 default.rsync, source="/home/test1", target="root@test::test2", delete = false, delay = 20, maxProcesses = 2, exclude = &#123; ".git", ".idea", &#125;, rsync = &#123; compress = true, acls = true, verbose = true, owner = true, group = true, perms = true &#125;&#125;]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>lsyncd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jumpserver部署文档]]></title>
    <url>%2F2018%2F09%2F24%2Fjumpserver%E9%83%A8%E7%BD%B2%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[jumpserver部署文档 Jumpserver特点： 1）完全开源，GPL授权 2）Python编写，容易再次开发 3）实现了跳板机基本功能，身份认证、访问控制、授权、审计 、批量操作等。 4）集成了Ansible，批量命令等 5）支持WebTerminal 6）Bootstrap编写，界面美观 7）自动收集硬件信息 8）录像回放 9）命令搜索 10）实时监控 11）批量上传下载 参考官网地址，写的非常详细 jumpserver官网部署文档]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>jumpserver</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http状态码分析]]></title>
    <url>%2F2018%2F09%2F24%2Fhttp%E7%8A%B6%E6%80%81%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[以下http协议分析图片来自菜鸟教程：http协议状态码 如有侵犯，请告知，将删除。]]></content>
      <categories>
        <category>http状态码</category>
      </categories>
      <tags>
        <tag>http状态码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git操作]]></title>
    <url>%2F2018%2F09%2F21%2FGit%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[作为一名运维人员，学会使用git也是完全有必要的 #git在分支下工作 创建新分支：1git checkout -b sun #此命令，会创建新分支，并切换到新分支上 添加修改的代码文件，到当前新分支12git add 文件git commit -m “注释信息” 合并分支123git checkout master #先切换到master分支上git merge sun #合并新分支sun ，到当前的master上 合并后，删除当前分支1git branch -d sun #如果没有合并，不能删除当前分支 查看所有分支1git branch -a git add之后的撤销操作123456789101112git status #可以看到git add 中的文件git reset HEAD #对上次所有的add撤销git reset HEAD test.txt #只对上次add test.txt文件撤销git commit 之后的撤销操作git log #查看commit信息的哈希值例如：commit b262ed4528aebe2052f0c92e149e3e3fb0f7c609git reset &#123;commit后的哈希值&#125;git push 之后的撤销操作git revert HEAD 撤销前一次 commit git revert HEAD^ 撤销前前一次 commit git revert commit-id (撤销指定的版本，撤销也会作为一次提交进行保存） git revert是提交一个新的版本，将需要revert的版本的内容再反向修改回去，版本会递增，不影响之前提交的内容。 git pull 显示代码冲突的解决办法：123如果丢弃本地的更改，同步仓库的代码，使用以下方法：git reset –hardgit pull git合并冲突解决1git checkout -- 文件名 # 以工程为主，覆盖本地文件 git忽略本地文件权限发生变动123git config core.filemode false# 或者修改.git/config文件filemode = false]]></content>
      <categories>
        <category>Git基本操作技能</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7部署ftp服务]]></title>
    <url>%2F2018%2F09%2F21%2FCentos7%E9%83%A8%E7%BD%B2ftp%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[在生产环境，开发需要借助ftp来上传开发程序包，特此记录下，部署vsftpd的笔记，方便后续查看 环境说明OS: Centos7.3 1511(core) 部署123yum -y install vsftpdsystemctl enable vsftpdsystemctl start vsftpd 配置采用虚拟用户，基于系统用户，实现不同用户，控制不同目录12345678910111213141516171819cp /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.bak# vim /etc/vsftpd/vsftpd.conf# 禁用匿名用户登录anonymous_enable=NO# 添加下列内容到vsftpd.conf末尾use_localtime=YESlisten_port=21chroot_local_user=YESidle_session_timeout=300guest_enable=YESguest_username=vsftpduser_config_dir=/etc/vsftpd/vconfdata_connection_timeout=1virtual_use_local_privs=YESpasv_min_port=10060pasv_max_port=10090accept_timeout=5connect_timeout=1allow_writeable_chroot=YES 建立用户文件123# vim /etc/vsftpd/virtuserstesttestpwd@123 生成用户数据文件123456789101112131415161718db_load -T -t hash -f /etc/vsftpd/virtusers /etc/vsftpd/virtusers.db #设定PAM验证文件，并指定对虚拟用户数据库文件进行读取 chmod 600 /etc/vsftpd/virtusers.db ## 修改前先备份 cp /etc/pam.d/vsftpd /etc/pam.d/vsftpd.bak# 将auth及account的所有配置行均注释掉# vi /etc/pam.d/vsftpdauth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/virtusersaccount sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/virtusers# 如果系统为32位，上面改为lib例如：![ftpd](/images/ftp-virtusers.png)## 新建系统用户useradd vsftpd -d /home/vsftpd -s /sbin/nologinchown -R vsftpd:vsftpd /home/vsftpd 建立虚拟用户个人配置文件1234567891011121314mkdir /etc/vsftpd/vconfcd /etc/vsftpd/vconftouch test ##虚拟用户是什么，这里就是什么# vim test内容如下：local_root=/data/packages/write_enable=YESanon_world_readable_only=NOanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES 防火墙配置12firewall-cmd --add-service=ftp --permanentfirewall-cmd --reload 重启vsftpd服务1systemctl restart vsftpd 需要注意刚才/data/packages这个目录的本地权限需要允许vsftpd用户，有访问权限！ 如果后续要增加用户： 例如添加test1用户1234567891011121314151617181920212223# 编辑此文件，添加虚拟用户的配置# vim /etc/vsftpd/virtusers# 追加：test1testpwd@123生成用户数据文件db_load -T -t hash -f /etc/vsftpd/virtusers /etc/vsftpd/virtusers.db# 进入此目录/etc/vsftpd/vconftouch test1# 编辑test文件vim test1# 添加以下内容:local_root=/date/test1/packages #指定上传路径write_enable=YESanon_world_readable_only=NOanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>vsftpd配置与使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker仓库Harbor的配置与使用]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker%E4%BB%93%E5%BA%93Harbor%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[有一个私有仓库来管理镜像，还是非常方便的，特此记录下部署docker Harbor的笔记 参考链接 官方文档相关链接安装和配置指南用户指南 简介 Harbor的基本功能： VMware公司最近开源了企业级Registry项目Harbor，由VMware中国研发的团队负责开发 基于角色的访问控制 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限。 镜像复制 – 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡，高可用，混合云和多云的场景。 图形化用户界面 – 用户可以通过浏览器来浏览，检索当前Docker镜像仓库，管理项目和命名空间。 AD/LDAP 支持 – Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。 审计管理 – 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。 国际化 – 已拥有英文、中文、德文、日文和俄文的本地化版本。更多的语言将会添加进来。 RESTful API – RESTful API 提供给管理员对于Harbor更多的操控, 使得与其它管理软件集成变得更容易。 部署简单 – 提供在线（online）和离线（offline）两种安装工具， 也可以安装到vSphere平台(OVA方式)虚拟设备。 官方提供的架构图 环境描述 OS : Centos7本机已经安装docker docker-compose 安装部署下载离线安装包安装包链接地址 解压包1tar xf harbor-offline-installer-v1.5.1.tgz 修改配置文件123456789101112131415# 主配置文件harbor.cfg以下修改的参数中，仓库启用了https，满足docker仓库默认pull push需要使用https，要不然需要修改docker参数添加 –insecure-register修改hostname = hub.com #这个配置，是指定docker 仓库的url地址，也就是在客户端执行 docker pull 时，需要指定的仓库地址 修改ui_url_protocol = https #指定url访问为https，默认是http， 如果这里修改成https，如果使用http访问仓库，会自动跳转到https上；修改customize_crt: on #打开表示，创建私钥和根证书，用于https链接，官方介绍:打开或关闭，默认打开）打开此属性时，准备脚本创建私钥和根证书，用于生成/验证注册表令牌。当由外部来源提供密钥和根证书时，将此属性设置为off。 ssl_cert = /data/cert/hub.com.bundle.crt #ssl证书路径，ssl_cert_key = /data/cert/hub.com.key.pem #ssl私钥文件路径 这两项，在nginx的配置中使用；会加载到nginx的配置文件中注释： https生成证书，我使用的是github上的一个生成自签名证书的脚本生成；这个脚本，使用openssl注册自签名证书，只不过把所有的操作封装成了脚本，可以生成多域名证书，泛域名证书，表示很好用，也可以参考官网提供的openssl 生成 github链接地址：https://github.com/Fishdrowned/ssl 修改self_registration = off #禁止普通用户可以注册用户选项 修改project_creation_restriction = adminonly #只允许管理员创建项目 配置截图： 当然，harbor支持邮件发送，用户忘记密码，通过邮件来更改密码；这里我没有使用邮件服务； harbor也可以支持ldap认证；修改完配置文件，接下来就是制作证书了： 制作证书：创建目录：（此目录，容器会挂载此目录下的证书文件，也就是配置文件中指定的证书路径），当然也可以自定义此路径mkdir /data/cert使用openssl命令生成证书（本文我使用的是脚本生成）openssl生成证书主要分几个步骤： 创建CA证书 生成证书签名请求 生成服务器证书 介绍脚本使用： 脚本路径： /root/ssl 脚本执行: ./gen.cert.sh hub.com 脚本输出路径： /root/ssl/out/hub.com/ 证书生成成功后，就可以执行脚本安装了！修改docker-compose.yml,指定端口访问主要修改，proxy映射到宿主机的默认端口，80改为5000，https默认使用443； 执行以下命令，运行容器：1./install.sh 安装完成后，可以使用docker-compose ps 查看运行的容器；安装成功后，就可以使用浏览器进行访问了！注意： 生成证书时，使用的是hub.com，hub.com是一个虚假的域名，需要在本机添加hosts文件， 192.168.0.154 hub.com 访问UI界面https://hub.com 介绍几个命令如果在容器运行后，修改配置文件，使用以下命令，重新加载容器 停止容器：(注意需要在harbor目录中执行，因为要依赖docker-compose.yml文件) docker-compose down重新加载配置文件修改harbor.cfg配置文件后，执行以下命令，重新生成文件 ./prepare #如果语法错误，会提示错误启动容器： docker-compose up -d]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker Harbor仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker与系统软件防火墙关系]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker%E4%B8%8E%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E9%98%B2%E7%81%AB%E5%A2%99%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[在使用docker的过程中，经常遇到要改动防火墙，要注意的问题 以下笔记总结参考此链接: Docker网络与防火墙 QAQ: 在docker运行的过程中，重启了firewalld或者iptables A:会触发，在宿主机无法转发请求到容器，这是因为 docker 在默认启动的时候，会修改iptables规则，如果重启了iptables，或者firewalld，则docker默认启动服务设置的规则就会丢失，所以会影响容器访问 Q: 启动一个新的docker容器，映射了端口，需不需要在系统防火墙开放端口 A: 不需要，因为docker 容器如果映射了端口，在没有指定网络模式的情况下，默认使用docker0网络，也就是容器的网关，容器访问外部数据，到达docker0，也就是网关后，会查询主机的路由表，确定数据包从哪个网卡发出，iptables负责对数据包进行snat转换，将源地址转换为对应网卡的地址，因此容器对外是不可见的。 A: 外部想要访问容器内的数据，首先需要将容器的端口映射到宿主机上。这时候docker会在iptables添加转发规则，把接收到的数据转发给容器。 注意:如果在启动docker服务的情况下，需要动态添加防火墙规则。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker与系统防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker swarm 一些常用命令]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker-swarm-%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[记录工作中常用的一些docker swarm的命令 docker命令官网 docker swarm命令docker swarm创建集群1docker swarm init --advertise-addr 192.168.1.10 node节点加入集群1234567891011docker swarm join --token "创建集群的tocken值" 192.168.1.10:2377#如果忘记了加入集群的命令，可以在管理节点执行以下命令获取[1::root@sun-host::~]# &gt;&gt;&gt;docker swarm join-token manager #查看加入管理节点的tockenTo add a manager to this swarm, run the following command: docker swarm join --token SWMTKN-1-5n0yqdoirvjroddv4tk4q352rjg5ywqo0gur2a5ibaw517y9ed-6bwuuocgw1lx3anqsiy373uyn 192.168.1.10:2377[1::root@sun-host::~]# &gt;&gt;&gt;docker swarm join-token worker #查看加入工作节点的tockenTo add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-5n0yqdoirvjroddv4tk4q352rjg5ywqo0gur2a5ibaw517y9ed-5lo62wh31nrt439b679s2ulim 192.168.1.10:2377 查看集群中的服务12docker service ls docker service ls ps 服务名 查看服务部署在哪个节点1docker service ps 服务名 修改服务实例数1docker service scale nginx=3 删除节点1docker node rm node2 排除节点1docker node update --availability drain &lt;NODE-ID&gt; 恢复排除的节点1docker node update --availability active &lt;NODE-ID&gt; 删除shutdown的容器,和无用数据清理1docker system prune -f docker node常用命令12345678docker node ls #查看所有集群节点docker node rm #删除某个节点（-f强制删除）docker node inspect ##查看节点详情,标签 --pretty 显示信息比较规整docker node demote #节点降级，由管理节点降级为工作节点docker node promote #节点升级，由工作节点升级为管理节点# docker node promote node1 node2 # 提升node1 node2节点为管理节点docker node update #更新节点docker node ps #查看节点中的 Task 任务 docker service 常用命令123456789docker service create #创建服务, 如果编写compose文件，可以使用docker stack命令部署docker service inspect #查看服务的详细信息docker service ps #查看服务运行的节点docker service logs #查看某个服务的日志信息docker service rm #删除服务docker service ls #列出集群中所有服务docker service ls --filter name=字符串匹配服务名 #过滤servicedocker service update #更新服务docker service update --image hub.com/image service_name #更新服务的镜像 docker swarm服务的动态命令设置123456789101112# 命令格式 docker service [option] servicedocker service update --env-adddocker service update --env-rm docker service update --host-add docker service update --host-rmdocker service update --hostnamedocker service update --mount-add type=volume,source=/data,target=/datadocker service update --mount-rm type=volume,source=/data,target=/datadocker service update --network-add name=my-network,alias=web1 # Add a networkdocker service update --network-rm name=my-network,alias=web1docker service update --publish-add published=8080,target=80 # Add or update a published portdocker service update --publish-rm published=8080,target=80 # Remove a published port by its target port 批量删除所有服务12docker service ls -1 # 获取所有service的IDdocker service ls -q | xargs docker service rm Docker Stack 部署多个集群服务docker stack使用文件docker-compose.yml批量部署服务创建编排文件docker-compose.yml12345678910111213141516version: '3'services: mynginx: image: hub.test.com:5000/almi/nginx:0.1 ports: - "8081:80" deploy: replicas: 3 busybox: image: hub.test.com:5000/busybox:latest volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: replicas: 2 使用docker-stack批量创建服务123docker stack deploy -c docker-compose.yml deploy-testdocker stack ps deploy-tes# docker stack部署的容器名称 deploy-test_&lt;service名称&gt;.随机后缀 docker stack 常用命令123456docker stack deploy #部署新的堆栈或更新现有堆栈docker stack ls #列出现有堆栈docker stack ps #列出堆栈中的任务docker stack rm #删除堆栈 （docker stack deploy部署的时候指定的服务名字）docker stack services #列出堆栈中的服务docker stack down #移除某个堆栈（不删数据） docker stack deploy 显示服务的状态accepted: 任务已经被分配到某一个节点执行preparing: 准备资源，一般是从网络拉取iamgerunning: 副本运行成功shutdown: 报错，终止，当一个任务被终止（stoped or killed），任务不能被重启，但是一个替代的任务会被重启 查看swarm中服务的ip1docker service inspect --format '&#123;&#123; .Endpoint.VirtualIPs &#125;&#125;' 服务名]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker中使用supervisor管理进程]]></title>
    <url>%2F2018%2F09%2F20%2Fdocker%E4%B8%AD%E4%BD%BF%E7%94%A8supervisor%E7%AE%A1%E7%90%86%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[docker file 中 ENTRYPOINT 和CMD的用法 ENTRYPOINT &amp;&amp; CMD在docker file中，如果同时指定了ENTRYPOINT和CMD，例如： CMD 的指令将作为参数传递给ENTRYPOINTENTRYPOINT 指定 /usr/bin/tini – /usr/bin/entrypoint.sh /usr/bin/tini 是转发信号，防止僵尸进程， /usr/bin/entrypoint.sh脚本指定了exec $@接受所有的参数，也就是会接受CMD传递过来的参数，启动supervisord服务 为何这样用呢？ 如果有些操作，需要在docker 容器运行前需要指定的操作，就可以通过shell写在ENTRYPOINT.sh脚本中，控制容器执行操作！]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker file</tag>
        <tag>ENTRYPOINT</tag>
        <tag>CMD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7绑定双网卡]]></title>
    <url>%2F2018%2F09%2F19%2Fcentos7%E7%BB%91%E5%AE%9A%E5%8F%8C%E7%BD%91%E5%8D%A1%2F</url>
    <content type="text"><![CDATA[Centos7绑定双网卡： #安装必需的包：1yum install teamd -y #停止NetworkManager123systemctl stop NetworkManagersystemctl disable NetworkManager #Creating a Network Team Using ifcfg Files12345678910111213cd /etc/sysconfig/network-scripts/vi ifcfg-team0DEVICE=team0DEVICETYPE=TeamONBOOT=yesBOOTPROTO=noneIPADDR=192.168.10.110PREFIX=24GATEWAY=192.168.10.254TEAM_CONFIG='&#123;"runner": &#123;"name": "activebackup"&#125;, "link_watch": &#123;"name": "ethtool"&#125;&#125;'#做好备份继续编辑需要绑定的网卡信息，调整prio优先级 1234567# cat ifcfg-eno1DEVICETYPE=TeamPortTEAM_MASTER=team0TEAM_PORT_CONFIG='&#123;"prio":100&#125;'NAME=eno1DEVICE=eno1ONBOOT=yes 12345678# cat ifcfg-eno2DEVICETYPE=TeamPortTEAM_MASTER=team0TEAM_PORT_CONFIG='&#123;"prio":99&#125;'NAME=eno2DEVICE=eno2ONBOOT=yes 123#重启网络systemctl restart network #检查端口状态12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697teamnl team0 ports1: eth0: up 1000Mbit FD2: eth1: up 1000Mbit FD#检查teaming状态teamdctl team0 statesetup: runner: activebackupports: eno1 link watches: link summary: up instance[link_watch_0]: name: ethtool link: up eno2 link watches: link summary: up instance[link_watch_0]: name: ethtool link: uprunner: active port: eno1#手动断开其中一条链路验证主备模式切换是否正常ip link set eno1 downteamdctl team0 statesetup: runner: activebackupports: eno1 link watches: link summary: up instance[link_watch_0]: name: ethtool link: up eno2 link watches: link summary: up instance[link_watch_0]: name: ethtool link: uprunner: active port: eno2]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux高阶命令使用]]></title>
    <url>%2F2018%2F09%2F19%2Flinux%E9%AB%98%E9%98%B6%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[编写shell脚本中，常用的一些awk grep getops 语法 awk1234567tailf access.log | awk 'substr($3,1,3)&gt;200'# 查看访问日志中，过滤非200状态码的日志请求# substr是一个内置函数substr($4,20) # 表示从第四个字段里的第20个字符开始，一直到设定的分隔符 结束substr($4,1,3) # 表示从第四个字段里的第1个字符开始，截取3个字符结束substr($4,3,6) # 表示从第四个字段里的第3个字符开始，截取6个字符结束 getopsgetops指定参数，获取值 1234567891011121314151617181920[root@test-host tmp]# cat test.shwhile getopts “:h:p:” optname;do case “$optname” in “h”) echo “ -h选项的值是 $OPTARG” ;; “p”) echo “-p 选项的值是 $OPTARG” ;; “?” ) echo “不知道此选项” ；； “:”) echo “此选项没有值” ;; “*”) echo “错误信息” ；； esacdone 1234Usage: ./test.sh -h 192.168.1.18 -p 22"-h 选项的值是 192.168.1.18""-p 选项的值是 22" fgrep12fgrep -c "hello" test.txt #匹配hello字符在test.txt文件中匹配行的数目fgrep -l "hello" test.txt #显示匹配hello的文件名 du命令统计目录大小1du -h --max-depth=1 &#123;path&#125; #只显示目录的层级是一级，但是列出的大小，是属于整个文件夹的 pkill12#提出当前登录用户的终端sudo pkill -kill -t pts/15 脚本执行，获取当前路径1cur_dir="$(cd "$(dirname "$[BASH_SOURCE[0]]")"; pwd)" echo输出颜色123456789101112131415161718192021222324252627282930313233343536373839404142434445464748echo -e "\e[31m 我要输入的内容 \e[0m" #输出内容为红色echo -e "\033[31m 红色字 \033[0m"echo -e "\033[34m 黄色字 \033[0m"echo -e "\033[41;33m 红底黄字 \033[0m"echo -e "\033[41;37m 红底白字 \033[0m"# 字颜色: 30--37 echo -e "\033[30m 黑色字 \033[0m" echo -e "\033[31m 红色字 \033[0m" echo -e "\033[32m 绿色字 \033[0m" echo -e "\033[33m 黄色字 \033[0m" echo -e "\033[34m 蓝色字 \033[0m" echo -e "\033[35m 紫色字 \033[0m" echo -e "\033[36m 天蓝字 \033[0m" echo -e "\033[37m 白色字 \033[0m"# 字背景颜色范围：40—–47 echo -e "\033[40;37m 黑底白字 \033[0m" echo -e "\033[41;37m 红底白字 \033[0m" echo -e "\033[42;37m 绿底白字 \033[0m" echo -e "\033[43;37m 黄底白字 \033[0m" echo -e "\033[44;37m 蓝底白字 \033[0m" echo -e "\033[45;37m 紫底白字 \033[0m" echo -e "\033[46;37m 天蓝底白字 \033[0m" echo -e "\033[47;30m 白底黑字 \033[0m"# 最后控制选项 \33[0m 关闭所有属性 \33[1m 设置高亮度 \33[4m 下划线 \33[5m 闪烁 \33[7m 反显 \33[8m 消隐 \33[30m — \33[37m 设置前景色 \33[40m — \33[47m 设置背景色 \33[nA 光标上移n行 \33[nB 光标下移n行 \33[nC 光标右移n行 \33[nD 光标左移n行 \33[y;xH设置光标位置 \33[2J 清屏 \33[K 清除从光标到行尾的内容 \33[s 保存光标位置 \33[u 恢复光标位置 \33[?25l 隐藏光标 \33[?25h 显示光标 sed获取域名解析的ip地址1nslookup www.baidu.com | sed -n -e '4,$p' | awk '/Address/&#123;print $2&#125;' tr分割符123456789testinfo="python,java,php"for i in $testinfo;do echo $testinfo | tr ',' '\n' #将逗号隔开，\n换行 , \n也可以使用别的字符替换done#结果输出:pythonjavaphp 123# 使用-- 拼接[42::root@test-host:: test]# &gt;&gt;&gt; for i in $testinfo;do echo $testinfo | tr ',' '--'; donepython-java-php eval命令12eval ls $pipe wc -l# shell第1次扫描命令行时，它替换出pipe的值｜，接着eval使它再次扫描命令行，这时shell把｜作为管道符号了。 查看timewait的连接数1ss -tan state time-wait | wc -l 获取系统当前时间1date +%Y.%m.%d-%H:%M:%S 获取系统时间(前30分钟)1date -d '-30 munutes' "+%F %T" 截取30分钟内的日志信息1234# 截取三十分钟日志_befor=$(date -d '-30 minutes' "+%F %T")_now=$(date "+%F %T")awk -F '\\[|\\]' -v _befor="$&#123;_befor&#125;" -v _now="$&#123;_now&#125;" '$2 &gt; _befor &amp;&amp; $2 &lt; _now&#123;print $0&#125;' /var/log/nginx//access.log 获取本机的内网ip地址1ip addr | grep inet | egrep -v '(127.0.0.1|inet6|docker)' | awk '&#123;print $2&#125;' | tr -d "addr:" | head -n 1 | cut -d / -f1 显示目录结构各级的权限1namei -om /path/to/check]]></content>
      <categories>
        <category>linux高阶命令</category>
      </categories>
      <tags>
        <tag>awk getopts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志检索常用命令]]></title>
    <url>%2F2018%2F09%2F19%2Fnginx%E6%97%A5%E5%BF%97%E6%A3%80%E7%B4%A2%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[查找特定时间点的日志1cat access.log | awk '$1 &gt;="[21/Jul/2014:14:37:50" &amp;&amp; $1 &lt;="[21/Jul/2014:14:38:00"' 禁止特定ip访问12345678封掉此IP： iptables -t mangle -I PREROUTING -s 192.168.1.53 -j DROP解封命令： iptables -t mangle -D PREROUTING -s 192.168.1.53 -j DROP#查看mangle规则# 打印出行号iptables -t mangle -L --line-numbers |grep DROP# 通过编号删除一条规则iptables -t mangle -D PREROUTING 1 获取IP前101awk '&#123;print $7&#125;' access.log | sort | uniq -c | sort -n | tail 计算文件中列的和12345678[root@test-host /tmp]# cat test.txt12345#求列的和awk 'BEGIN&#123;sum=0&#125;&#123;sum+=$1&#125;END&#123;print sum&#125;' test.txt 检索request_time比较长的日志请求12# 匹配request_time大于1秒以上的请求日志中，并匹配hall的location匹配cat access.log | awk 'substr($10,2,5)&gt;1 &amp;&amp; $0~/hall/&#123;print $0&#125;' &gt; lr2-response_long_access.log 统计nginx访问日志的QPS1tail -f access.log | awk '&#123;print $3&#125;' | awk 'BEGIN&#123;key="";count=0&#125;&#123;if(key==$1)&#123;count++&#125;else&#123;printf("%s\t%d\r\n", key, count);count=1;key=$1&#125;&#125;' 根据访问IP统计UV1awk '&#123;print $1&#125;' access.log|sort | uniq -c |wc -l 统计访问URL统计PV1awk '&#123;print $7&#125;' access.log|wc -l 查询访问最频繁的URL1awk '&#123;print $7&#125;' access.log|sort | uniq -c |sort -n -k 1 -r|more 查询访问最频繁的IP1awk '&#123;print $1&#125;' access.log|sort | uniq -c |sort -n -k 1 -r|more 根据时间段统计查看日志1cat access.log| sed -n '/14\/Mar\/2015:21/,/14\/Mar\/2015:22/p'|more 截取30分钟内的日志信息1234# 截取三十分钟日志_befor=$(date -d '-30 minutes' "+%F %T")_now=$(date "+%F %T")awk -F '\\[|\\]' -v _befor="$&#123;_befor&#125;" -v _now="$&#123;_now&#125;" '$2 &gt; _befor &amp;&amp; $2 &lt; _now&#123;print $0&#125;' /var/log/nginx//access.log tomcat日志统计访问url排名1cat /var/lb/logs/la?/hall/localhost_access_log.2019-03-12.txt | awk -F '\\[|\\]' '$2 &gt; "12/Mar/2019:13:00:00" &amp;&amp; $2 &lt; "12/Mar/2019:13:59:59" &amp;&amp; $0 !~ /health/&#123;gsub("\?.*$", "");print&#125; ' | awk '&#123;print $6,$7&#125;' | sort | uniq -c | sort -n | tail -20]]></content>
      <categories>
        <category>linux运维基本技能</category>
      </categories>
      <tags>
        <tag>nginx日志检索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown语法积累]]></title>
    <url>%2F2018%2F09%2F19%2FMarkdown%E8%AF%AD%E6%B3%95%E7%A7%AF%E7%B4%AF%2F</url>
    <content type="text"><![CDATA[markdwon语法积累图片加载显示图片1![加载图片](/images/custome.png) 引用1&gt; 代表引用 标题1234# 一级标题## 二级标题### 三级标题......... 依次类推 表格单元格和表头使用 | 来分割不同的单元格 12345| name | description || ---- | --- ||ansible_ssh_host | 执行的主机 | |ansible_ssh_user | ssh连接的用户名 ||ansible_ssh_port | ssh目标主机的端口号 | name description ansible_ssh_host 执行的主机 ansible_ssh_user ssh连接的用户名 ansible_ssh_port ssh目标主机的端口号 对齐 :— 代表左对齐 :–: 代表居中对齐 —: 代表右对齐]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英语学习一]]></title>
    <url>%2F2018%2F09%2F18%2F%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[英语爱好者的词汇积累 Bus No.38 has a regular schedule.第38路车有一个固定的时间表regular: [/‘rɛgjəlɚ/] 定期的，有规律的schedule: [/ˈskedʒʊl; skɛdʒʊl/] vt.安排，计划 It comes every 15 minutes.每15分钟就有一次 3.Bus No.47 comes less often.第47路公共汽车很少 It comes at 8:20,8:45,and 9:25.它是在8:20,8:45和9:25 Bus No.60 is the earliest bus.第60路公共汽车是最早的。earliest： [ /‘ɝlɪɪst/] 早的，初期的 It comes at 8:05,8:30,and 9:00时间是8:05,8:30和9:00 Bus No.38 has stops at the main train station and the airport.38路公共汽车停在火车总站和机场 Bus No.60 stops at the main train station,but doesn’t go to the airport.第60路公共汽车停在火车站，但不去机场 Bus No.47 doesn’t go to either the main train station or the airport.第47路公共汽车即不去火车站也不去机场either：[/‘iðɚ/] adj.两者之中任一的 prep. 任何一个 The last bus to the airport left 15 minutes ago,at 8:55.最后一班去机场的巴士15分钟前，8点55分 Here is a bus scheduel at a bus stop.这是公共汽车站的公交时刻表 It has the schedule for 3 buses between 8:00 and 9:30 in the morning.有3辆公共汽车的时间表在早上8:00到9:30之间]]></content>
      <categories>
        <category>英语学习</category>
      </categories>
      <tags>
        <tag>常明学英语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible的playbook文件的语法]]></title>
    <url>%2F2018%2F09%2F18%2Fansible%E7%9A%84playbook%E6%96%87%E4%BB%B6%E7%9A%84%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[记录工作中使用到的编写playbook文件的一些语法 ansible中编写playbook文件，通过不同的角色执行操作首先看一份playbook文件, 文件名 testInstallDocker.yml1234567891011#入口playbook文件---- hosts: 'test-1' #sudo: yes # ansible 2版本后，以什么用户执行命令的方式，改为以下方式 become: yes become_user: root become_method: sudo roles: - docker - yum 执行命令12ansible-playbook testInstallDocker.yml#这条命令执行，接下来，会发生什么呢？ 首先会找到testInstalldocker.yml文件中定义的内容， — 代表注释， - hosts: test-1 指定要操作的主机是test-1 sudo: yes 表示允许普通用户执行sudo权限 roles: roles 会默认去ansible的默认/etc/ansible/roles目录下找 docker yum, 当然此目录也可以通过ansible.cfg文件修改 进入/etc/ansible/roles目录1234567891011121314151617181920212223以下可以看到/etc/ansible/roles/&#123;docker,yum&#125; 目录下创建的文件[sun@test-host roles]$ tree -L 2 dockerdocker ├── files #在playbook语法中，指定源文件，从此目录中查找│ ├── daemon.json│ └── docker-ce.repo├── handlers #定义触发操作，在playbook中通过notify定义│ └── main.yml├── meta #定义当前角色的依赖关系│ └── main.yml└── tasks #入口文件 └── main.yml4 directories, 5 files[sun@test-host roles]$ tree -L 2 yumyum├── Readme.txt├── tasks│ └── main.yml└── vars └── main.yml2 directories, 3 files 以上两个目录docker yum，就可以称之为角色， 通过刚才的入口文件，调用角色 看一下角色中创建的各文件都是什么意思？ files/：存放由copy或script模块等调用的文件；templates/:template模块查找所需要模板文件的目录；tasks/：至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含；handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含；vars/：至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含；meta/：至少应该包含一个名为main.yml的文件，定义当前角色的特殊设定及其依赖关系；其它的文件需要在此文件中;default/：设定默认变量时使用此目录中的main.yml文件； 在角色中的入口文件，就是tasks目录，查看docker角色的tasks目录下的main.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[sun@test-host /etc/ansible/roles/docker/tasks] cat main.yml---# 删除旧版本- name: Ensure old versions of Docker are not installed. package: #调用ansible的package模块，安装rpm包 name: '&#123;&#123; item &#125;&#125;' #&#123;&#123; item &#125;&#125; 使用模板变量语法，item可以迭代执行元素， 就是with_items中定义的元素 state: absent # package安装包的几种状态 absent代表删除软件包 present 监测是否安装，否，则安装 with_items: - lxc-docker - docker-engine - docker - docker-common - docker.io#安装存储库- name: Ensure depend package is installed package: name: '&#123;&#123; item &#125;&#125;' state: present with_items: - yum-utils - device-mapper-persistent-data - lvm2# 添加 repo- name: Add Docker repository. copy: # 调用copy模块，拷贝文件 src: docker-ce.repo # src指定的文件路径，就是docker角色中files 目录中的文件 dest: /etc/yum.repos.d/docker-ce.repo #目标主机的路径 owner: root group: root mode: 0644# 安装指定版本- name: Install docker package: name: "docker-ce-17.09.1.ce-1.el7.centos" state: present enablerepo: docker-ce-stable# 添加 /etc/docker/- name: Ensure /etc/docker/ exist file: path=/etc/docker/ mode=0600 state=directory #调用file模块， state=directory，表示path指定的路径是一个目录，不存在则创建# 启动服务器- name: Ensure Docker is started and enabled at boot. systemd: #调用systemd控制服务状态 name: docker state: started #启动docker服务 enabled: yes #开机自启动 docker角色定义依赖关系12345# cat //etc/ansible/roles/docker/meta/main.yml# yum角色执行完后，再执行docker角色---dependencies: - &#123; role: yum &#125; 查看yum角色中的tasks目录下的main.yml文件12345678910111213141516---- name: Install epel repo yum: #调用yum模块 name: 'epel-release.noarch' state: latest- name: install the 'Development tools' package group yum: name: "@Development tools" state: present- name: Install packages yum: #调用yum模块 name: "&#123;&#123; pkg_list &#125;&#125;" #这里的pkg_list 变量会从 当前角色的vars目录下的main.yml中获取 state: latest #更新到最新版本 1234[sun@test-host /etc/ansible/roles/yum/vars]$ cat main.yml pkg_list: - bash-completion - bash-completion-extras 在playbook中，yum模块和package的区别： yum是centos 和redhat系列系统的默认安装rpm包命令 如果是ubuntu系统或者opensuse系统，那么就得使用package的模块了，该模块会为每个系统调用相关的包模块（apt，yum等） 最开始的那条命令，ansible-playbook testInstallDocker.yml ，就会找到docker角色，yum角色，并且根据角色中的入口文件执行相应操作！理解ansible-playbook的路由关系后，就可以熟练编写playbook文件，定义不同模块的角色执行。 ansible-playbook命令使用123ansible-playbook --syntax-check /path/to/playbook.yml #测试playbook文件中定义的语法是否正确ansible-playbook -C /path/to/playbook.yml #只测试运行，并无真正执行ansible-playbook /path/to/playbook.yml #执行playbook文件 playbook文件中各模块的语法systemd服务systemd控制服务运行状态 service服务12- name: Enable firewalld service: name=firewalld state=started enabled=yes user模块user模块的用法: 添加或者删除用户，根据state 指定state: present 用户存在，不执行操作，不存在，添加state:absent: 删除用户 with_items,对于元素迭代使用 如果是多个元素呢？ 多个元素迭代使用方法： gourp模块goup模块的用法 file模块file模块创建目录1234567---- name: "创建目录" file: path=&#123;&#123; item &#125;&#125; state=directory with_items: - /usr/local/nginx - /usr/local/src/nginx file模块创建软连接, 将/usr/local/python3/bin/python3 软连接到/usr/bin/python3 file模块设置权限 unarchive解压模块用于解压文件，模块包含如下选项： copy：在解压文件之前，是否先将文件复制到远程主机，默认为yes。若为no，则要求目标主机上压缩包必须存在。 creates：指定一个文件名，当该文件存在时，则解压指令不执行 dest：远程主机上的一个路径，即文件解压的路径 grop：解压后的目录或文件的属组 list_files：如果为yes，则会列出压缩包里的文件，默认为no，2.0版本新增的选项 mode：解决后文件的权限 src：如果copy为yes，则需要指定压缩文件的源路径owner：解压后文件或目录的属主示例如下：123 - unarchive: src=foo.tgz dest=/var/lib/foo - unarchive: src=/tmp/foo.zip dest=/usr/local/bin copy=no- unarchive: src=https://example.com/example.zip dest=/usr/local/bin copy=no 根据条件判断是否执行12345678910111213141516171819- name: "查看python3是否安装，忽略提示" shell: python3 #执行一条命令，将结果赋值给register定义的result register: result ignore_errors: True #忽略错误提示#拷贝Python-3.6.5- name: "copy Python3-6.5 to dest" copy: src=Python-3.6.5.tgz dest=/usr/local/src/Python-3.6.5.tgz when: result is failed #当result返回的是个错误的时候，执行此tasks#编译安装python3.6.5- name: "compile install" shell: pip install --upgrade supervisor requests;cd /usr/local/src/;tar zxf Python-3.6.5.tgz; cd Python-3.6.5;./configure --prefix=/usr/local/python3 --with-ssl;make;make install when: result is failed#软连接python3- name: "ln -s python3" file: src=/usr/local/python3/bin/python3 dest=/usr/bin/python3 state=link when: result is failed yum模块yum 模块使用 copy模块触发handlers的操作copy触发handlers的操作 handlers/main.yml文件12- name: reload crond command: systemctl restart crond rsync模块1234567- synchronize: src: /usr/local/src/uploadfile/ dest: /usr/local/src/uploadfile/ delete: yes rsync_opts: - "--exclude=logs" - "-avz" notify触发handlers的用法注意: notify后的名字，必须和handlers中定义的名字相同 handlers/main.yml12- name: restart supervisor systemd: name=supervisord state=restarted 角色中的meta定义依赖关系123456meta/main.yml---dependencies: - &#123; role: docker &#125; playbook中变量的定义123456789---- hosts: test-host vars: http_port: 80 remote_user: root tasks: - name: firewalld set firewalld: port=&#123;&#123; http_port &#125;&#125;/tcp permanent=true state=enabled immediate=yes ansible关闭selinux，并等待重启完成，继续执行task123456789101112131415161718192021222324252627- name: install libselinux-python yum: name: libselinux-python state: present tags: - optimize - selinux- name: turn off selinux selinux: state: disabled register: se tags: - optimize - selinux - name: reboot host and wait for it to return shell: sleep 5 &amp;&amp; shutdown -r now "reboot for disable selinux" async: 1 poll: 0 ignore_errors: true when: se.reboot_required == True- name: Wait for the server to finish rebooting wait_for_connection: delay: 5 ansible执行策略优化 ansible并发程序执行的等待优化ansible的任务执行，是并发操作，默认开启5个进程执行，可以执行-f 定义并发进程数ansible默认5个并发进程，如果控制主机比较多，例如20个主机，那么会并行执行5台主机，只有这5台主机全部执行完一次任务，再继续下一批的5台执行任务，如果其中一台执行完任务，那么它默认也会等待那四台主机完成，然后再5台并行执行任务，这样的话，就会影响执行效率； 如果目标主机的网络稳定性不好，开启的进程就会一直等待最后一个任务执行完成，才继续下一个任务 在使用playbook文件中，可以指定 strategy: free 表示异步执行，尽快切换到下一台主机，默认为linear ansible的清单文件中的参数 name description ansible_ssh_host 执行的主机 ansible_ssh_user ssh连接的用户名 ansible_ssh_port ssh目标主机的端口号 以上也是工作中常用到的，没有写的太详细，就是忘记语法的时候，翻出来看看！]]></content>
      <categories>
        <category>linux运维大杂烩</category>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible的playbook语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible命令与模块的使用]]></title>
    <url>%2F2018%2F09%2F18%2Fansible%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[主要记录一下，平常使用ansible的一些命令和模块的使用 ansible定义主机组清单文件默认路径: /etc/ansible/hosts 也可以在ansible.cfg中指定其他路径123[test] # 定义主机组test-1 #主机列表 这里的主机，使用了主机名定义，方便后续在playbook中设置主机hostname，获取清单的变量test-2 当然需要在宿主机的hosts文件指定ipansible的清单文件也可以调用脚本的方式 ansible的命令语法1ansible &#123;主机 | 主机组&#125; -m &#123;指定模块&#125; -a &#123;执行的命令&#125; ansible执行命令选择用户进行ssh连接12# ansible version: 2.8.2ansible &#123;主机 | 主机组 &#125; -b --become-user=USER -m 指定模块 -a 执行的命令 ansible模块command模块12ansible test -m command -a 'hostname' #默认就是command，所以不需要执行-m commandansible test -a "hostname" shell模块12ansible test -m shell -a 'echo "root:testpassword" | chpasswd'#此命令，使用到了管道符号，就必须使用shell模块，command模块不支持管道操作 copy模块12ansible test -m copy -a 'src=/tmp/test.txt dest=/tmp/test.txt'# 将源主机的/tmp/test.txt文件推送到目标主机的/tmp/test.txt synchronize模块12345678ansible test -m synchronize -a 'src=/tmp/directory1/ dest=/tmp/directory1/'#将源主机的directory1目录推送到目标主机ansible test -m synchronize -a 'src=/tmp/directory1/ dest=/tmp/directory1/ delete=yes'# 保持和源目录统一，删除目标目录，源目录没有的文件# 忽略文件同步ansible test -m synchronize -a "src=/tmp/server/ dest=/tmp/client/ rsync_opts='--exclude=sync_test/other.t'" ** 注意:同步目录的时候，源路径目录必须以/ 结尾，要不然同步过去会生成子目录 /tmp/directory1/directory1 script模块12345678910111213141516171819202122232425262728293031323334ansible test -m script -a '/tmp/test.sh'#ansible会把本地/tmp/test.sh脚本推送到目标主机，并执行脚本，执行完删除脚本，退出``` ## file模块### 常用参数| 参数名 | 是否必须 | 默认值 | 选项 | 说明 || --- | --- | --- | --- | --- || follow | no | no | yes/no | 如果原来的文件是link，拷贝后依旧是link| force | no | no | yes/no | 强制执行，没说的 || group | no | | | 设定一个群组拥有拷贝到远程节点的文件权限 || mode | no | | | 等同于chmod，参数可以为“u+rwx or u=rw,g=r,o=r” || owner | no | | | 设定一个用户拥有拷贝到远程节点的文件权限 || path | yes | | | 目标路径，也可以用dest,name代替 || src | yes | | | 待拷贝文件/文件夹的原始位置。 || state | no | | file/link/directory/hard/touch/absent | file代表拷贝后是文件；link代表最终是个软链接；directory代表文件夹；hard代表硬链接；touch代表生成一个空文件；absent代表删除 |### playbook的写法```bash# 修改文件的所有组、人、权限。- file: path=/etc/foo.conf owner=foo group=foo mode=0644# 操作链接的案例- file: src=/file/to/link/to dest=/path/to/symlink owner=foo group=foo state=link#参数化案例- file: src=/tmp/&#123;&#123; item.path &#125;&#125; dest=&#123;&#123; item.dest &#125;&#125; state=link with_items: - &#123; path: 'x', dest: 'y' &#125; - &#123; path: 'z', dest: 'k' &#125;# 使用touch来创建一个空文件并定义权限- file: path=/etc/foo.conf state=touch mode="u=rw,g=r,o=r"# touch一个空文件，并且修改权限- file: path=/etc/foo.conf state=touch mode="u+rw,g-wx,o-rwx" ansible忽略第一次免密钥ssh登录的yes操作1234# cat /etc/ansible/ansible.cfg[defaults]host_key_checking = False # 忽略此检测]]></content>
      <categories>
        <category>自动化运维工具</category>
      </categories>
      <tags>
        <tag>ansible命令</tag>
        <tag>ansible模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[firewalld自定义服务开放端口]]></title>
    <url>%2F2018%2F09%2F18%2Ffirewalld%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%8D%E5%8A%A1%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[在使用docker swarm集群的时候，各工作节点需要开放通信的端口，手动一个一个加，又比较麻烦 索性写成firewalld的服务，然后直接添加此服务即可！ 自定义firewalld服务路径： /usr/lib/firewalld/services/ 新增docker-swarm.xml文件12345678910&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;service&gt;&lt;short&gt;docker-swarm&lt;/short&gt;&lt;description&gt;Default ports for docker swarm&lt;/description&gt;&lt;port protocol="tcp" port="2376"/&gt; &lt;!--For Docker Machine --&gt;&lt;port protocol="tcp" port="2377"/&gt; &lt;!--It only needs to be opened on manager nodes --&gt;&lt;port protocol="tcp" port="7946"/&gt; &lt;!--For container network discovery --&gt;&lt;port protocol="udp" port="7946"/&gt; &lt;!--For container network discovery --&gt;&lt;port protocol="udp" port="4789"/&gt; &lt;!--For container ingress networking --&gt;&lt;/service&gt; firewall-cmd添加自定义的服务12firewall-cmd --add-service=docker-swarm --permanentfirewall-cmd --reload 查看是否添加成功1firewall-cmd --list-all #列出默认区域的防火墙配置]]></content>
      <categories>
        <category>Centos7防火墙</category>
      </categories>
      <tags>
        <tag>firewalld</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo Next主题使用配置]]></title>
    <url>%2F2018%2F09%2F16%2Fhexo-Next%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[当前主题采用版本信息 Next Version: v6.0.0 Hexo Version: v5.1 记录初次使用hexo的基本配置，做个笔记文档！所有的记录，都是在hexo的官网，和别人的博客中找到的，感谢分享的这些文档，让我可以参照部署出自己的博客。 hexo站点使用配置博客的title打开站点配置文件123456789# Sitetitle: Changming's blogssubtitle: 坚持是一种美德description: 命运给你一个比别人低的起点，是想告诉你，让你用一生的努力去奋斗出一个绝地反击的故事。这个故事关于独立，关于梦想，关于坚忍，关于勇气！keywords:author: 李常明language: zh-Hanstimezone:email: 15116973831@163.com 博客左侧导航栏配置打开主题配置文件：D:\hexo\themes\next123456789menu: home: / || home about: /个人简介/ || user tags: /标签/ || tags categories: /分类/ || th archives: /归档/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 上面为菜单的配置;在站点的使用逻辑关系home: 为站点中显示的命名/: 匹配的url|| home : 定义显示的图标 about: 站点中显示的名称/个人简介： 匹配的url ，需要hexo new page “个人简介” 创建与url匹配的页面user: 站点中显示的图标 博客左侧底部栏设置打开站点配置文件，site的区域配置123# Siteauthor: 李常明description: 描述信息 下面的日志 分类 标签，如果站点中，有文章，并添加分类，标签，会自动显示 分类 标签的使用分类 标签的关联关系分类： 文章属于哪一类标签： 文章的主题内容，根据标签判断文章的内容 使用，在hexo文件夹中执行以下命令12hexo new page "分类" #名称必须匹配在上述主题配置文件中Menu区域的匹配的urlhexo new page "标签" 以上页面创建完成后，会存在 D:\hexo\source{分类，标签}在分类，标签中，以上命令会默认创建index.md文件，分别编辑分类，标签中的index.md添加如下内容 标签12345---title: 标签date: 2018-09-16 16:07:36type: "tags" #添加tags--- 分类12345---title: 分类date: 2018-09-16 16:09:20type: "categories" #添加categories--- 新建一篇博客，查看分类和标签的使用1hexo new "hello_world" #新建博客的命令 上述命令执行完后，会生成D:\hexo\source_posts\hello_world.md文件 在hello_world.md文件添加分类和标签12345678---title: test 分类和标签使用date: 2018-09-16 16:09:20tags: - hexo部署配置categories: - 博客搭建--- 123hexo calenhexo generatehexo s #本地运行，访问查看分类和标签 在文章中，指定了标签和分类，那么文章就会归类到同名的标签和分类中，可以快速检索到文章 hexo站内搜索 进入hexo根目录，使用npm 安装插件1npm install hexo-generator-searchdb --save 打开站点配置文件，在Extensions下面添加123456# 搜索search: path: search.xml field: post format: html limit: 10000 打开主题配置文件，找到Local search，将enable设置为true123#站点内文章的搜索功能local_search: enable: true 友情链接添加打开主题配置文件,links区域123links: 追马: http://www.zhuimar.com/ jkzhao: http://jkzhao.github.io/ 设置文章只显示预览部分123auto_excerpt: enable: true #改为true，默认显示length设置的长度内容 length: 150 或者在文章中使用,会显示此标志之前的内容 基本上简约版的配置已经完成了，如果添加其它主题配置优化的，基本上网上也都有相似的文章 贴上几个笔者参考主题配置的urlhexo主题配置优化添加必力评论 后续更新markdown的语法，用于平常翻看！]]></content>
      <categories>
        <category>hexo博客配置与优化</category>
      </categories>
      <tags>
        <tag>hexo站点配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 部署(一)]]></title>
    <url>%2F2018%2F09%2F16%2Fhexo-%E9%83%A8%E7%BD%B2-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[让写作成为习惯，使用博客构建自己的写作平台 hexo博客搭建 折腾了好久的时间，终于使用hexo部署起来了自己的博客。初次使用hexo，也是各种纠结，看起来还不错，想用，但又感觉好麻烦，终于借着周六日休息的时间，把博客整起来了，特此记录下遇到的问题，哈哈！ hexo初体验 初体验的博客部署参考连接：jkzhao部署hexohexo简介 Hexo可以集成Github Pages展示自己的博客Hexo是一个可以快速生成静态页面的博客框架，通过编写mardown文件，转换成html文件，方便在浏览器中加载。 hexo的特点： 快速生成静态页面 支持Markdown 一键部署博客 丰富的插件支持 hexo部署 因个人机使用的win10系统，所以，以下环境都在windows上执行 安装依赖工具 Node.js Git 下载以上两个工具即可。 在GitHub上创建仓库 例如我的仓库： 上面的仓库地址，就是后续要访问的地址，格式必须为： name.github.io 配置本地windows可以免秘钥登录自己的仓库，这个这么简单的问题，就不叙述了。 使用Hexo创建博客框架-1. 在本地磁盘中，新建文件夹 自定义名称 例如hexo-2. 进入hexo文件夹，打开git bash,执行以下命令1234npm install -g hexo #使用npm安装hexo，npm需要安装node.js的支持hexo init #初始化项目结构hexo g #用于生成静态网站文件hexo s #在本地运行静态网页 上面的命令执行完成后，会提示：12345678910$ hexo sINFO Start processingWARN ===============================================================WARN ========================= ATTENTION! ==========================WARN ===============================================================WARN NexT repository is moving here: https://github.com/theme-nextWARN ===============================================================WARN It's rebase to v6.0.0 and future maintenance will resume thereWARN ===============================================================INFO Hexo is running at http://localhost:4000 . Press Ctrl+C to stop. 本地浏览器，访问http://localhost:4000(默认端口4000) 默认主题的博客已经可以显示： 配置本地文件部署到GitHub 在Hexo文件夹下找到_config.yml文件，站点配置文件 修改代码如下：1234deploy: type: git repository: git@github.com:MrLichangming/MrLichangming.github.io.git branch: master 部署到仓库123hexo cleanhexo generatehexo deploy #同步到github仓库，必须本地可以免秘钥，上面deploy字段中，仓库地址填写正确 更改默认主题为NexT在hexo文件夹下，使用git clone Next主题1git clone https://github.com/iissnan/hexo-theme-next themes/next 克隆Next主题到本地hexo文件夹下的thems/next,此路径下全是主题配置文件 启用Next主题打开站点配置文件 1.修改theme字段，将值更改为next 2.修改next主题的样式， scheme: Pisces 当然看个人爱好，可以使用其他样式 预览123hexo cleanhexo generatehexo s hexo的部署很简单，就能看到一个默认的雏形，第二篇文章会更新hexo的Next主题配置优化]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo部署配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux字符串截取]]></title>
    <url>%2F2016%2F02%2F09%2FLinux%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%88%AA%E5%8F%96%2F</url>
    <content type="text"><![CDATA[写脚本，判断变量或者某个值的时候，难免会用到截取的操作以下整理为字符串截取的几种方法 example1234# 定义一个变量var=http://www.google.com/onlineStudy.html# 注意 字符串截取的位置索引号 从1开始计算, 计算公式从0 #号截取，删除左边字符，保留右边字符(删除从左往右遇到的第一个匹配符以及左边的所有内容)1234567echo $&#123;var#*//&#125;# 注释如下 #号是运算符，*//表示从左边开始删除第一个// 号及左边的所有字符，即删除 http://# 输出结果:www.google.com/onlineStudy.html ##号截取，删除左边字符，保留右变字符(删除从左往右遇到的最后一个匹配符以及左边的所有内容)1234567echo $&#123;var##*/&#125;# 注释如下##运算符，*/ 标识从左边开始删除最后一个(最右边) /号及左边的所有字符# 输出结果:onlineStudy.html %号截取，删除右边字符，保留左边字符1234echo $&#123;var%/*&#125;%/* 表示从右边开始，删除第一个 / 号及右边的字符结果是：http://www.google.com %%号截取，删除右边字符，保留左边字符(删除从由往左遇到的最后一个匹配符以及右边所有内容)123echo $&#123;var%%/*&#125;%%/* 表示从右边开始，删除最后（最左边）一个 / 号及右边的字符结果是：http: 截取内容1234567891011121314echo $&#123;var:0:5&#125; # 0表示从左边第一个字符开始，5表示字符的总个数结果为: http:echo $&#123;var:7&#125; # 7表示左边第8个字符开始，一直到结束结果为: www.google.com/onlineStudy.htmlecho $&#123;var:0-7:3&#125; # 0-7表示右边算起第7个字符开始， 3表示字符的个数结果为: dy.echo $&#123;var:0-7&#125; # 0-7表示从右边算起第7个字符开始，一直到结束结果为: dy.htmlecho $&#123;var:0-1&#125; # 右边的第1个字符，到结束结果为: l]]></content>
      <categories>
        <category>linux高阶命令</category>
      </categories>
      <tags>
        <tag>linux高阶命令</tag>
      </tags>
  </entry>
</search>
